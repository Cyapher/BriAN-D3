{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22ff45d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T06:33:46.764371Z",
     "start_time": "2023-11-29T06:33:41.471044Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== IMPORTS/LIBRARIES =====================\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f96df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T07:47:16.188549Z",
     "start_time": "2023-11-27T07:47:16.177846Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== TRAINING HISTORY FUNCTIONS =====================\n",
    "def historyToCsv():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Convert the datetime object to a string\n",
    "    filename_friendly_datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # save to csv: \n",
    "    hist_csv_file = 'history' + filename_friendly_datetime_string + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "def csvToHistory(csv_filename):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    hist_df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    history_dict = hist_df.to_dict(orient='list')\n",
    "\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32811683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T06:33:50.750929Z",
     "start_time": "2023-11-29T06:33:46.767360Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flattened_features (Flatten  (None, 25088)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " embedding (Dense)           (None, 512)               12845568  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 8)           0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 56, 56, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 112, 112, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 224, 224, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " image_retinex_output (Conv2  (None, 224, 224, 3)      219       \n",
      " D)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,560,475\n",
      "Trainable params: 27,560,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ===================== MULTITASK MODEL SETUP =====================\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Dense(512, activation='linear', name='embedding')(flattened_features)\n",
    "\n",
    "# additional_dense_layer1 = tf.keras.layers.Dense(64, name='additional_dense1')(embedding_layer)\n",
    "# additional_dense_layer2 = tf.keras.layers.Dense(64, name='additional_dense2')(additional_dense_layer1)\n",
    "# additional_dense_layer3 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense3')(flattened_features)\n",
    "\n",
    "# landmarks = tf.keras.layers.Dense(10, activation='linear', name='landmark_output')(additional_dense_layer2)\n",
    "# illum = tf.keras.layers.Dense(1, activation='linear', name='previous_illuminance_output')(additional_dense_layer2)\n",
    "\n",
    "# Reshape layer to the desired shape\n",
    "reshaped_features = tf.keras.layers.Reshape((8, 8, 8))(embedding_layer)\n",
    "\n",
    "# Upsampling layers\n",
    "upsample1 = tf.keras.layers.UpSampling2D(size=(7, 7))(reshaped_features)\n",
    "upsample2 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample1)\n",
    "upsample3 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample2)\n",
    "\n",
    "retinex = tf.keras.layers.Conv2D(3, kernel_size=(3, 3), activation='relu', padding='same', name='image_retinex_output')(upsample3)\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = [retinex]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "#         'landmark_output': 'mean_squared_error'\n",
    "#         'previous_illuminance_output': 'mean_squared_error'\n",
    "        'image_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "#         'landmark_output': ['mse', \"mae\"]\n",
    "#         'previous_illuminance_output': ['mse', \"mae\"]\n",
    "        'image_retinex_output': ['mse', \"mae\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()\n",
    "# plot_model(multi_task_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a57105f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T06:33:50.783544Z",
     "start_time": "2023-11-29T06:33:50.754920Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== RETINEX ONLY DATA GEN =====================\n",
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True,\n",
    "                 random_seed=None):  # Add a new parameter for random seed\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed  # Store the random seed\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "#         self.n_coords = 2  # Assuming landmark coordinates are 2-dimensional\n",
    "        self.n_illuminance = 1  # Assuming a single illuminance value\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1, random_state=self.random_seed).reset_index(drop=True)  # Use the random seed\n",
    "    \n",
    "    def __get_input(self, path, target_size):\n",
    "    \n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = tf.image.resize(image_arr, (target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr / 255.\n",
    "    \n",
    "    def __get_output(self, label, output_type):\n",
    "        # Assuming output_type is 'coordinates', 'illuminance', or 'adjusted_image_path'\n",
    "#         if output_type == 'coordinates':\n",
    "#             # Assuming label is a string containing a dictionary-like structure\n",
    "#             # Safely evaluate the string as a literal dictionary using ast.literal_eval\n",
    "#             coordinates_dict = ast.literal_eval(label)\n",
    "            \n",
    "#             # Extract x and y coordinates for each landmark\n",
    "#             landmarks = ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']\n",
    "#             coordinates_list = [coordinates_dict[landmark] for landmark in landmarks]\n",
    "            \n",
    "#             # Flatten the list and convert to numpy array\n",
    "#             coordinates_array = np.array([coord for landmark_coords in coordinates_list for coord in landmark_coords])\n",
    "            \n",
    "# #             print(\"Shape of landmarks_array:\", coordinates_array.shape)\n",
    "            \n",
    "#             # If there are exactly 10 values, return the array, otherwise raise an error\n",
    "#             if len(coordinates_array) == 10:\n",
    "#                 return coordinates_array\n",
    "#             else:\n",
    "#                 raise ValueError(\"Expected 10 coordinates, but found {}\".format(len(coordinates_array)))\n",
    "#         if output_type == 'illuminance':\n",
    "#             # Convert the illuminance value to a float\n",
    "#             return float(label)\n",
    "        if output_type == 'adjusted_image_path':\n",
    "            # Assuming label is the path to the adjusted image\n",
    "            return self.__get_input(label, self.input_size)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        \n",
    "#         coords_batch = batches[self.y_col['coordinates']]\n",
    "#         illuminance_batch = batches[self.y_col['illuminance']]\n",
    "        adjusted_image_path_batch = batches[self.y_col['adjusted_image_path']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
    "\n",
    "#         y0_batch = np.asarray([self.__get_output(y, 'coordinates') for y in coords_batch])\n",
    "#         y0_batch = np.asarray([self.__get_output(y, 'illuminance') for y in illuminance_batch])\n",
    "        y0_batch = np.asarray([self.__get_output(y, 'adjusted_image_path') for y in adjusted_image_path_batch])\n",
    "\n",
    "        return X_batch, [y0_batch]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "\n",
    "        # Print a few examples of the data\n",
    "#         print(\"Sample X:\", tf.shape(X[0]))  # Print the first example in the batch\n",
    "#         print(\"Sample y[0] (landmarks):\", tf.shape(y[0][0]))  # Print the first example in the landmarks output\n",
    "#         print(\"Sample y[1] (illum):\", tf.shape(y[1][0]))  # Print the first example in the illum output\n",
    "#         print(\"Sample y[2] (adjusted_image_path):\", tf.shape(y[2][0]))  # Print the first example in the adjusted_image_path output\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e36c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== DATA GEN SETUP (RETINEX ONLY TASK) =====================\n",
    "\n",
    "train_df = pd.read_csv(\"\") # path to train_data csv\n",
    "train_df[\"Filename\"] = \"./data/Training/\" + train_df[\"Filename\"] + \".jpg\"\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "X_col = {'path': 'Filename'}\n",
    "y_col = {'adjusted_image_path': 'Retinex'}\n",
    "\n",
    "# Create an instance of CustomDataGen\n",
    "train_gen = CustomDataGen(train_df, X_col, y_col, batch_size=32, input_size=(224, 224, 3))\n",
    "\n",
    "eval_df = pd.read_csv(\"\") # path to eval_data csv\n",
    "eval_df[\"Filename\"] = \"./data/Evaluation/\" + eval_df[\"Filename\"] + \".jpg\"\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "eval_X_col = {'path': 'Filename'}\n",
    "eval_y_col = {'adjusted_image_path': 'Retinex'}\n",
    "\n",
    "val_gen = CustomDataGen(eval_df, eval_X_col, eval_y_col, batch_size=32, input_size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37cea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = multi_task_model.fit(train_gen, epochs=50, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f18fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T07:52:06.883872Z",
     "start_time": "2023-11-27T07:52:06.639705Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===================== SAVE MODEL WEIGHTS =====================\n",
    "\n",
    "multi_task_model.save('RetinexOnlyModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8425be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T06:39:18.281426Z",
     "start_time": "2023-11-29T06:39:16.061453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the image\n",
    "image = tf.keras.preprocessing.image.load_img(\"\") # insert image path here\n",
    "image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image_arr = tf.image.resize(image_arr, (224, 224)).numpy()\n",
    "image_arr = image_arr / 255\n",
    "image_arr = tf.expand_dims(image_arr, 0)  # Add batch dimension\n",
    "\n",
    "# Assuming multi_task_model is your model\n",
    "result = multi_task_model.predict(image_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fb1bdf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T06:40:21.832801Z",
     "start_time": "2023-11-29T06:40:21.811474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([  1, 224, 224,   3])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992243aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T06:45:47.515239Z",
     "start_time": "2023-11-29T06:45:44.181789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Denormalize the array\n",
    "denormalized_array = result * 255\n",
    "\n",
    "# Convert the array to uint8 (required by PIL)\n",
    "denormalized_array = denormalized_array.astype(np.uint8)\n",
    "\n",
    "denormalized_array = np.squeeze(denormalized_array, axis=0)\n",
    "\n",
    "# Convert RGB to grayscale using the luminance formula\n",
    "grayscale_array = np.dot(denormalized_array[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# Convert to uint8 (optional, depending on the range of values)\n",
    "grayscale_array = grayscale_array.astype(np.uint8)\n",
    "\n",
    "# Create an image from the grayscale array\n",
    "grayscale_image = Image.fromarray(grayscale_array, mode='L')  # 'L' mode specifies grayscale\n",
    "\n",
    "# # Display the image\n",
    "grayscale_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
