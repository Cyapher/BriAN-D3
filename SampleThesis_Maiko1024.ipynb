{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69663c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:35.029950Z",
     "start_time": "2023-10-24T16:42:27.539554Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf89806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:35.599028Z",
     "start_time": "2023-10-24T16:42:35.590309Z"
    }
   },
   "outputs": [],
   "source": [
    "trainLandmarks = []\n",
    "trainLandmarksRet = []\n",
    "trainFileNames = []\n",
    "trainIllumsRaw = []\n",
    "trainIllumsRet = []\n",
    "evalLandmarks = []\n",
    "evalLandmarksRet = []\n",
    "evalFileNames = []\n",
    "evalIllumsRaw = []\n",
    "evalIllumsRet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096c8392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:37.570870Z",
     "start_time": "2023-10-24T16:42:37.552418Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def frame_capture(file):\n",
    "    \n",
    "    cap = cv2.VideoCapture(file)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "            \n",
    "    current_frame = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "#         print(file)\n",
    "        if not ret:\n",
    "            current_frame = 0\n",
    "            break \n",
    "\n",
    "        if current_frame % 15 == 0:\n",
    "            \n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "            \n",
    "            parentDir = os.path.dirname(os.path.dirname(file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "            \n",
    "            childDir = os.path.dirname(file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "            \n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "            \n",
    "#             filename of txt document containing labels for current video\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                labelFile = labelFile.replace(\"nightno\", \"night_no\")\n",
    "            else:\n",
    "                scenario = \"\"\n",
    "                if \"sunglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                elif \"night_noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"night_noglasses\"    \n",
    "                elif \"noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"noglasses\"\n",
    "                elif \"night_glasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                else:\n",
    "                    scenario = \"glasses\"\n",
    "                \n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + scenario + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                if not os.path.exists(labelFile):                    \n",
    "                    labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + \"wh\" + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                \n",
    "            with open(labelFile) as f:\n",
    "                labels = f.readline()\n",
    "            try:\n",
    "                \n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                else:\n",
    "                    save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                \n",
    "#                 Creating..../data/Testing/037_sunglasses_mix/037_sunglasses_mix_7110_1.jpg\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "            print('Creating...' + file_name)\n",
    "            cv2.imwrite(file_name, frame)\n",
    "            \n",
    "            img_file = Path(file_name) # for Retinex images, use replace() to get path of same named images in order to get post-retinex illum\n",
    "            \n",
    "            if save_path == \"./data/Training/\":\n",
    "                trainFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                trainLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                trainIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetTraining/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                trainIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                trainLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "                \n",
    "                \n",
    "\n",
    "            elif save_path == \"./data/Evaluation/\":\n",
    "                evalFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                evalLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                evalIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetEvaluation/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                evalIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                evalLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "            \n",
    "            \n",
    "        current_frame += 1\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf88578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:37.884879Z",
     "start_time": "2023-10-24T16:42:37.873317Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Training Videos Path\n",
    "def trainingData_prep():\n",
    "    training_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Training Dataset\") #AVIs\n",
    "    training_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in training_videos.glob(\"*\"):\n",
    "        for scenario in driver.glob(\"*\"):\n",
    "            for videos_file in scenario.glob(\"*.avi\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "                datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "                indexDataset = datasetDir.rfind('\\\\')\n",
    "                datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "                parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "                currDir = parentDir\n",
    "\n",
    "                childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "                indexParent = parentDir.rfind('\\\\')\n",
    "                parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "                indexChild = childDir.rfind('\\\\')\n",
    "                childDir = childDir[indexChild:]\n",
    "\n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "                data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "                inputPath = save_path + folder_name\n",
    "\n",
    "                if not os.path.exists(inputPath):\n",
    "                    os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "                video_path = str(videos_file)\n",
    "                training_video_paths.append(video_path)\n",
    "                frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732f5fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:38.141408Z",
     "start_time": "2023-10-24T16:42:38.131485Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation Videos Path\n",
    "def evalData_prep():\n",
    "    evaluation_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset\") #AVIs\n",
    "    evaluation_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in evaluation_videos.glob(\"*\"):\n",
    "        for videos_file in driver.glob(\"*.mp4\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "            parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "\n",
    "            childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "            data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "            inputPath = save_path + folder_name\n",
    "\n",
    "            if not os.path.exists(inputPath):\n",
    "                os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "            video_path = str(videos_file)\n",
    "            evaluation_video_paths.append(video_path)\n",
    "            frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2243a300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:38.402069Z",
     "start_time": "2023-10-24T16:42:38.392414Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Testing Videos Path\n",
    "def testData_prep():\n",
    "    testing_videos = Path(r\"NTHU Dataset\\Testing_Dataset\") #MP4s\n",
    "    testing_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for videos_file in testing_videos.glob(\"*.mp4\"):\n",
    "        print(videos_file)\n",
    "\n",
    "#         note: videos_file refers to direct path of current video file\n",
    "\n",
    "        print(os.path.dirname(videos_file))\n",
    "\n",
    "        datasetDir = os.path.dirname(videos_file)\n",
    "        indexDataset = datasetDir.rfind('\\\\')\n",
    "        datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "        save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "        folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "        print(save_path + folder_name)\n",
    "\n",
    "        data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "        inputPath = save_path + folder_name\n",
    "\n",
    "        if not os.path.exists(inputPath):\n",
    "            os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "        video_path = str(videos_file)\n",
    "        testing_video_paths.append(video_path)\n",
    "        frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0936f309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:39.012167Z",
     "start_time": "2023-10-24T16:42:38.955885Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- ILLUM EST FUNCTIONS\n",
    "\"\"\"\n",
    "Module for hyper spectral image simulation\n",
    "==========================================\n",
    "\n",
    " :_HYPSPCIM_PATH: path to module\n",
    "\n",
    " :_HYPSPCIM_DEFAULT_IMAGE: path + filename to default image\n",
    " \n",
    " :_CSF_NIKON_D700: Nikon D700 camera sensitivity functions\n",
    " \n",
    " :_ROUNDING: rounding of input to xyz_to_rfl() search algorithm for improved speed\n",
    "\n",
    " :xyz_to_rfl(): approximate spectral reflectance of xyz based on k nearest \n",
    "                neighbour interpolation of samples from a standard reflectance \n",
    "                set.\n",
    "\n",
    " :render_image(): Render image under specified light source spd.\n",
    "\n",
    " :get_superresolution_hsi(): Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "\n",
    " :hsi_to_rgb(): Convert HyperSpectral Image to rgb\n",
    " \n",
    " :rfl_to_rgb(): Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "     \n",
    ".. codeauthor:: Kevin A.G. Smet (ksmet1977 at gmail.com)\n",
    "\"\"\"\n",
    "\n",
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "\n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "illum_out = 0\n",
    "\n",
    "__all__ =['_HYPSPCIM_PATH','_HYPSPCIM_DEFAULT_IMAGE','render_image','xyz_to_rfl',\n",
    "          'get_superresolution_hsi','hsi_to_rgb','rfl_to_rgb','_CSF_NIKON_D700']             \n",
    "\n",
    "_HYPSPCIM_PATH = _PKG_PATH + _SEP + 'hypspcim' + _SEP\n",
    "_HYPSPCIM_DEFAULT_IMAGE = _PKG_PATH + _SEP + 'toolboxes' + _SEP + 'hypspcim' +  _SEP + 'data' + _SEP + 'testimage1.jpg'\n",
    "\n",
    "\n",
    "_ROUNDING = 6 # to speed up xyz_to_rfl search algorithm, increase if kernel dies!!!\n",
    "\n",
    "# Nikon D700 camera sensitivity functions:\n",
    "_CSF_NIKON_D700 = np.vstack((np.arange(400,710,10),\n",
    "                             np.array([[0.005, 0.007, 0.012, 0.015, 0.023, 0.025, 0.030, 0.026, 0.024, 0.019, 0.010, 0.004, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  0.000,  0.000,  0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000], \n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.002, 0.003, 0.005, 0.007, 0.012, 0.013, 0.015, 0.016, 0.017, 0.020, 0.013, 0.011, 0.009, 0.005,  0.001,  0.001,  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.002, 0.002, 0.003],\n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.003, 0.010, 0.012,  0.013,  0.022,  0.020, 0.020, 0.018, 0.017, 0.016, 0.016, 0.014, 0.014, 0.013]])[::-1]))\n",
    "\n",
    "\n",
    "def xyz_to_rfl(xyz, CSF = None, rfl = None, out = 'rfl_est', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {},\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, verbosity = 0,\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Approximate spectral reflectance of xyz values based on nd-dimensional linear interpolation \n",
    "    or k nearest neighbour interpolation of samples from a standard reflectance set.\n",
    "    \n",
    "    Args:\n",
    "        :xyz: \n",
    "            | ndarray with xyz values of target points.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb (float) values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'rfl_est' or str, optional\n",
    "        :refspd: \n",
    "            | None, optional\n",
    "            | Refer ence spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65.\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set used for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | :rfl_est:\n",
    "            | ndarrays with estimated reflectance spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    \n",
    "    wlr = rfl[0]\n",
    "    \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "        \n",
    "    # Calculate rgb values of standard rfl set under refspd:\n",
    "    if CSF is None:\n",
    "        # Calculate lab coordinates:\n",
    "        xyz_rr, xyz_wr = spd_to_xyz(refspd, relative = True, rfl = rfl, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_rr = colortf(xyz_rr, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)[:,0,:]\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions\n",
    "        rgb_rr = rfl_to_rgb(rfl, spd = refspd, CSF = CSF, wl = None)   \n",
    "        lab_rr = rgb_rr\n",
    "        xyz = xyz\n",
    "        lab_rr = np.round(lab_rr,csf_based_rgb_rounding) # speed up search\n",
    "        \n",
    "        global illum_out\n",
    "        illum_out = np.mean(lab_rr)\n",
    "        print(\"Illuminance: \" + str(np.mean(lab_rr)))\n",
    "        \n",
    "    # Convert xyz to lab-type values under refspd:\n",
    "    if CSF is None:\n",
    "        lab = colortf(xyz, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)\n",
    "    else:\n",
    "        lab = xyz # xyz contained rgb values !!!\n",
    "        rgb = xyz\n",
    "        lab = np.round(lab,csf_based_rgb_rounding) # speed up search\n",
    "    \n",
    "    if interp_type == 'nearest':\n",
    "        # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "        # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "        # Construct cKDTree:\n",
    "        tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "        \n",
    "        # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "        d, inds = tree.query(lab, k = k_neighbours )\n",
    "        if k_neighbours  > 1:\n",
    "            d += _EPS\n",
    "            w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "            rfl_est = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "        else:\n",
    "            rfl_est = rfl[inds+1,:].copy()\n",
    "    elif interp_type == 'nd':\n",
    "\n",
    "        rfl_est = math.ndinterp1_scipy(lab_rr, rfl[1:], lab)\n",
    "            \n",
    "        _isnan = np.isnan(rfl_est[:,0]) \n",
    "\n",
    "        if (_isnan.any()): #do nearest neigbour method for those that fail using Delaunay (i.e. ndinterp1_scipy)\n",
    "\n",
    "            # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "            # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "            # Construct cKDTree:\n",
    "            tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "\n",
    "            # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "            d, inds = tree.query(lab[_isnan,...], k = k_neighbours )\n",
    "\n",
    "            if k_neighbours  > 1:\n",
    "                d += _EPS\n",
    "                w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "                rfl_est_isnan = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "            else:\n",
    "                rfl_est_isnan = rfl[inds+1,:].copy()\n",
    "            rfl_est[_isnan, :] = rfl_est_isnan\n",
    "\n",
    "    else:\n",
    "        raise Exception('xyz_to_rfl(): unsupported interp_type!')\n",
    "    \n",
    "    rfl_est[rfl_est<0] = 0 #can occur for points outside convexhull of standard rfl set.\n",
    "\n",
    "    rfl_est = np.vstack((rfl[0],rfl_est))\n",
    "        \n",
    "    if ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('lab_est' in out.split(',')) | ('DEi_ab' in out.split(',')) | ('DEa_ab' in out.split(','))) & (CSF is None):\n",
    "        xyz_est, _ = spd_to_xyz(refspd, rfl = rfl_est, relative = True, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_est = colortf(xyz_est, tf = cspace, fwtf = cspace_tf_copy)[:,0,:]\n",
    "        DEi_ab = np.sqrt(((lab_est[:,1:3]-lab[:,1:3])**2).sum(axis=1))\n",
    "        DEa_ab = DEi_ab.mean()\n",
    "    elif ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('rgb_est' in out.split(',')) | ('DEi_rgb' in out.split(',')) | ('DEa_rgb' in out.split(','))) & (CSF is not None):\n",
    "        rgb_est = rfl_to_rgb(rfl_est[1:], spd = refspd, CSF = CSF, wl = wlr) \n",
    "        xyz_est = rgb_est\n",
    "        DEi_rgb = np.sqrt(((rgb_est - rgb)**2).sum(axis=1))\n",
    "        DEa_rgb = DEi_rgb.mean()\n",
    "\n",
    "        \n",
    "    if verbosity > 0:\n",
    "        if CSF is None:\n",
    "            ax = plot_color_data(lab[...,1], lab[...,2], z = lab[...,0], \\\n",
    "                            show = False, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'ro', label = 'Original')\n",
    "            plot_color_data(lab_est[...,1], lab_est[...,2], z = lab_est[...,0], \\\n",
    "                            show = True, axh = ax, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'bd', label = 'Rendered')\n",
    "        else:\n",
    "            n = 100 #min(rfl.shape[0]-1,rfl_est.shape[0]-1)\n",
    "            s = np.random.permutation(rfl.shape[0]-1)[:min(n,rfl.shape[0]-1)]\n",
    "            st = np.random.permutation(rfl_est.shape[0]-1)[:min(n,rfl_est.shape[0]-1)]\n",
    "            fig = plt.figure()\n",
    "            ax = np.zeros((3,),dtype=np.object)\n",
    "            ax[0] = fig.add_subplot(131)\n",
    "            ax[1] = fig.add_subplot(132)\n",
    "            ax[2] = fig.add_subplot(133,projection='3d')\n",
    "            ax[0].plot(rfl[0],rfl[1:][s].T, linestyle = '-')\n",
    "            ax[0].set_title('Original RFL set (random selection of all)')\n",
    "            ax[0].set_ylim([0,1])\n",
    "            ax[1].plot(rfl_est[0],rfl_est[1:][st].T, linestyle = '--')\n",
    "            ax[0].set_title('Estimated RFL set (random selection of targets)')\n",
    "            ax[1].set_ylim([0,1])\n",
    "            ax[2].plot(rgb[st,0],rgb[st,1],rgb[st,2],'ro', label = 'Original')\n",
    "            ax[2].plot(rgb_est[st,0],rgb_est[st,1],rgb_est[st,2],'bd', label = 'Rendered')\n",
    "            ax[2].legend()\n",
    "    if out == 'rfl_est':\n",
    "        return rfl_est\n",
    "    elif out == 'rfl_est,xyz_est':\n",
    "        return rfl_est, xyz_est\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "\n",
    "def render_image(img = None, spd = None, rfl = None, out = 'img_hyp', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {}, CSF = None,\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, show = True,\n",
    "                 verbosity = 0, show_ref_img = True,\\\n",
    "                 stack_test_ref = 12,\\\n",
    "                 write_to_file = None,\\\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Render image under specified light source spd.\n",
    "    \n",
    "    Args:\n",
    "        :img: \n",
    "            | None or str or ndarray with float (max = 1) rgb image.\n",
    "            | None load a default image.\n",
    "        :spd: \n",
    "            | ndarray, optional\n",
    "            | Light source spectrum for rendering\n",
    "            | If None: use CIE illuminant F4\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'img_hyp' or str, optional\n",
    "            |  (other option: 'img_ren': rendered image under :spd:)\n",
    "        :refspd:\n",
    "            | None, optional\n",
    "            | Reference spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65 (srgb has a D65 white point)\n",
    "        :D: \n",
    "            | None, optional\n",
    "            | Degree of (von Kries) adaptation from spd to refspd. \n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :show: \n",
    "            | True, optional\n",
    "            |  Show images.\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "              rendered image pixels.\n",
    "        :show_ref_img:\n",
    "            | True, optional\n",
    "            | True: shows rendered image under reference spd. False: shows\n",
    "            |  original image.\n",
    "        :write_to_file:\n",
    "            | None, optional\n",
    "            | None: do nothing, else: write to filename(+path) in :write_to_file:\n",
    "        :stack_test_ref: \n",
    "            | 12, optional\n",
    "            |   - 12: left (test), right (ref) format for show and imwrite\n",
    "            |   - 21: top (test), bottom (ref)\n",
    "            |   - 1: only show/write test\n",
    "            |   - 2: only show/write ref\n",
    "            |   - 0: show both, write test\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | img_hyp, img_ren, \n",
    "            | ndarrays with float hyperspectral image and rendered images \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get image:\n",
    "    #imread = lambda x: plt.imread(x) #matplotlib.pyplot\n",
    "   \n",
    "    if img is not None:\n",
    "        if isinstance(img,str):\n",
    "            img = plt.imread(img).copy() # use matplotlib.pyplot's imread\n",
    "    else:\n",
    "        img = plt.imread(_HYPSPCIM_DEFAULT_IMAGE).copy()\n",
    "    \n",
    "    if img.dtype == np.uint8: \n",
    "        img = img/255\n",
    "    elif img.dtype == np.uint16:\n",
    "        img = img/(2**16-1)\n",
    "    elif (img.dtype == np.float64) | (img.dtype == np.float32):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    if img.max() > 1.0: raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    \n",
    "    \n",
    "    # Convert to 2D format:\n",
    "    rgb = img.reshape(img.shape[0]*img.shape[1],3) # *1.0: make float\n",
    "    rgb[rgb==0] = _EPS # avoid division by zero for pure blacks.\n",
    "\n",
    "    \n",
    "    # Get unique rgb values and positions:\n",
    "    rgb_u, rgb_indices = np.unique(rgb, return_inverse=True, axis = 0)\n",
    "\n",
    "    \n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    wlr = rfl[0] # spectral reflectance set determines wavelength range for estimation (xyz_to_rfl())\n",
    "        \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "\n",
    "\n",
    "    # Convert rgb_u to xyz and lab-type values under assumed refspd:\n",
    "    if CSF is None:\n",
    "        xyz_wr = spd_to_xyz(refspd, cieobs = cieobs, relative = True)\n",
    "        xyz_ur = colortf(rgb_u*255, tf = 'srgb>xyz')\n",
    "    else:\n",
    "        xyz_ur = rgb_u # for input in xyz_to_rfl (when CSF is not None: this functions assumes input is indeed rgb !!!)\n",
    "    \n",
    "    # Estimate rfl's for xyz_ur:\n",
    "    rfl_est, xyzri = xyz_to_rfl(xyz_ur, rfl = rfl, out = 'rfl_est,xyz_est', \\\n",
    "                 refspd = refspd, D = D, cieobs = cieobs, \\\n",
    "                 cspace = cspace, cspace_tf = cspace_tf, CSF = CSF,\\\n",
    "                 interp_type = interp_type, k_neighbours = k_neighbours, \n",
    "                 verbosity = verbosity,\n",
    "                 csf_based_rgb_rounding = csf_based_rgb_rounding)\n",
    "\n",
    "    # Get default test spd if none supplied:\n",
    "    if spd is None:\n",
    "        spd = _CIE_ILLUMINANTS['F4']\n",
    "        \n",
    "    if CSF is None:\n",
    "        # calculate xyz values under test spd:\n",
    "        xyzti, xyztw = spd_to_xyz(spd, rfl = rfl_est, cieobs = cieobs, out = 2)\n",
    "    \n",
    "        # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            xyzti = cat.apply(xyzti, xyzw1 = xyztw, xyzw2 = xyz_wr, D = D)\n",
    "    \n",
    "        # Convert xyzti under test spd to srgb:\n",
    "        rgbti = colortf(xyzti, tf = 'srgb')/255\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions under spd:\n",
    "        rgbti = rfl_to_rgb(rfl_est, spd = spd, CSF = CSF, wl = None) \n",
    "        \n",
    "         # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            white = np.ones_like(spd)\n",
    "            white[0] = spd[0]\n",
    "            rgbwr = rfl_to_rgb(white, spd = refspd, CSF = CSF, wl = None)\n",
    "            rgbwt = rfl_to_rgb(white, spd = spd, CSF = CSF, wl = None)\n",
    "            rgbti = cat.apply_vonkries2(rgbti,rgbwt,rgbwr,xyzw0=np.array([[1.0,1.0,1.0]]), in_type='rgb',out_type= 'rgb',D=1)\n",
    "        \n",
    "    \n",
    "    # Reconstruct original locations for rendered image rgbs:\n",
    "    img_ren = rgbti[rgb_indices]\n",
    "    img_ren.shape = img.shape # reshape back to 3D size of original\n",
    "    img_ren = img_ren\n",
    "    \n",
    "    # For output:\n",
    "    if show_ref_img == True:\n",
    "        rgb_ref = colortf(xyzri, tf = 'srgb')/255 if (CSF is None) else xyzri # if CSF not None: xyzri contains rgbri !!!\n",
    "        img_ref = rgb_ref[rgb_indices]\n",
    "        img_ref.shape = img.shape # reshape back to 3D size of original\n",
    "        img_str = 'Rendered (under ref. spd)'\n",
    "        img = img_ref\n",
    "    else:\n",
    "        img_str = 'Original'\n",
    "        img = img\n",
    "       \n",
    "    \n",
    "    if (stack_test_ref > 0) | show == True:\n",
    "        if stack_test_ref == 21:\n",
    "            img_original_rendered = np.vstack((img_ren,np.ones((4,img.shape[1],3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd)\\n ' + img_str \n",
    "        elif stack_test_ref == 12:\n",
    "            img_original_rendered = np.hstack((img_ren,np.ones((img.shape[0],4,3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd) | ' + img_str \n",
    "        elif stack_test_ref == 1:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str = 'Rendered (under test spd)' \n",
    "        elif stack_test_ref == 2:\n",
    "            img_original_rendered = img\n",
    "            img_original_rendered_str = img_str\n",
    "        elif stack_test_ref == 0:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str =  'Rendered (under test spd)' \n",
    "            \n",
    "    if write_to_file is not None:\n",
    "        # Convert from RGB to BGR formatand write:\n",
    "        #print('Writing rendering results to image file: {}'.format(write_to_file))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imsave(write_to_file, img_original_rendered)\n",
    "            \n",
    "    if show == True:\n",
    "        # show images using pyplot.show():\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.imshow(img_original_rendered)\n",
    "        plt.title(img_original_rendered_str)\n",
    "        plt.gca().get_xaxis().set_ticklabels([])\n",
    "        plt.gca().get_yaxis().set_ticklabels([])\n",
    "        \n",
    "        if stack_test_ref == 0:\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title(img_str)\n",
    "            plt.axis('off')\n",
    "      \n",
    "    if 'img_hyp' in out.split(','):\n",
    "        # Create hyper_spectral image:\n",
    "        rfl_image_2D = rfl_est[rgb_indices+1,:] # create array with all rfls required for each pixel\n",
    "        img_hyp = rfl_image_2D.reshape(img.shape[0],img.shape[1],rfl_image_2D.shape[1])\n",
    "\n",
    "\n",
    "    # Setup output:\n",
    "    if out == 'img_hyp':\n",
    "        return img_hyp\n",
    "    elif out == 'img_ren':\n",
    "        return img_ren\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "def rfl_to_rgb(rfl, spd = None, CSF = None, wl = None, normalize_to_white = True):\n",
    "    \"\"\" \n",
    "    Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "    \n",
    "    Args:\n",
    "        :rfl:\n",
    "            | ndarray with spectral reflectance functions (1st row is wavelengths if wl is None).\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True: white-balance output rgb to a perfect white diffuser.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb values for each spectral reflectance functions\n",
    "    \"\"\"\n",
    "    rfl_cp = rfl.copy()\n",
    "    if (wl is None): \n",
    "        wl = rfl_cp[0] \n",
    "        rfl_cp = rfl_cp[1:]\n",
    "    wlr = getwlr(wl)\n",
    "    if spd is not None:\n",
    "        spd = cie_interp(spd,wlr,kind='linear')[1:]\n",
    "    else:\n",
    "        spd = np.ones_like(wlr)\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    CSF = cie_interp(CSF,wlr,kind='linear')\n",
    "    CSF[1:] = CSF[1:]*spd\n",
    "    rgb = rfl_cp @ CSF[1:].T \n",
    "    if normalize_to_white:\n",
    "        white = np.ones_like(spd)\n",
    "        white = white/white.sum()*spd.sum()\n",
    "        rgbw = white @ CSF[1:].T  \n",
    "        rgb = rgb/rgbw.max(axis = 0,keepdims=True) \n",
    "    \n",
    "    return rgb\n",
    "\n",
    "    \n",
    "    \n",
    "def hsi_to_rgb(hsi, spd = None, cieobs = _CIEOBS, srgb = False, \n",
    "               linear_rgb = False, CSF = None, normalize_to_white = True, \n",
    "               wl = [380,780,1]):\n",
    "    \"\"\" \n",
    "    Convert HyperSpectral Image to rgb.\n",
    "    \n",
    "    Args:\n",
    "        :hsi:\n",
    "            | ndarray with hyperspectral image [M,N,L]\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set to convert spectral data to xyz tristimulus values.\n",
    "        :srgb:\n",
    "            | False, optional\n",
    "            | If False: Use xyz_to_srgb(spd_to_xyz(...)) to convert to srgb values\n",
    "            | If True: use camera sensitivity functions.\n",
    "        :linear_rgb:\n",
    "            | False, optional\n",
    "            | If False: use gamma = 2.4 in xyz_to_srgb, if False: use gamma = 1 and set :use_linear_part: to False.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True & CSF is not None: white-balance output rgb to a perfect white diffuser.\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb image [M,N,3]\n",
    "    \"\"\"\n",
    "    if spd is None:\n",
    "        spd = _CIE_E.copy()\n",
    "    wlr = getwlr(wl)\n",
    "    spd = cie_interp(spd,wl,kind='linear')\n",
    "    \n",
    "    hsi_2d = np.reshape(hsi,(hsi.shape[0]*hsi.shape[1],hsi.shape[2]))\n",
    "    if srgb:\n",
    "        xyz = spd_to_xyz(spd, cieobs = cieobs, relative = True, rfl = np.vstack((wlr,hsi_2d)))\n",
    "        gamma = 1 if linear_rgb else 2.4\n",
    "        rgb = xyz_to_srgb(xyz, gamma = gamma, use_linear_part = not linear_rgb)/255\n",
    "    else:\n",
    "        if CSF is None: CSF = _CSF_NIKON_D700\n",
    "        rgb = rfl_to_rgb(hsi_2d, spd = spd, CSF = CSF, wl = wl, normalize_to_white = normalize_to_white)        \n",
    "    return np.reshape(rgb,(hsi.shape[0],hsi.shape[1],3))\n",
    "\n",
    "       \n",
    "def get_superresolution_hsi(lrhsi, hrci, CSF, wl = [380,780,1], csf_based_rgb_rounding = _ROUNDING,\n",
    "                            interp_type = 'nd', k_neighbours = 4, verbosity = 0):\n",
    "    \"\"\" \n",
    "    Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "    \n",
    "    Args:\n",
    "        :lrhsi:\n",
    "            | ndarray with float (max = 1) LowResolution HSI [m,m,L].\n",
    "        :hrci:\n",
    "            | ndarray with float (max = 1) HighResolution HSI [M,N,3].\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | Verbosity level for sub-call to render_image().\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :hrhsi:\n",
    "            | ndarray with HighResolution HSI [M,N,L].\n",
    "        \n",
    "    Procedure:\n",
    "        | Call render_image(hrci, rfl = lrhsi_2, CSF = ...) to estimate a hyperspectral image\n",
    "        | from the high-resolution color image hrci with the reflectance spectra \n",
    "        | in the low-resolution hyper-spectral image as database for the estimation.\n",
    "        | Estimation is done in raw RGB space with the lrhsi converted using the\n",
    "        | camera sensitivity functions in CSF.\n",
    "    \"\"\"\n",
    "    wlr = getwlr(wl)\n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "    lrhsi_2d = np.vstack((wlr,np.reshape(lrhsi,(lrhsi.shape[0]*lrhsi.shape[1],lrhsi.shape[2])))) # create 2D rfl database\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    hrhsi = render_image(hrci, spd = eew,\n",
    "                         refspd = eew, rfl = lrhsi_2d, D = None,\n",
    "                         interp_type = interp_type, k_neighbours = k_neighbours,\n",
    "                         verbosity = verbosity, show = bool(verbosity),\n",
    "                         CSF = CSF, csf_based_rgb_rounding = csf_based_rgb_rounding) # render HR-hsi from HR-ci using LR-HSI rfls as database        \n",
    "    return hrhsi\n",
    "\n",
    "\n",
    "def illuminanceEstimation(input_img):\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for HSI simulation and rendering:\n",
    "    #--------------------------------------------------------------------------\n",
    "    # plt.close('all')\n",
    "    # from luxpy.toolboxes import spdbuild as spb\n",
    "    # S = spb.spd_builder(peakwl = [460,525,590],fwhm=[20,40,20],target=4000, tar_type = 'cct') \n",
    "    # img = _HYPSPCIM_DEFAULT_IMAGE\n",
    "    # img_hyp,img_ren = render_image(img = img, \n",
    "    #                                 cspace = 'Yuv',interp_type='nd',\n",
    "    #                                 spd = S, D=1, \n",
    "    #                                 show_ref_img = True,\n",
    "    #                                 stack_test_ref = 21,\n",
    "    #                                 out='img_hyp,img_ren',\n",
    "    #                                 write_to_file = 'test.jpg') \n",
    "    # raise Exception('')\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for super resolution:\n",
    "    #--------------------------------------------------------------------------\n",
    "    import time\n",
    "    import luxpy as lx\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage import transform\n",
    "    import imageio\n",
    "    from skimage.transform import rescale,resize\n",
    "    \n",
    "    np.random.seed(1)    \n",
    "    \n",
    "    # Set some default parameters:\n",
    "    #----------------------------\n",
    "    load_hsi = False # If True: load hrci and hrhsi from npy-file.\n",
    "    file = input_img\n",
    "\n",
    "    cieobs = '1931_2' # CIE CMF set\n",
    "    linear_rgb = 1 # only used when srgb in hsi_to_rgb == True !!!\n",
    "    verbosity = 0\n",
    "    \n",
    "    # Create HR-rgb image and HR-HSI for code testing: \n",
    "    #---------------------------------------------------\n",
    "    # get an image:\n",
    "    im = imageio.v2.imread(file)/255\n",
    "    \n",
    "    # rescale to n x dimensions of typical hyperspectral camera:\n",
    "    n = 2 # downscale factor\n",
    "    w, h = 1280, 960\n",
    "    cr,cc = np.array(im.shape[:2])//2\n",
    "    crop = lambda im,cr,cc,h,w:im[(cr-h//2):(cr+h//2),(cc-w//2):(cc+w//2),:].copy()\n",
    "    im = crop(im,cr,cc,h*n,w*n)\n",
    "#     print('New image shape:',im.shape)\n",
    "    \n",
    "    # simulate HR hyperspectral image:\n",
    "    hrhsi = render_image(im,show=False)\n",
    "    wlr = getwlr([380,780,1]) #  = wavelength range of default TM30 rfl set\n",
    "    wlr = wlr[20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "    hrhsi = hrhsi[...,20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "#     print('Simulated HR-HSI shape:',hrhsi.shape)\n",
    "    # np.save(file[:-4]+'.npy',{'hrhsi':hrhsi,'im':im, 'wlr':wlr})\n",
    "    \n",
    "    # Illumination spectrum of HSI:    \n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "        \n",
    "    # Create fig and axes for plots:\n",
    "    if verbosity > 0: fig, axs = plt.subplots(1,3)\n",
    "    \n",
    "    # convert HR hsi to HR rgb image:\n",
    "    hrci = hsi_to_rgb(hrhsi, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[0].imshow(hrci)\n",
    "    \n",
    "    # create LR hsi image for testing:\n",
    "    dl = n \n",
    "    lrhsi = hrhsi[::dl,::dl,:]\n",
    "#     print('Simulated LR-HSI shape:',lrhsi.shape)\n",
    "    \n",
    "    # convert LR hsi to LR rgb image:\n",
    "    lrci = hsi_to_rgb(lrhsi, spd = eew, cieobs = cieobs, wl = wlr,linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[1].imshow(lrci)\n",
    "    \n",
    "    # # Perform rgb guided super-resolution:\n",
    "    #hrci = lrci # for testing of estimation code\n",
    "    tic = time.time()\n",
    "    hrhsi_est = get_superresolution_hsi(lrhsi, hrci, CSF = _CSF_NIKON_D700, wl = wlr)\n",
    "#     print('Elapsed time (s): {:1.4f}'.format(time.time() - tic))\n",
    "    hrci_est = hsi_to_rgb(hrhsi_est, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "\n",
    "    if verbosity > 0:  axs[2].imshow(hrci_est)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Plot some rfl to visually evaluate estimation accuracy:\n",
    "    \n",
    "    hsi_rmse = np.linalg.norm(hrhsi-hrhsi_est)/np.array(hrhsi.shape[:2]).prod()**0.5\n",
    "#     print('RMSE(ground-truth,estimate): {:1.4f}'.format(hsi_rmse))\n",
    "    \n",
    "    global illum_out\n",
    "    return illum_out\n",
    "    \n",
    "#     fig, axs = plt.subplots(1,4, figsize=(22,5))\n",
    "    \n",
    "#     axs[0].imshow(transform.rescale(lrci,dl,order=0,multichannel=True),aspect='auto')\n",
    "#     axs[0].set_title('Color image of LR-HSI\\n(HR-to-LR scale factor = {:1.2f})'.format(1/dl))\n",
    "#     axs[0].axis('off')\n",
    "#     axs[1].imshow(hrci_est,aspect='auto')\n",
    "#     axs[1].set_title('Color image of estimated HR-HSI')\n",
    "#     axs[1].axis('off')\n",
    "    \n",
    "#     px_rmse = ((hrhsi_est-hrhsi)**2).sum(axis=-1)**0.5 # rmse per pixel\n",
    "#     axs[2].set_title('RMSE(ground-truth, estimated) HR-HSI\\nRMSE = {:1.4f}, max = {:1.4f}'.format((px_rmse**2).mean()**0.5,px_rmse.max()))\n",
    "#     im = axs[2].imshow(px_rmse, cmap = 'jet',aspect='auto') # rmse per pixel\n",
    "#     cbar = axs[2].figure.colorbar(im, ax=axs[2])\n",
    "#     cbar.ax.set_ylabel('RMSE', rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    \n",
    "#     psorted = np.unravel_index(np.argsort(px_rmse, axis=None), px_rmse.shape) # index of pixels sorted by px_rmse\n",
    "#     np.random.seed(1)\n",
    "#     pxs = np.random.permutation(min(hrhsi.shape[:2]))[:12].reshape(2,3,2)\n",
    "#     iis = np.hstack((pxs[...,0].ravel(),psorted[0][-3:]))\n",
    "#     jjs = np.hstack((pxs[...,1].ravel(),psorted[1][-3:]))\n",
    "#     colors = np.array(['m','b','c','g','y','r','k','lightgrey','grey'])\n",
    "#     for t in range(len(iis)):\n",
    "#         ii,jj = iis[t],jjs[t]\n",
    "#         axs[1].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[2].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[3].plot(wlr,hrhsi[ii,jj,:],color = colors[t], linestyle ='-',label='ground-truth (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#         axs[3].plot(wlr,hrhsi_est[ii,jj,:],color = colors[t], linestyle = '--',label='estimate (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#     axs[3].legend(bbox_to_anchor=(1.05, 1))   \n",
    "#     axs[3].set_xlabel('Wavelengths (nm)')\n",
    "#     axs[3].set_ylabel('Spectral Reflectance')\n",
    "#     plt.subplots_adjust(right=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb1ae358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:40.539413Z",
     "start_time": "2023-10-24T16:42:40.531440Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def illumEstOneFolder_prep():\n",
    "    images = Path(r\"data\\Training\\001_nonsleepyCombination\") #imgs\n",
    "#     landmarks = []\n",
    "#     fileNames = []\n",
    "#     illums = []\n",
    "    \n",
    "#     for img_file in images.glob(\"*.jpg\"):\n",
    "\n",
    "#         print(os.path.basename(img_file)[:-4])\n",
    "#         fileNames.append(os.path.basename(img_file)[:-4])\n",
    "#         landmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "#         illums.append(illuminanceEstimation(img_file))\n",
    "#         retinexImplement(img_file)\n",
    "    \n",
    "#     ilu_dis = pd.DataFrame({'File Names': fileNames, 'Landmark Confidence': landmarks, 'Illuminance': illums})\n",
    "    \n",
    "#     print(ilu_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6f26ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:41.014921Z",
     "start_time": "2023-10-24T16:42:41.011423Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generateLandmarks(img):\n",
    "    img = cv2.imread(img)\n",
    "    detector = MTCNN()\n",
    "    output = detector.detect_faces(img)\n",
    "#     print(output[0]['confidence'])\n",
    "    \n",
    "    return output[0]['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a15479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:41.257111Z",
     "start_time": "2023-10-24T16:42:41.250484Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# notes:\n",
    "\n",
    "# average 2.67s per image for generating landmarks and illuminance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f9a8d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:43.930022Z",
     "start_time": "2023-10-24T16:42:41.492432Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import URetinexNet\n",
    "from URetinex_Net import *\n",
    "\n",
    "# Import Arch_network\n",
    "import sys\n",
    "sys.path.append(r\"URetinex_Net\")\n",
    "\n",
    "# testing of URetinex.Net\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from network.Math_Module import P, Q\n",
    "from network.decom import Decom\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "from utils import *\n",
    "\n",
    "def one2three(x):\n",
    "    return torch.cat([x, x, x], dim=1).to(x)\n",
    "\n",
    "class Inference(nn.Module):\n",
    "    #Class Inference Methods\n",
    "    def __init__(self, opts):\n",
    "        super().__init__()\n",
    "        self.opts = opts\n",
    "        # loading decomposition model \n",
    "        self.model_Decom_low = Decom()\n",
    "        self.model_Decom_low = load_initialize(self.model_Decom_low, self.opts.Decom_model_low_path)\n",
    "        # loading R; old_model_opts; and L model\n",
    "        self.unfolding_opts, self.model_R, self.model_L= load_unfolding(self.opts.unfolding_model_path)\n",
    "        # loading adjustment model\n",
    "        self.adjust_model = load_adjustment(self.opts.adjust_model_path)\n",
    "        self.P = P()\n",
    "        self.Q = Q()\n",
    "\n",
    "        transform = [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform)\n",
    "        print(self.model_Decom_low)\n",
    "        print(self.model_R)\n",
    "        print(self.model_L)\n",
    "        print(self.adjust_model)\n",
    "        #time.sleep(8)\n",
    "\n",
    "    def unfolding(self, input_low_img):\n",
    "        for t in range(self.unfolding_opts.round):      \n",
    "            if t == 0: # initialize R0, L0\n",
    "                P, Q = self.model_Decom_low(input_low_img)\n",
    "            else: # update P and Q\n",
    "                w_p = (self.unfolding_opts.gamma + self.unfolding_opts.Roffset * t)\n",
    "                w_q = (self.unfolding_opts.lamda + self.unfolding_opts.Loffset * t)\n",
    "                P = self.P(I=input_low_img, Q=Q, R=R, gamma=w_p)\n",
    "                Q = self.Q(I=input_low_img, P=P, L=L, lamda=w_q) \n",
    "            R = self.model_R(r=P, l=Q)\n",
    "            L = self.model_L(l=Q)\n",
    "        return R, L\n",
    "    \n",
    "    def lllumination_adjust(self, L, ratio):\n",
    "        ratio = torch.ones(L.shape) * self.opts.ratio\n",
    "        return self.adjust_model(l=L, alpha=ratio)\n",
    "    \n",
    "    def forward(self, input_low_img):\n",
    "        if torch.cuda.is_available():\n",
    "            input_low_img = input_low_img\n",
    "        with torch.no_grad():\n",
    "            start = time.time()  \n",
    "            R, L = self.unfolding(input_low_img)\n",
    "            High_L = self.lllumination_adjust(L, self.opts.ratio)\n",
    "            I_enhance = High_L * R\n",
    "            p_time = (time.time() - start)\n",
    "        return I_enhance, p_time\n",
    "\n",
    "    def run(self, low_img_path):\n",
    "        file_name = os.path.basename(self.opts.img_path)\n",
    "        name = file_name.split('.')[0]\n",
    "        low_img = self.transform(Image.open(low_img_path)).unsqueeze(0)\n",
    "        enhance, p_time = self.forward(input_low_img=low_img)\n",
    "        if not os.path.exists(self.opts.output):\n",
    "            os.makedirs(self.opts.output)\n",
    "        save_path = os.path.join(self.opts.output, file_name.replace(name, \"%s_URetinexNet\"%(name)))\n",
    "        np_save_TensorImg(enhance, save_path)  \n",
    "        print(\"================================= time for %s: %f============================\"%(file_name, p_time))\n",
    "\n",
    "#         add to own function for input of img path\n",
    "def retinexImplement(img, outPath):\n",
    "    parser = argparse.ArgumentParser(description='Configure')\n",
    "    \n",
    "    # specify your data path here!\n",
    "    parser.add_argument('--img_path', type=str, default=img)\n",
    "    parser.add_argument('--output', type=str, default=outPath)\n",
    "    # ratio are recommended to be 3-5, bigger ratio will lead to over-exposure \n",
    "    parser.add_argument('--ratio', type=int, default=5)\n",
    "    # model path\n",
    "    parser.add_argument('--Decom_model_low_path', type=str, default=\"./URetinex_Net/ckpt/init_low.pth\")\n",
    "    parser.add_argument('--unfolding_model_path', type=str, default=\"./URetinex_Net/ckpt/unfolding.pth\")\n",
    "    parser.add_argument('--adjust_model_path', type=str, default=\"./URetinex_Net/ckpt/L_adjust.pth\")\n",
    "    parser.add_argument('--gpu_id', type=int, default=0)\n",
    "    \n",
    "#     opts = parser.parse_args() change parse_args() to parse_known_args\n",
    "    opts, _ = parser.parse_known_args()\n",
    "    for k, v in vars(opts).items():\n",
    "        print(k, v)\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(opts.gpu_id)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = Inference(opts)\n",
    "        print(\"CUDA (GPU) is available\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Loading the model on CPU...\")\n",
    "        model = Inference(opts).to(torch.device('cpu'))\n",
    "    \n",
    "#    \n",
    "    model.run(opts.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679d8739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:42:43.934591Z",
     "start_time": "2023-10-24T16:42:43.931026Z"
    }
   },
   "outputs": [],
   "source": [
    "# evalData_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e4da41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T16:45:21.709653Z",
     "start_time": "2023-10-24T16:43:11.661276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_0_0.jpg\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illuminance: 0.29567792373263885\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_0_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_0_0.jpg: 3.437191============================\n",
      "Illuminance: 0.516026363376736\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020EEC4FFCE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_15_0.jpg\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020EED55AE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Illuminance: 0.2929762817534723\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_15_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_15_0.jpg: 3.615767============================\n",
      "Illuminance: 0.513045514422743\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_30_0.jpg\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "Illuminance: 0.29606498448350704\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_30_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_30_0.jpg: 3.649661============================\n",
      "Illuminance: 0.5178306256293403\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_45_0.jpg\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Illuminance: 0.2991066410894097\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_45_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_45_0.jpg: 3.554091============================\n",
      "Illuminance: 0.5205153679947918\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_60_0.jpg\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Illuminance: 0.29778815756076393\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_60_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_60_0.jpg: 3.456750============================\n",
      "Illuminance: 0.5188656798350694\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_75_0.jpg\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Illuminance: 0.29540649650173617\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_75_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_75_0.jpg: 3.740395============================\n",
      "Illuminance: 0.5162518392838541\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_90_0.jpg\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "Illuminance: 0.2979124167057292\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_90_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_90_0.jpg: 3.613254============================\n",
      "Illuminance: 0.5190531985807292\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_105_0.jpg\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Illuminance: 0.29994796240885413\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_105_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_105_0.jpg: 3.552177============================\n",
      "Illuminance: 0.5218593519053819\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_120_0.jpg\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "Illuminance: 0.29637356141927085\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_120_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_120_0.jpg: 3.545668============================\n",
      "Illuminance: 0.5163899465885416\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_135_0.jpg\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Illuminance: 0.2969686096050347\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_135_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_135_0.jpg: 3.631787============================\n",
      "Illuminance: 0.5168914892708333\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_150_0.jpg\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Illuminance: 0.2955887041015627\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_150_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 5\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_150_0.jpg: 3.681041============================\n",
      "Illuminance: 0.5162052219791669\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_165_0.jpg\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "Illuminance: 0.2953554853255209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainingData_prep()\n",
      "Cell \u001b[1;32mIn[4], line 57\u001b[0m, in \u001b[0;36mtrainingData_prep\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(videos_file)\n\u001b[0;32m     56\u001b[0m training_video_paths\u001b[38;5;241m.\u001b[39mappend(video_path)\n\u001b[1;32m---> 57\u001b[0m frame_capture(video_path)\n",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m, in \u001b[0;36mframe_capture\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     88\u001b[0m trainFileNames\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_file)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m     89\u001b[0m trainLandmarks\u001b[38;5;241m.\u001b[39mappend(generateLandmarks(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(img_file) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_file)))\n\u001b[1;32m---> 90\u001b[0m trainIllumsRaw\u001b[38;5;241m.\u001b[39mappend(illuminanceEstimation(img_file))\n\u001b[0;32m     92\u001b[0m retSave_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/RetTraining/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m parentDir[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m retinexImplement(img_file, retSave_path)\n",
      "Cell \u001b[1;32mIn[7], line 728\u001b[0m, in \u001b[0;36milluminanceEstimation\u001b[1;34m(input_img)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;66;03m# # Perform rgb guided super-resolution:\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;66;03m#hrci = lrci # for testing of estimation code\u001b[39;00m\n\u001b[0;32m    727\u001b[0m     tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 728\u001b[0m     hrhsi_est \u001b[38;5;241m=\u001b[39m get_superresolution_hsi(lrhsi, hrci, CSF \u001b[38;5;241m=\u001b[39m _CSF_NIKON_D700, wl \u001b[38;5;241m=\u001b[39m wlr)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m#     print('Elapsed time (s): {:1.4f}'.format(time.time() - tic))\u001b[39;00m\n\u001b[0;32m    730\u001b[0m     hrci_est \u001b[38;5;241m=\u001b[39m hsi_to_rgb(hrhsi_est, spd \u001b[38;5;241m=\u001b[39m eew, cieobs \u001b[38;5;241m=\u001b[39m cieobs, wl \u001b[38;5;241m=\u001b[39m wlr, linear_rgb \u001b[38;5;241m=\u001b[39m linear_rgb)\n",
      "Cell \u001b[1;32mIn[7], line 638\u001b[0m, in \u001b[0;36mget_superresolution_hsi\u001b[1;34m(lrhsi, hrci, CSF, wl, csf_based_rgb_rounding, interp_type, k_neighbours, verbosity)\u001b[0m\n\u001b[0;32m    636\u001b[0m lrhsi_2d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((wlr,np\u001b[38;5;241m.\u001b[39mreshape(lrhsi,(lrhsi\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mlrhsi\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],lrhsi\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))) \u001b[38;5;66;03m# create 2D rfl database\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CSF \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: CSF \u001b[38;5;241m=\u001b[39m _CSF_NIKON_D700\n\u001b[1;32m--> 638\u001b[0m hrhsi \u001b[38;5;241m=\u001b[39m render_image(hrci, spd \u001b[38;5;241m=\u001b[39m eew,\n\u001b[0;32m    639\u001b[0m                      refspd \u001b[38;5;241m=\u001b[39m eew, rfl \u001b[38;5;241m=\u001b[39m lrhsi_2d, D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    640\u001b[0m                      interp_type \u001b[38;5;241m=\u001b[39m interp_type, k_neighbours \u001b[38;5;241m=\u001b[39m k_neighbours,\n\u001b[0;32m    641\u001b[0m                      verbosity \u001b[38;5;241m=\u001b[39m verbosity, show \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(verbosity),\n\u001b[0;32m    642\u001b[0m                      CSF \u001b[38;5;241m=\u001b[39m CSF, csf_based_rgb_rounding \u001b[38;5;241m=\u001b[39m csf_based_rgb_rounding) \u001b[38;5;66;03m# render HR-hsi from HR-ci using LR-HSI rfls as database        \u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hrhsi\n",
      "Cell \u001b[1;32mIn[7], line 477\u001b[0m, in \u001b[0;36mrender_image\u001b[1;34m(img, spd, rfl, out, refspd, D, cieobs, cspace, cspace_tf, CSF, interp_type, k_neighbours, show, verbosity, show_ref_img, stack_test_ref, write_to_file, csf_based_rgb_rounding)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_hyp\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Create hyper_spectral image:\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     rfl_image_2D \u001b[38;5;241m=\u001b[39m rfl_est[rgb_indices\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;66;03m# create array with all rfls required for each pixel\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m     img_hyp \u001b[38;5;241m=\u001b[39m rfl_image_2D\u001b[38;5;241m.\u001b[39mreshape(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],rfl_image_2D\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    480\u001b[0m \u001b[38;5;66;03m# Setup output:\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_hyp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainingData_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8df106c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T17:01:12.383036Z",
     "start_time": "2023-10-23T17:01:09.784468Z"
    }
   },
   "outputs": [],
   "source": [
    "# requires images converted to feature array\n",
    "\n",
    "# base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.MeanSquaredError(),\n",
    "#               metrics=[tf.keras.metrics.Accuracy(),\n",
    "#                        tf.keras.metrics.Precision(),\n",
    "#                        tf.keras.metrics.Recall(),\n",
    "#                        tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8e4c5e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:41.371198Z",
     "start_time": "2023-10-24T17:31:40.959692Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_81 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)         1792      ['input_81[0][0]']            \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)         36928     ['block1_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)         0         ['block1_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)        73856     ['block1_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)        147584    ['block2_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)          0         ['block2_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)          295168    ['block2_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)          590080    ['block3_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)          590080    ['block3_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)          0         ['block3_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)          1180160   ['block3_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)          2359808   ['block4_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)          2359808   ['block4_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)          0         ['block4_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)          2359808   ['block4_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)          2359808   ['block5_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)          2359808   ['block5_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)            0         ['block5_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " additional_dense (Dense)    (None, 7, 7, 64)             32832     ['block5_pool[0][0]']         \n",
      "                                                                                                  \n",
      " illuminance_retinex_output  (None, 7, 7, 1)              65        ['additional_dense[0][0]']    \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " landmark_output (Dense)     (None, 7, 7, 1)              65        ['additional_dense[0][0]']    \n",
      "                                                                                                  \n",
      " previous_illuminance_outpu  (None, 7, 7, 1)              65        ['additional_dense[0][0]']    \n",
      " t (Dense)                                                                                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14747715 (56.26 MB)\n",
      "Trainable params: 14747715 (56.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "additional_dense_layer = tf.keras.layers.Dense(64, activation='relu', name='additional_dense')(base_model.output)\n",
    "\n",
    "task_outputs = {\n",
    "    'landmark_detection': tf.keras.layers.Dense(1, activation='relu', name='landmark_output')(additional_dense_layer),\n",
    "    'previous_illuminance': tf.keras.layers.Dense(1, activation='relu', name='previous_illuminance_output')(additional_dense_layer),\n",
    "    'illuminance_retinex': tf.keras.layers.Dense(1, activation='relu', name='illuminance_retinex_output')(additional_dense_layer)\n",
    "}\n",
    "\n",
    "inputData = [trainLandmarks, trainIllumsRaw, trainIllumsRet]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'landmark_output': 'mean_squared_error',\n",
    "        'previous_illuminance_output': 'mean_squared_error',\n",
    "        'illuminance_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'landmark_output': 'mse', \"accuracy\"\n",
    "        'previous_illuminance_output': 'mse', \"accuracy\" \n",
    "        'illuminance_retinex_output': 'mse' \"accuracy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "65c7b7d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:42.244818Z",
     "start_time": "2023-10-24T17:31:42.070504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAfXCAYAAAAg6tXPAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdTWwc55kn8Kesj1kMNnGA2NJkNrEAQ6OMsYCVgYFAmoMFWwIWMba0F4v6sOggGFlDYWPAu/JhIDShgw34sNKODlmIIHcOgjHmh31iw/YsYCqID1bPQQZ5EAZyMoLIiWanezJYMgYWiLV27UFTbTbZJLvJVnVT+v2AhsXqt6qf9y2GrH/qrZdJlmVZAAAAcF890u0CAAAAHgbCFwAAQAGELwAAgAIIXwAAAAXY2u0CAHrdtWvX4r//9//e7TKgcP/1v/7X2L9/f7fLAHhguPMFsIZ/+Id/iPfee6/bZTyQKpVKVCqVbpdBE++99178wz/8Q7fLAHiguPMF0KJ333232yU8cI4cORIRxrYXJUnS7RIAHjjufAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAPfB4OBgDA4OdrsMAKCHCF8AD6CFhYVIkmRd+5bL5Th8+HAkSRKHDx+OsbGxZceuVCoxMjIShw8f7kS5LUuSpOmraEvHt1fqAqC3be12AQAPojfeeKOrn//xxx+va7+LFy/G66+/HtPT0zE5ORkzMzPxgx/8IO7cuRNnz56NiIgLFy5ERMSbb77ZsXpblWVZLCwsxLe+9a2IiJifn49HH3208DqWjm+WZVGr1WLnzp1drQuA3ubOF8ADZmFhIUZGRta17+uvvx4REXv37m347y9+8Yt6mzfeeKOr4XJxqOlGwFlpfHfs2FH/t+AFQDPCF0CH1Wq1GBsba5iSt3RbuVyuT+ubm5urt8mn/EVEjIyMRJIkcebMmfjss88iIppOaVu67cKFC1Eulxvea1V+V6tSqURE1Gvr9p28tWyW8c3lAS7ff3BwMGq1Wly8eLHh8y5evFjfZ/F7i/uUbz98+HBcvXp1WV8XFhbizJkznkEE6AUZAKsaHx/P2vlxmaZpFhEN+yzedu3atSzLsmx2djaLiGxgYCDLsqz+/uI28/Pz2cDAQBYR2c2bN7Nqtbrs2PlxFm9b+nU7SqVSvYbR0dGsWq02bbeRz8i9+OKL2Ysvvtj2fr06vq2OSf6Z1Wp1WZ3Xrl1r+HqxNE3r56NarWZpmmajo6NZlmXZ1NRUFhHZ9PT0svGYnp5uerzVREQ2Pj7e1j4ArE74AlhDu+Ery5pfhLeyrVmb6enpLCKyCxcubOg47cjDQalUyubn55u26aXw1eq2+z2+rY5JqVRqCENL97tw4UIWEdns7GxDnXnQyrIsGx0dbVpnqVRqOOZK528twhdA55l2CNDj8ueu8uex7reLFy/GgQMHYn5+PiIi+vv7Y2FhoZDP7oaixzfi3jTOy5cvx9zcXMPUwtyhQ4ciIuJ//a//Vd/20UcfxZ/+6Z/Wv37nnXciYvm0yKULoXj+DKB3CF8A1I2NjcXrr78eP/rRj+LRRx+N/v7+KJfLMTEx0e3SHjgjIyPx05/+NNI0Xfbe3r17Y2BgIE6fPh0LCwuxsLAQv/rVr+KJJ56ot8mfO8vuzWJpeAHQm4QvgE1iYGDgvn/G8ePHI+LruyX50umnT5++75/dbUWM75kzZyLiXsg9ffp0/OxnP4s9e/asWs+HH34YH3/8cfz4xz9u2i5fLASA3id8AfS4/OL6hRdeuO+ftfQuTB7Cmt2deVAUNb6VSiUOHDgQEV+H3MV3spbK734dP348RkZGYt++fQ3vDw8PR0TE22+/XZ8Wmq9+CEBvEr4AOqxWqy379+Jt+YXy4ueoFr8fce/OSN7m7bffjjRN6wEovyOSh4Z8WfiIr++s5G3bvRh/7bXXGj4/P3a+fWkflv67CM0+uxfGd+lnLFapVGL//v3x1FNPNew/NzfXcOdq6THyu13Nwu9/+k//KSLuPeP1rW99K5IkiZ07d8aRI0dWrQWALurqch8Am0C7qx3GoiXN8/3a3bZ4ufDh4eGGFetmZ2fr701OTmZZltWXHM+XIc9X8CuVSisuFb+Sqamp+mqHAwMD2dTU1Kr9W1x/u9pd7XClz+72+LZaV/45S/fPVz9cvLphLk3T7ObNm03HY3Z2tv6nARbvv/gz0zRteXyXjrXVDgE6K8kyT+YCrGZiYiKOHj1ayEIG+Yp1D8uP5iNHjkRExLvvvlvI52228V1YWIi/+Iu/iMuXLxf+2UmSxPj4ePT19RX+2QAPKtMOAaBHTUxM1AMqAJuf8AXQI5o9K0bnbJbxHRwcrP/drrm5uXj++ee7XRIAHbK12wUAcE++rHv+705Ojcun261ls0zHW4/7Ob6dlK+AODw8HK+88kqXqwGgk4QvgB5xP8NArwaNIm2WMXjllVeELoAHlGmHAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFCArd0uAGCzOHLkSLdLeOBUKpWIMLYAPByEL4A1fO9734sXX3yx22U8kPbt27fq+3/3d38XERFPPfVUEeWwyIsvvhjf+973ul0GwAMlybIs63YRANBMX19fRERMTEx0uRIA2DjPfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUIMmyLOt2EQDw13/91/FXf/VX8dVXX9W33bx5MyIivv/979e3PfLII/Fnf/Zn8dJLLxVeIwBshPAFQE+YmZmJH/zgBy21nZ6ejr17997nigCgs4QvAHrGH//xH9fvdq1k9+7d8ctf/rKgigCgczzzBUDP6O/vj23btq34/rZt2+InP/lJgRUBQOe48wVAz7h161bs3r07VvvV9Mtf/jJ2795dYFUA0BnufAHQM5588sn4kz/5k0iSZNl7SZLEM888I3gBsGkJXwD0lJdffjm2bNmybPuWLVvi5Zdf7kJFANAZph0C0FNqtVp85zvfaVhyPuLeEvN37tyJP/iDP+hSZQCwMe58AdBTduzYEc8++2zD3a8tW7bEgQMHBC8ANjXhC4Ce09/f39I2ANhMTDsEoOf89re/jcceeyzu3r0bEfeWmK/VavGtb32ry5UBwPq58wVAz/nmN78ZP/rRj2Lr1q2xdevWeOGFFwQvADY94QuAnnTy5Mn48ssv48svv4yXXnqp2+UAwIZt7XYBAN02MTHR7RJo4u7du7F9+/bIsix+97vfOU89qq+vr9slAGwanvkCHnrN/qAv0BqXEQCtM+0QICLGx8cjyzKvHnt9+OGH8Td/8zcdPabz3ZnX+Ph4l/9XC7D5mHYIQM86dOhQt0sAgI4RvgDoWVu3+jUFwIPDtEMAAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AmhDrVaLsbGxOHz48Iba3K/PBgB6l/AF0Ibz58/H8ePHo1wub6jNepw6daql4y4sLESlUomRkZEHJqj1Sp8qlUoMDg5GkiSRJEkMDg7GzMxM1Gq1SJKk8Hrm5ubizJkzkSRJnDlzJq5evdrwfl5ns9fFixejXC7HwsJC4XUDPKyEL4A2XL58uSNt1mNycrKldhcuXIj3338/Tp8+3fEA2C290KfBwcG4cuVK9Pf3R5ZlkWVZvPrqqzE3Nxc7d+4svJ6FhYWYmZmJy5cvx/z8fBw4cCAOHjzYMD5ZlkW1Wq1/PT8/X6/90KFDMTIyEv39/VGr1QqvH+BhlGRZlnW7CIBuSpIkxsfHo6+vr+X2EfcubDfSZj3aOe79qqGbOtGnds93RNTvcK0UgCuVSuzfv7/QsS6Xy5GmacO2lcZnpe21Wi1OnToVERFvv/12PProoy1//sTERBw9evSB+v4CuN/c+QJYp1qtFhcvXqxP+Zqbm1tzn4WFhRgbG6tP/RoZGVl216FZm5VcvXq1YSpZp61Vy2r9WfqMWrlcjiRJ4vDhwzE3NxeVSmXZVLhcPq5JkrQ0rvdTpVKJN998M86dO7dim3379jV8XcS47N27t2ktAwMDLfdtx44d8dprr0W5XI6PP/645f0AWB/hC2Cdbt26FWfPno1qtRp37tyJXbt2rTl9q7+/Pz7//PP6dLByuRynTp1qeO6mv78/bty4UZ8e9umnn8bg4GDT4+3evTuGh4ejWq3elzsQa9WyWn8WP6NWqVQiTdOYnZ2Ncrkcb731Vuzbty+mpqYiIqJUKjXUf/bs2SiVSjE9PR1PPPFEx/vVjvfffz8iIp588slV2y2uvxvjkn8PvfDCC23175lnnomIiA8++KCt/QBYhwzgIRcR2fj4eFvtl/74vHnzZhYR2fDw8IptpqamsojIqtVqfdu1a9eyiMhGR0ezLMuy0dHRpm3SNF123Onp6fp+rdbZjrVqaaU/zWpYuq1UKmURkc3Pz9e3zc/PZ6VSqeN9yo+x0fO9mm6MS/65aZo2tG+1D+sZ1/Hx8Q2fC4CHjTtfAB2wZ8+eiIg4ffr0im3efffdiLg31Sv31FNPRUTEO++80/DfxW327du37FmjSqUSQ0NDcezYsQ5U39xatbTSn1a8+OKLERHx4Ycf1rddv369vn2z6da4XLp0Kc6dO9fWc1sAFEv4AijI0NDQsm35hXK+Ql2rK/ndvn07hoaGolKpdK7AJdaqpZX+tGLv3r2RpmlDMPn5z3++4jNNRcufoWp1SfZujMvY2Fikabrs2bNW5P0qlUpt7wtAe4QvgA5abbGDfGW6Zs+F5fvlbWZmZlb9nGPHjkWpVIr9+/fft2XC16qllf606sSJE/VnoObm5uKHP/xhm9XeP/kzVLdv326pfdHjMjMzEzdu3IhXXnmlrWPnrl+/HhERzz333Lr2B6B1whdAB+QB5cCBAyu2OXHiRETcW6gjl991OHLkSER8feE+NDRUfy//Q7pLvf7665GmaZw/f74DPVhurVpa6U+rnn/++YiIuHLlSnzyySfx7LPPbqz4DkrTNNI0bXpHKzc3NxcXL16MiGLHpVarxUcffRRvvPFGfdvMzEzT75dmarVaXLp0KdI0rX8WAPdRtx86A+i2aHMBhjRNs4jIpqamsizLsmq1mqVpml24cKH+dfzrAgaLF12Yn5/P0jTN0jStbx8dHc0GBgbqbfJj5ftHRDYwMJDdvHmz4bj5ogqzs7MNC30s/qylbdu1Wi2t9KdZvYvrWjw2Wfb1AhP5OC7ViT5lWfvnO8u+HovF/c/Nzs42jEFR49Ls/OSvycnJeruVxm16enpZne2w4AZA+/zUBB5667kYz1eWywNJHsTy4y1+LVatVrPh4eH6e6Ojo8uCRLVarV9wl0ql+sV+s+PmK+st3tbsYny9F8kr1dJKf5p9/mo1TU9PZxGx7DM63af1nO8suxdiJicns4GBgfrnp2maDQ8PZ7Ozsw1tixiXxXUsfa30PbP4deHChezatWttj0NO+AJoX5Jl/jQ98HBLkiTGx8ejr6+v26VQAOe7MyYmJuLo0aP35e/LATyoPPMFAABQAOELAACgAFu7XQAAxUqSpKV2ppMBQGcJXwAPGaEKALrDtEMAAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKMDWbhcA0AuuXbvW7RIokPO9ccYQoH1JlmVZt4sA6KYkSbpdAmxaLiMAWufOF/DQc/HYu/r6+iIiYmJiosuVAMDGeeYLAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoABbu10AAERE/O3f/m3MzMw0bLt161ZERAwPDzdsf/rpp2Pfvn2F1QYAnSB8AdATarVa/Pmf/3ls2bIlHnnk3sSMLMsiIuKnP/1pRER89dVX8eWXX8bk5GTX6gSA9Uqy/DcbAHTR3bt347HHHovf/va3q7b7xje+Eb/5zW9i+/btBVUGAJ3hmS8AesK2bdvi2LFjq4aqbdu2xfHjxwUvADYl4QuAnnH8+PH44osvVnz/7t27ceLEiQIrAoDOMe0QgJ7x1VdfxR/+4R9GtVpt+v7jjz8e//RP/1R/JgwANhO/vQDoGY888kicPHmy6bTC7du3x49//GPBC4BNy28wAHrKSlMPv/jiizh+/HgXKgKAzjDtEICes3v37vj7v//7hm27du2K27dvd6cgAOgAd74A6DknT56Mbdu21b/evn17/OQnP+liRQCwce58AdBzfvWrX8Uf/dEfNWy7efNm7Nmzp0sVAcDGufMFQM/ZvXt3PP3005EkSSRJEk8//bTgBcCmJ3wB0JNefvnl2LJlS2zZsiVefvnlbpcDABtm2iEAPekf//Ef43vf+15kWRZzc3Px3e9+t9slAcCGCF/AQy9Jkm6XAJuWywiA1m3tdgEAveC1116L/fv3d7sMlvjoo48iSZI4ePBgx4559OhR57sDrl27FpcuXep2GQCbijtfwEMvSZIYHx+Pvr6+bpfCEv/yL/8SERHf/va3O3ZM57szJiYm4ujRo+58AbTBnS8AelYnQxcAdJvVDgEAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXQBtqtVqMjY3F4cOHN9Tmfn02ANC7hC+ANpw/fz6OHz8e5XJ5Q23W49SpUy0dd2FhISqVSoyMjDwwQW1ubi7OnDkTSZLEmTNn4urVq12po1KpxODgYCRJEkmSxODgYMzMzEStVoskSQqvZ61xyets9rp48WKUy+VYWFgovG6Ah5XwBdCGy5cvd6TNekxOTrbU7sKFC/H+++/H6dOnOx4Au2FhYSFmZmbi8uXLMT8/HwcOHIiDBw8W3rfBwcG4cuVK9Pf3R5ZlkWVZvPrqqzE3Nxc7d+4stJaI1sYly7KoVqv1r+fn5+u1Hzp0KEZGRqK/vz9qtVrh9QM8jJIsy7JuFwHQTUmSxPj4ePT19bXcPuLehe1G2qxHO8e9XzUUrVwuR5qmDds20rd2z3dE1O9wrRSAK5VK7N+/v9CxbmdcVtpeq9Xi1KlTERHx9ttvx6OPPtry509MTMTRo0c3/fcXQJHc+QJYp1qtFhcvXqxP+Zqbm1tzn4WFhRgbG6tP/RoZGVl216FZm5VcvXq1YSpZp61Vy2r9WfqMWrlcjiRJ4vDhwzE3NxeVSmXZVLhcPq5JksTevXub1jYwMNDx/jZTqVTizTffjHPnzq3YZt++fQ1fb5Zx2bFjR7z22mtRLpfj448/bnk/ANZH+AJYp1u3bsXZs2ejWq3GnTt3YteuXWtO3+rv74/PP/+8Ph2sXC7HqVOnGp676e/vjxs3btSnh3366acxODjY9Hi7d++O4eHhqFar9+UOxFq1rNafxc+oVSqVSNM0Zmdno1wux1tvvRX79u2LqampiIgolUoN9Z89ezZKpVJMT0/HE0880VBTPlYvvPBCx/vbzPvvvx8REU8++eSq7RbXv5nG5ZlnnomIiA8++KCt/QBYhwzgIRcR2fj4eFvtl/74vHnzZhYR2fDw8IptpqamsojIqtVqfdu1a9eyiMhGR0ezLMuy0dHRpm3SNF123Onp6fp+rdbZjrVqaaU/zWpYuq1UKmURkc3Pz9e3zc/PZ6VSqWldU1NTWZqmDe3b0YnzvZpeHJe1+rCe75Xx8fENfX8BPIzc+QLogD179kRExOnTp1ds8+6770bEvaleuaeeeioiIt55552G/y5us2/fvmXPGlUqlRgaGopjx451oPrm1qqllf604sUXX4yIiA8//LC+7fr16/XtS126dCnOnTvX1vNJRTIuAKxE+AIoyNDQ0LJt+YVyvkJdqyv43b59O4aGhqJSqXSuwCXWqqWV/rRi7969kaZpQzD5+c9/3vSZprGxsUjTdNkzVvdT/gxVq0uyb7ZxyftVKpXa3heA9ghfAB202mIH+cp0zZ4Ly/fL28zMzKz6OceOHYtSqRT79++/b8uEr1VLK/1p1YkTJ+rPQM3NzcUPf/jDZW1mZmbixo0b8corr7R17I3Kn6G6fft2S+0327hcv349IiKee+65de0PQOuEL4AOyAPKgQMHVmxz4sSJiLi3UEcuv+tw5MiRiPj6wn1oaKj+Xv6HdJd6/fXXI03TOH/+fAd6sNxatbTSn1Y9//zzERFx5cqV+OSTT+LZZ59teL9Wq8VHH30Ub7zxRn3bzMxM03HptDRNI03Tpne0cnNzc3Hx4sWI2FzjUqvV4tKlS5Gmaf2zALiPuv3QGUC3RZsLMKRpmkVENjU1lWVZllWr1SxN0+zChQv1r+NfFzBYvOjC/Px8lqZplqZpffvo6Gg2MDBQb5MfK98/IrKBgYHs5s2bDcfNF1WYnZ1tWOhj8Wctbduu1WpppT/N6l1c1+KxybKvF5jIx3G1OvLX5ORk2/1q93wvrmFx/3Ozs7MNY9Br47LS98L09PSyOtthwQ2A9vmpCTz01nMxnq8slweSPIjlx1v8WqxarWbDw8P190ZHR5eFo2q1Wr/gLpVK9Yv9ZsfNV9ZbvK3Zxfh6L5JXqqWV/jT7/NVqmp6eziJi2WcMDAys2KelbVuxnvOdZfdCzOTkZEM9aZpmw8PD2ezsbEPbXhmXld7Pw9y1a9faHoec8AXQviTL/Gl64OGWJEmMj49HX19ft0uhAM53Z0xMTMTRo0fvy9+XA3hQeeYLAACgAMIXAABAAbZ2uwAAipUkSUvtTCcDgM4SvgAeMkIVAHSHaYcAAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUIAky7Ks20UAdFOSJN0uATYtlxEArdva7QIAum18fLzbJbCCv/zLv4yIiP/yX/5LlysBgI1z5wuAntXX1xcRERMTE12uBAA2zjNfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAJs7XYBABAR8X//7/+N3/3udw3bvvjii4iI+D//5/80bP+93/u9+P3f//3CagOATkiyLMu6XQQA/I//8T/ipz/9aUttf/azn8V//s//+T5XBACdJXwB0BP++Z//Ob7zne/El19+uWq7LVu2xP/+3/87Hn/88YIqA4DO8MwXAD3h8ccfj+effz62bNmyYpstW7bEwYMHBS8ANiXhC4CecfLkyVhtQkaWZXHy5MkCKwKAzjHtEICe8fnnn8fjjz++bOGN3Pbt2+Of//mf45vf/GbBlQHAxrnzBUDP+MY3vhH/8T/+x9i2bduy97Zu3RqHDx8WvADYtIQvAHrKSy+9FP/v//2/Zdu//PLLeOmll7pQEQB0hmmHAPSUL774Ih577LH4/PPPG7b/23/7b+M3v/lN/N7v/V6XKgOAjXHnC4Cesn379njxxRdj+/bt9W3btm2Lvr4+wQuATU34AqDnnDhxIr744ov613fv3o0TJ050sSIA2DjTDgHoOV999VXs3LkzfvOb30RExLe//e2oVqur/g0wAOh17nwB0HMeeeSReOmll2L79u2xbdu2OHnypOAFwKYnfAHQk44fPx5ffPGFKYcAPDC2drsAgHYdOXKk2yVQkN///d+PiIj/9t/+W5croSjvvvtut0sAuG/c+QI2nffeey9+/etfd7sM1qmd87dr167YtWvXfa6IXvDrX/863nvvvW6XAXBfWXAD2HSSJInx8fHo6+vrdimsQzvn78aNGxER8e///b+/32XRZRMTE3H06NFwWQI8yEw7BKBnCV0APEhMOwQAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfwAOtVqvF2NhYHD58eENt7tdnb0YPar96yUpjPDg4GIODg12qCoCNEr6AB9r58+fj+PHjUS6XN9RmPU6dOtXScRcWFqJSqcTIyMimCDT3a7yaSZKk4VWpVFZsW6lUlrW/X3Xkr8OHD8fIyEjUarWOfVZEsWOcm5ubizNnzkSSJHHmzJm4evVqw/srjUGSJHHx4sUol8uxsLBQWL0Am5HwBTzQLl++3JE26zE5OdlSuwsXLsT7778fp0+fLvRie73u13g1k2VZzM7O1r++cuXKim0Xv1etViPLso7WUXNsx2UAACAASURBVK1WG77Osix+9rOfxdzcXOzcuTM+++yzjn3eSmP8xhtvxBtvvNGxz8ktLCzEzMxMXL58Oebn5+PAgQNx8ODBhu/HpWMwPz9fH4dDhw7FyMhI9Pf3dzyIAjxIhC+ALrtfF9QPiieeeCIi7oXUoaGhmJubW9Zmbm4udu/eXf96x44dHa+j2TGfeOKJePXVVyMi4i//8i87/plF+fjjjyNN04iIePTRR+PYsWMREcvuxC4eg0cffbT+771798b//J//MyLu3fF1BwygOeELeGjUarW4ePFifVpVs4v4pRYWFmJsbKw+varZFLNmbVZy9erV+zItrlarRblcrl8sj4yM1Pu59I7MevvU7Tsahw4dioiITz75ZNl7n3zySf39ZhYWFupjkiRJDA4O1vvTbKpiO9MX80AyNDTU8HmdHuNmz4Et3VYul+vTIZd+f1+9ejUOHz5cnya4+LPy4LXUwMDAqn1fbMeOHfHaa69FuVyOjz/+uOX9AB4mwhfw0Lh161acPXs2qtVq3LlzJ3bt2rVmoOjv74/PP/+8PuWqXC4v+3/2+/v748aNG/UpWJ9++umKiyLs3r07hoeHOz4tbufOnXH48OEol8tRqVTilVdeifn5+YiI+P73v98QwFrt01ptirZ3794YGBiI48ePL3vvF7/4Rezdu3fFff/iL/4iTp8+HdVqNWZnZ+PNN9+M8+fPR8S96XTDw8MREfVpddVqNdI0jenp6TXPUz4mi4PK/RjjZs8QLt5WqVQiTdOYnZ2Ncrkcb731Vr1duVyOgwcPxrlz5yLLsvh3/+7fxc6dO1cMl3kNL7zwwqp9X+qZZ56JiIgPPvigrf0AHhoZwCYTEdn4+Hhb7Zf+uLt582YWEdnw8PCKbaamprKIyKrVan3btWvXsojIRkdHsyzLstHR0aZt0jRddtzp6en6fq3W2Y5m+09PT2cRkV24cKHlPrXSZiO1tnv+8n0W13bt2rWGPk5NTa1aV6lUygYGBhqOt7TdwMBAvd8XLlxo6P/S/aanp7Msy7L5+fmsVCo11HQ/x3i921Zqk39fLDU1NZWlaZrNz8+vOAYrWe/3xvj4+Ia+/wE2Az/lgE2nE+Fr6fbVLsYXm5+fzyKiHq7SNG3pQvTatWsNF//t1NmqVvrZSp9aadOt8JX/e/FYlkqlhvdWq2t2dja7cOFC03bVarXex5s3b65Yx9JXqVSqh7Esu79jvN5tzT5vtbFK07Qh4La6Xyvvr0T4Ah4GfsoBm05R4Wu9+zVrm98hW+mCtpVjrWUj9XaqTat1biR85WM5OzubVavVhruJq9U1PDxcD1YrtVvrPLXS7/s5xuvdlt8Bzcdq6R3RxUZHR+t3hNvpX5Z9HSAXB+JWCV/Aw8AzX8BDbbUFBfJFCJo9F5bvl7eZmZlZ9XOOHTsWpVIp9u/f35WFK5bW20qfVmvTTX/6p38aEfcW2bh69Wr969WMjY3F6dOn42c/+1ns2bOnaZtarRZ37tyJCxcubOg89eIY7927NyYnJ+POnTv1BUdGR0fj7NmzDe1mZmbixo0b8corr6zrc65fvx4REc8999yGawZ4EAlfwEMpD0sHDhxYsc2JEyci4t5CHbl8IYIjR45ExNcX0UNDQ/X38j9Wu9Trr78eaZrWF3ooQr7QRr5wQit9aqVNNz3xxBNRKpXi+PHjcefOnfpS9KvJF+lYre3bb78dZ8+ejVOnTm3oPPXiGJfL5Xj22Wfj7NmzkWVZTE5O1peTz9Vqtfjoo48a/uzBzMxM0+/lZmq1Wly6dCnSNI3nn3++o/UDPDC6fesNoF3R5rS1/LmsfFGGarWapWlan3KVP+sT0bgAwvz8fJamaZamaX376Ohow/NG+bHy/eNfn0e6efNmw3HzhQtmZ2eziFg2rSufrrW47XrGJRZNLcsXg8ifIWq1T2u1WWm82qmznfOXf97iz8qnzS1+1mq1uvJzNDs72zDtsFqt1sdp8bg3mz63+Byt1u/7NcZrbcvrb1bn4u/Ppd+r1Wq16fdx/pqcnGw6BovHa3p6ell/2mXaIfAw8FMO2HTavXjPsq9Xb8svOPMglh9v8WuxarWaDQ8PNwSbpeGoWq3WV7wrlUr1xRqaHTdf5W7xtpUujNczLnkgyfs6PDzctN5W+rRSm07U2er5W21cmq1euFLbPKyVSqX6+RoYGKiH4aXtVzpeq32/H2O8kW2LvyeaBbB8QY5mr5W+nxe/Lly4sOrzjK0QvoCHQZJlHfxDMwAFSJIkxsfHo6+vr9ul9JT87zX1+o915694n332Wfybf/Nvlk27/Oyzz+L73/9+T3zPTExMxNGjR3uiFoD7xTNfAPAAGxsbiz179jR93m3nzp0xOjrahaoAHk5bu10AABu3eNW8Wq0WO3bs6GI19JJ33nknPv/88/gP/+E/NASwzz77LH7xi1+se2VDANrnzhdAj0uSZM3Xzp076+0X/xvefvvt+MY3vhFvvfVW/ftlcHAwfv3rXwteAAVz5wugx3kGho149NFH49ixY3Hs2LG4fPlyt8sBeKi58wUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABUiyLMu6XQRAO5IkiX379sV3v/vdbpfCOrz33nvOH8v8+te/jkqlEi5LgAeZ8AVsOkeOHOl2CRTk7/7u7yIi4qmnnupyJRTl3Xff7XYJAPeN8AVAz+rr64uIiImJiS5XAgAb55kvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIkWZZl3S4CAP76r/86/uqv/iq++uqr+rabN29GRMT3v//9+rZHHnkk/uzP/ixeeumlwmsEgI0QvgDoCTMzM/GDH/ygpbbT09Oxd+/e+1wRAHSW8AVAz/jjP/7j+t2ulezevTt++ctfFlQRAHSOZ74A6Bn9/f2xbdu2Fd/ftm1b/OQnPymwIgDoHHe+AOgZt27dit27d8dqv5p++ctfxu7duwusCgA6w50vAHrGk08+GX/yJ38SSZIsey9JknjmmWcELwA2LeELgJ7y8ssvx5YtW5Zt37JlS7z88stdqAgAOsO0QwB6Sq1Wi+985zsNS85H3Fti/s6dO/EHf/AHXaoMADbGnS8AesqOHTvi2Wefbbj7tWXLljhw4IDgBcCmJnwB0HP6+/tb2gYAm4lphwD0nN/+9rfx2GOPxd27dyPi3hLztVotvvWtb3W5MgBYP3e+AOg53/zmN+NHP/pRbN26NbZu3RovvPCC4AXApid8AdCTTp48GV9++WV8+eWX8dJLL3W7HADYsK3dLgCg2yYmJrpdAk3cvXs3tm/fHlmWxe9+9zvnqUf19fV1uwSATcMzX8BDr9kf9AVa4zICoHWmHQJExPj4eGRZ5tVjrw8//DD+5m/+pqPHdL478xofH+/y/2oBNh/TDgHoWYcOHep2CQDQMcIXAD1r61a/pgB4cJh2CAAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AbajVajE2NhaHDx/eUJv79dkAQO8SvgDacP78+Th+/HiUy+UNtVmPU6dOtXTcubm5OHPmTCRJEmfOnImrV692tI5uWFhYiEqlEiMjI10Nn5VKJQYHByNJkkiSJAYHB2NmZiZqtVokSVJ4PWud67zOZq+LFy9GuVyOhYWFwusGeFgJXwBtuHz5ckfarMfk5OSabRYWFmJmZiYuX74c8/PzceDAgTh48GDHg2DRLly4EO+//36cPn26a30ZHByMK1euRH9/f2RZFlmWxauvvhpzc3Oxc+fOwutp5VxnWRbVarX+9fz8fL32Q4cOxcjISPT390etViu8foCHUZJlWdbtIgC6KUmSGB8fj76+vpbbR9y7sN1Im/VY67jlcjnSNC2klm7oRF/aPd8RUb/DtVIArlQqsX///kLHuJ1zvdL2Wq0Wp06dioiIt99+Ox599NGWP39iYiKOHj36QHxfARTFnS+AdarVanHx4sX6lK+5ubk191lYWIixsbH61K+RkZFldx2atVnJ1atXG6aSLb0Yzw0MDLTXuRZrWa0/S59RK5fLkSRJHD58OObm5qJSqSybCpfLxzVJkpbG9X6qVCrx5ptvxrlz51Zss2/fvoavixiXvXv3Nq2lnXO9Y8eOeO2116JcLsfHH3/c8n4ArI/wBbBOt27dirNnz0a1Wo07d+7Erl271py+1d/fH59//nl9Oli5XI5Tp041PHfT398fN27cqE8P+/TTT2NwcLDp8Xbv3h3Dw8NRrVab3oHIj/vCCy+sq49r1bJafxY/o1apVCJN05idnY1yuRxvvfVW7Nu3L6ampiIiolQqNdR/9uzZKJVKMT09HU888cS6au+U999/PyIinnzyyVXbLa6/G+Oy3nP9zDPPRETEBx980NZ+AKxDBvCQi4hsfHy8rfZLf3zevHkzi4hseHh4xTZTU1NZRGTVarW+7dq1a1lEZKOjo1mWZdno6GjTNmmaLjvu9PR0fb+VTE1NZWmaZvPz8y33L7dWLa30p9k4LN1WKpWyiGiocX5+PiuVSstqana8dnXifK+mG+OSf+5K53qtPqxnXMfHxzd8LgAeNu58AXTAnj17IiLi9OnTK7Z59913I+LeVK/cU089FRER77zzTsN/F7fZt2/fsmeNKpVKDA0NxbFjx1at69KlS3Hu3Lm2nuXJrVVLK/1pxYsvvhgRER9++GF92/Xr1+vbN5tujctGzjUAxRC+AAoyNDS0bFt+oZyvUNfqSn63b9+OoaGhqFQqK7YZGxuLNE2XPY/UqrVqaaU/rdi7d2+kadoQTH7+85+v+ExT0fJnqFpdkr0b47KRc533q1Qqtb0vAO0RvgA6aLXFDvLFMJo9F5bvl7eZmZlZ9XOOHTsWpVIp9u/f3/R4MzMzcePGjXjllVdarn2leleqpZX+tOrEiRP1Z6Dm5ubihz/8YZvV3j/5M1S3b99uqX3R47LRc339+vWIiHjuuefWtT8ArRO+ADogDygHDhxYsc2JEyci4t5CHbn8rsORI0ci4usL96Ghofp7+R/SXer111+PNE3j/PnzDdtrtVp89NFH8cYbbzTU1+wYq1mrllb606rnn38+IiKuXLkSn3zySTz77LNt7X8/pWkaaZo2vaOVm5ubi4sXL0ZEseOy0XNdq9Xi0qVLkaZp/bMAuI+6/dAZQLdFmwswpGmaRUQ2NTWVZVmWVavVLE3T7MKFC/Wv418XMFi86ML8/HyWpmmWpml9++joaDYwMFBvkx8r3z8isoGBgezmzZsNx80XVZidnW1Y6KPZ/vlrcnKyrXFZrZZW+tOs3vn5+aZjk2VfLzCRj+NSi/ddzwIiuXbPd5Z9PRaL+5+bnZ1tGIOixqXVc73SuE1PTy+rsx0W3ABon5+awENvPRfj+cpyeSDJg1h+vMWvxarVajY8PFx/b3R0dFmQqFar9QvuUqlUv9hvdtx8Zb3F4ajZxXhELAsNrVipllb606ze1cZmenp6xTpX6tN6rOd8Z9m9EDM5OdkwxmmaZsPDw9ns7GxD2yLGpZVzvdL7eZi7du1a2+OQE74A2pdkmT9NDzzckiSJ8fHx6Ovr63YpFMD57oyJiYk4evRo078vB0BznvkCAAAogPAFAABQgK3dLgCAYiVJ0lI708kAoLOEL4CHjFAFAN1h2iEAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFGBrtwsA6AXXrl3rdgkUyPneOGMI0L4ky7Ks20UAdFOSJN0uATYtlxEArXPnC3jouXjsXX19fRERMTEx0eVKAGDjPPMFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUADhCwAAoADCFwAAQAGELwAAgAIIXwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELAACgAMIXAABAAYQvAACAAghfAAAABRC+AAAACiB8AQAAFED4AgAAKIDwBQAAUICt3S4AACIi/vZv/zZmZmYatt26dSsiIoaHhxu2P/3007Fv377CagOAThC+AOgJtVot/vzP/zy2bNkSjzxyb2JGlmUREfHTn/40IiK++uqr+PLLL2NycrJrdQLAeiVZ/psNALro7t278dhjj8Vvf/vbVdt94xvfiN/85jexffv2gioDgM7wzBcAPWHbtm1x7NixVUPVtm3b4vjx44IXAJuS8AVAzzh+/Hh88cUXK75/9+7dOHHiRIEVAUDnmHYIQM/46quv4g//8A+jWq02ff/xxx+Pf/qnf6o/EwYAm4nfXgD0jEceeSROnjzZdFrh9u3b48c//rHgBcCm5TcYAD1lpamHX3zxRRw/frwLFQFAZ5h2CEDP2b17d/z93/99w7Zdu3bF7du3u1MQAHSAO18A9JyTJ0/Gtm3b6l9v3749fvKTn3SxIgDYOHe+AOg5v/rVr+KP/uiPGrbdvHkz9uzZ06WKAGDj3PkCoOfs3r07nn766UiSJJIkiaefflrwAmDTE74A6Ekvv/xybNmyJbZs2RIvv/xyt8sBgA0z7RCAnvSP//iP8b3vfS+yLIu5ubn47ne/2+2SAGBDhC/goZckSbdLgE3LZQRA67Z2uwCAXvDaa6/F/v37u10GS3z00UeRJEkcPHiwY8c8evSo890B165di0uXLnW7DIBNxZ0v4KGXJEmMj49HX19ft0thiX/5l3+JiIhvf/vbHTum890ZExMTcfToUXe+ANrgzhcAPauToQsAus1qhwAAAAUQvgAAAAogfAEAABRA+AIAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPAFAABQAOELoA21Wi3Gxsbi8OHDG2pzvz4bAOhdwhdAG86fPx/Hjx+Pcrm8oTbrcerUqZaOOzc3F2fOnIkkSeLMmTNx9erVjtbRDb3Sp0qlEoODg5EkSSRJEoODgzEzMxO1Wi2SJCm8nrXGJa+z2evixYtRLpdjYWGh8LoBHlbCF0AbLl++3JE26zE5Oblmm4WFhZiZmYnLly/H/Px8HDhwIA4ePNjxIFikXunT4OBgXLlyJfr7+yPLssiyLF599dWYm5uLnTt3FlpLRGvjkmVZVKvV+tfz8/P12g8dOhQjIyPR398ftVqt8PoBHkZJlmVZt4sA6KYkSWJ8fDz6+vpabh9x78J2I23WY63jlsvlSNO0kFqK0uk+tXu+I6J+h2ulAFypVGL//v2FjnE747LS9lqtFqdOnYqIiLfffjseffTRlj9/YmIijh49umm/rwC6wZ0vgHWq1Wpx8eLF+pSvubm5NfdZWFiIsbGx+tSvkZGRZXcdmrVZydWrVxumki29GM8NDAy017kWa1mtP0ufUSuXy5EkSRw+fDjm5uaiUqksmwqXy8c1SZLYu3dvR/vUrkqlEm+++WacO3duxTb79u1r+HqzjMuOHTvitddei3K5HB9//HHL+wGwPsIXwDrdunUrzp49G9VqNe7cuRO7du1ac/pWf39/fP755/XpYOVyOU6dOtXw3E1/f3/cuHGjPj3s008/jcHBwabH2717dwwPD0e1Wm16ByI/7gsvvLCuPq5Vy2r9WfyMWqVSiTRNY3Z2Nsrlcrz11luxb9++mJqaioiIUqnUUP/Zs2ejVCrF9PR0PPHEEx3tU7vef//9iIh48sknV223uP7NNC7PPPNMRER88MEHbe0HwDpkAA+5iMjGx8fbar/0x+fNmzeziMiGh4dXbDM1NZVFRFatVuvbrl27lkVENjo6mmVZlo2OjjZtk6bpsuNOT0/X91vJ1NRUlqZpNj8/33L/cmvV0kp/mo3D0m2lUimLiIYa5+fns1Kp1PE+5Z+/0fO9ml4cl7X60G4fsyzLxsfH294H4GHnzhdAB+zZsyciIk6fPr1im3fffTci7k31yj311FMREfHOO+80/Hdxm3379i171qhSqcTQ0FAcO3Zs1bouXboU586da+tZntxatbTSn1a8+OKLERHx4Ycf1rddv369vn2pjfSpCMYFgJUIXwAFGRoaWrYtv1DOV6hrdQW/27dvx9DQUFQqlRXbjI2NRZqmy55HatVatbTSn1bs3bs30jRtCCY///nPmz7TtNE+rUf+DFWrS7JvtnHJ+1UqldreF4D2CF8AHbTaYgf5YhjNngvL98vbzMzMrPo5x44di1KpFPv37296vJmZmbhx40a88sorLde+Ur0r1dJKf1p14sSJ+jNQc3Nz8cMf/nBZm070aT3yZ6hu377dUvvNNi7Xr1+PiIjnnntuXfsD0DrhC6AD8oBy4MCBFducOHEiIu4t1JHL7zocOXIkIr6+cB8aGqq/l/8h3aVef/31SNM0zp8/37C9VqvFRx99FG+88UZDfc2OsZq1ammlP616/vnnIyLiypUr8cknn8Szzz7b8H6n+rQeaZpGmqZN72jl5ubm4uLFixGxucalVqvFpUuXIk3T+mcBcB91+6EzgG6LNhdgSNM0i4hsamoqy7Isq1arWZqm2YULF+pfx78uYLB40YX5+fksTdMsTdP69tHR0WxgYKDeJj9Wvn9EZAMDA9nNmzcbjpsvqjA7O9uw0Eez/fPX5ORkW+OyWi2t9KdZvfPz803HJsu+XmAiH8fV6lhvn7Ks/fO9uIbF/c/Nzs42jEGvjcviYy9ejGN6enpZne2w4AZA+/zUBB5667kYz1eWywNJHsTy4y1+LVatVrPh4eH6e6Ojo8tWp6tWq/UL7lKpVL/Yb3bcfGW9xeGo2cV4RCwLDa1YqZZW+tOs3tXGZnp6ummdne7Tes53lt0LMZOTkw31pGmaDQ8PZ7Ozsw1te2VcVno/D3PXrl1rexxywhdA+5Is86fpgYdbkiQxPj4efX193S6FAjjfnTExMRFHjx5t+vflAGjOM18AAAAFEL4AAAAKsLXbBQBQrCRJWmpnOhkAdJbwBfCQEaoAoDtMOwQAACiA8AUAAFAA4QsAAKAAwhcAAEABhC8AAIACCF8AAAAFEL4AAAAKIHwBAAAUQPgCAAAogPDF/2fv/kLjOtP7gT8T2d6yNJuFTezudmtDcJ2GQtwSWOxexCQ2lIaOr2LZsq2UpU4q0w2k2BcljPCFA7mozPoixUJuL0Jo9Ce50rBJL2KXzUWsvUiQLkyxtzWRiNvObEqlNRTWrnN+F/6dif6MpJE0emdkfT4wbHTmnXOe9z1T+Xx73vMKAABIQPgCAABIQPgCAABIQPgCAABIoJBlWdbqIgBaqVAotLoE2LBcRgA0bkurCwBoteHh4VaXwCJ++tOfRkTE3/zN37S4EgBYO3e+AGhbnZ2dERExMjLS4koAYO088wUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJCA8AUAAJDAllYXAAAREf/7v/8bv/nNb+Zsu3v3bkRE/M///M+c7d/61rfi29/+drLaAKAZClmWZa0uAgD+/u//Pn7yk5801Pbtt9+Ov/7rv17nigCguYQvANrCr371q/j+978f9+/fX7JdR0dH/Od//mc88cQTiSoDgObwzBcAbeGJJ56IF154ITo6OhZt09HREQcPHhS8ANiQhC8A2sbJkydjqQkZWZbFyZMnE1YEAM1j2iEAbePOnTvxxBNPLFh4I7dt27b41a9+Fd/5zncSVwYAa+fOFwBt49FHH40///M/j61bty54b8uWLXH48GHBC4ANS/gCoK2cOHEi/u///m/B9vv378eJEydaUBEANIdphwC0lbt378bjjz8ed+7cmbP9t3/7t+Orr76Kb33rWy2qDADWxp0vANrKtm3b4qWXXopt27bVtm3dujU6OzsFLwA2NOELgLZz/PjxuHv3bu3ne/fuxfHjx1tYEQCsnWmHALSdr7/+Onbs2BFfffVVRER873vfi0qlsuTfAAOAdufOFwBt55FHHokTJ07Etm3bYuvWrXHy5EnBC4ANT/gCoC11dXXF3bt3TTkE4KGxpdUFAKzUkSNHWl0CiXz729+OiIi/+7u/a3ElpPL++++3ugSAdePOF7DhfPDBB/Hll1+2ugxWaSXnb9euXbFr1651roh28OWXX8YHH3zQ6jIA1pUFN4ANp1AoxPDwcHR2dra6FFZhJefv+vXrERHxh3/4h+tdFi02MjISR48eDZclwMPMtEMA2pbQBcDDxLRDAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACAK58tNgAAIABJREFUBIQvAACABIQv4KFWrVZjaGgoDh8+vKY263Xsjehh7Vc7WWyMe3t7o7e3t0VVAbBWwhfwUDt37lx0dXVFuVxeU5vVOHXqVEP7nZqaitOnT0ehUIjTp0/H1atXm1pHs63XeNVTKBTmvMbGxhZtOzY2tqD9etWRvw4fPhyXL1+OarXatGNFpB3j3HLfw8XGoFAoxIULF6JcLsfMzEyyegE2IuELeKhdunSpKW1WY3R0dNk2MzMzMTExEZcuXYrp6ek4cOBAHDx4MOlF90qt13jVk2VZTE5O1n5+5513Fm07+71KpRJZljW1jkqlMufnLMvi7bffjqmpqdixY0fcvHmzacdbbIzPnz8f58+fb9pxco18D+ePwfT0dG0cDh06FJcvX47u7u6mB1GAh4nwBdBCn3zySRSLxYiIeOyxx+LYsWMREab0zbJz586IiOjr64v+/v6Ymppa0GZqaip2795d+3n79u1Nr6PePnfu3BmvvfZaRET89Kc/bfoxU2n0ezh7DB577LHaf+/duzf+4R/+ISIe3PF1BwygPuEL2DSq1WpcuHChNq2q3kX8fDMzMzE0NFSbXlVvilm9Nou5evXqnOla+QXvfD09PSvuW7lcrl0sX758udbP+XdkVtunVt/ROHToUEREfPrppwve+/TTT2vv1zMzM1Mbk0KhEL29vbX+1JuquJLpi3kg6e/vn3O8Zo9xvefA5m8rl8u16ZDzv99Xr16Nw4cP16YJzj5WM76H27dvj9dffz3K5XJ88sknDX8OYDMRvoBN49atW3HmzJmoVCpx+/bt2LVr17KBoru7O+7cuVObclUulxf8f/a7u7vj+vXrtSlYn3/++aKLIuzevTsGBgYWnRaX7/fFF19cUd927NgRhw8fjnK5HGNjY/HKK6/E9PR0REQ89dRTcwJYo31ark1qe/fujZ6enujq6lrw3s9//vPYu3fvop/927/923j11VejUqnE5ORkvPnmm3Hu3LmIeDCdbmBgICKiNq2uUqlEsViM8fHxZacv5mMyO6isxxjXe4Zw9raxsbEoFosxOTkZ5XI53nrrrVq7crkcBw8ejDfeeCOyLIvf/d3fjR07diwaLlf7PXz22WcjIuLDDz9c0ecANo0MYIOJiGx4eHhF7ef/urtx40YWEdnAwMCiba5cuZJFRFapVGrbrl27lkVENjg4mGVZlg0ODtZtUywWF+x3fHy89rnFXLlyJSsWi9n09HTD/Vuqn+Pj41lEZH19fQ33qZE29Y61kjpXcv7yz8yu7dq1a3P6eOXKlSXrKpVKWU9Pz5z9zW/X09NT63dfX9+c/s//3Pj4eJZlWTY9PZ2VSqU5Na3nGK9222Jt8u/FfEt9D5c796v9bgwPD6/6OwWwUfgtB2w4zQhf87cvdTE+2/T0dBYRtXBVLBYbuhC9du3anIv/xRSLxTnBYiUa6WcjfWqkTavCV/7fs8eyVCrNeW+puiYnJ7O+vr667SqVSq2PN27cWLSO+a9SqVQLY1m2vmO82m31jrfUWC31PRS+AFbPbzlgw0kVvlb7uXpt8ztkSwWrwcHB2p241VhLvc1q02idawlf+VhOTk5mlUplzt3EpeoaGBioBavF2i13nhrp93qO8Wq35XdA87Gaf0d0tuW+h0uNQR4gZwfiRglfwGbgmS9gU1tqQYF8EYJ6z4Xln8vbTExMLHmcY8eORalUiv3799fd38TERFy/fj1eeeWVhmtfifn1NtKnpdq00p/8yZ9ExINFNq5evVr7eSlDQ0Px6quvxttvvx179uyp26Zarcbt27ejr69v0fPUiHYc471798bo6Gjcvn27tuDI4OBgnDlzZk67tX4PP/vss4iIeP7559dcM8DDSPgCNqU8LB04cGDRNsePH4+IBwt15PKFCI4cORIR31xE9/f3197L/1jtfGfPno1isVhb6CFXrVbj448/nvP3myYmJuruY6XyhTbyhRMa6VMjbVpp586dUSqVoqurK27fvl1bin4p+SIdS7V9991348yZM3Hq1Km656lR7TjG5XI5nnvuuThz5kxkWRajo6O15eRza/0eVqvVuHjxYhSLxXjhhReaWj/AQ6PVt94AVipWOG0tfy4rX5ShUqlkxWKxNuUqf9YnYu4CCNPT01mxWMyKxWJt++Dg4JznjfJ95Z+P//880o0bN+bsN1+4YHJyMov4ZqGPep/PX6Ojoysel5g1tSxfDCJ/hqjRPi3XZrHxWkmdKzl/+fFmHyufNjf7Waul6srHeHJycs60w0qlUhun2YtL1Js+l29brt/rNcbLbcvrr1dnve9X/l2tVCoNfw9n73v2eI2Pjy/oz0qZdghsBn7LARvOSi/es+yb1dvyC848iOX7m/2arVKpZAMDA3OCzfwV4CqVSm3Fu1KpVFusod5+81XuZl/8LnZhvNiiD0uNSx5I8r4ODAzUrbeRPi3WZqnxarTORs9fvXHJ1Vu9cLG2eVgrlUq189XT01MLw/PbL7a/Rvu+HmO8lm2zvxP1Algj38OlxqGvr2/VC8XkhC9gMyhk2TJ/wASgzRQKhRgeHo7Ozs5Wl9JW8r/X1O6/1p2/9G7evBm/9Vu/tWDa5c2bN+Opp55qi+/MyMhIHD16tC1qAVgvnvkCgIfY0NBQ7Nmzp+7zbjt27IjBwcEWVAWwOW1pdQEArN3sVfOq1Wps3769hdXQTt577724c+dO/Omf/umcAHbz5s34+c9/vm4rbAKwkDtfAG2uUCgs+9qxY0et/ez/hnfffTceffTReOutt2rfl97e3vjyyy8FL4DE3PkCaHOegWEtHnvssTh27FgcO3YsLl261OpyADY1d74AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASKGRZlrW6CICVKBQKsW/fvvjhD3/Y6lJYhQ8++MD5Y4Evv/wyxsbGwmUJ8DATvoAN58iRI60ugUT+9V//NSIinn766RZXQirvv/9+q0sAWDfCFwBtq7OzMyIiRkZGWlwJAKydZ74AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASKGRZlrW6CAD4p3/6p/jHf/zH+Prrr2vbbty4ERERTz31VG3bI488En/5l38ZJ06cSF4jAKyF8AVAW5iYmIg/+qM/aqjt+Ph47N27d50rAoDmEr4AaBt/8Ad/ULvbtZjdu3fHL3/5y0QVAUDzeOYLgLbR3d0dW7duXfT9rVu3xo9//OOEFQFA87jzBUDbuHXrVuzevTuW+qfpl7/8ZezevTthVQDQHO58AdA2nnzyyfjjP/7jKBQKC94rFArx7LPPCl4AbFjCFwBt5eWXX46Ojo4F2zs6OuLll19uQUUA0BymHQLQVqrVanz/+9+fs+R8xIMl5m/fvh2/8zu/06LKAGBt3PkCoK1s3749nnvuuTl3vzo6OuLAgQOCFwAbmvAFQNvp7u5uaBsAbCSmHQLQdn7961/H448/Hvfu3YuIB0vMV6vV+O53v9viygBg9dz5AqDtfOc734k/+7M/iy1btsSWLVvixRdfFLwA2PCELwDa0smTJ+P+/ftx//79OHHiRKvLAYA129LqAgBabWRkpNUlUMe9e/di27ZtkWVZ/OY3v3Ge2lRnZ2erSwDYMDzzBWx69f6gL9AYlxEAjTPtECAihoeHI8syrzZ7ffTRR/HP//zPTd2n892c1/DwcIv/rxZg4zHtEIC2dejQoVaXAABNI3wB0La2bPHPFAAPD9MOAQAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AFagWq3G0NBQHD58eE1t1uvYAED7Er4AVuDcuXPR1dUV5XJ5TW1W49SpUw3tt1qtRm9vbxQKhSgUCjE0NNTUOlphZmYmxsbG4vLlyy0Nn2NjY3PGtre3NyYmJqJarUahUEhez9TUVJw+fToKhUKcPn06rl69Ouf9vM56rwsXLkS5XI6ZmZnkdQNsVsIXwApcunSpKW1WY3R0dNk21Wo1bt26FefPn48sy2JwcDC6urriwoUL61JTKn19ffGzn/0sXn311aaH2kb19vbGO++8E93d3ZFlWWRZFq+99lpMTU3Fjh07ktczMzMTExMTcenSpZieno4DBw7EwYMH54xPlmVRqVRqP09PT9dqP3ToUFy+fDm6u7ujWq0mrx9gMypkWZa1ugiAVioUCjE8PBydnZ0Nt494cGG7ljarsdx+x8bGYt++fUlqaYVm9GWl5zsiane4FgvAY2NjsX///qRjXC6Xo1gsztm22Pgstr1arcapU6ciIuLdd9+Nxx57rOHjj4yMxNGjRx+K7xVAKu58AaxStVqNCxcu1KZ8TU1NLfuZmZmZGBoaqk39unz58oK7DvXaLObq1atzppLND175lLJSqbSKHi5fy1L9mf+MWrlcjkKhEIcPH46pqakYGxtbMBUul49roVBoaFzX09jYWLz55pvxxhtvLNqm3riv97js3bu3bi09PT0N92379u3x+uuvR7lcjk8++aThzwGwOsIXwCrdunUrzpw5E5VKJW7fvh27du1advpWd3d33LlzpzYdrFwux6lTp+Y8d9Pd3R3Xr1+vTQ/7/PPPo7e3t+7+du/eHQMDA1GpVBbcgZiamoq+vr7aPldjuVqW6s/sZ9TGxsaiWCzG5ORklMvleOutt2Lfvn1x5cqViHgQDmfXf+bMmSiVSjE+Ph47d+5cVe3N8rOf/SwiIp588skl282uvxXjkn+HXnzxxRX179lnn42IiA8//HBFnwNgFTKATS4isuHh4RW1n//r88aNG1lEZAMDA4u2uXLlShYRWaVSqW27du1aFhHZ4OBglmVZNjg4WLdNsVhcsN/x8fHa5+abnJystY2IrK+vr+H+5ZarpZH+1BuH+dtKpVIWEdn09HRt2/T0dFYqlRbUVG9/K9WM872UVoxLftxisTinfaN9WM24Dg8Pr/lcAGw27nwBNMGePXsiIuLVV19dtM37778fEQ+meuWefvrpiIh477335vzv7Db79u1b8KzR2NhY9Pf3x7Fjx+oea+fOnZFlWYyPj0epVIqzZ88uOX2xnuVqaaQ/jXjppZciIuKjjz6qbfvss89q2zeaVo3LxYsX44033ljRc1sApCV8ASTS39+/YFt+oZyvUNfoSn5ffPFF9Pf3x9jY2JLt9u7dW5tyuFQwrGe5WhrpTyP27t0bxWJxTjD5l3/5l0WfaUotf4aq0SXZWzEuQ0NDUSwWFzx71oi1PhcIQOOEL4AmWmqxg3xlunrPheWfy9tMTEwseZxjx45FqVSK/fv3L/ucWX5XbqWWq6WR/jTq+PHjtWegpqam4kc/+tEKq10/+TNUX3zxRUPtU4/LxMREXL9+PV555ZUV7Tv32WefRUTE888/v6rPA9A44QugCfKAcuDAgUXbHD9+PCIeLNSRy+86HDlyJCK+uXDv7++vvZf/Id35zp49G8ViMc6dO7dkbfl+BgcHG+pLbrlaGulPo1544YWIiHjnnXfi008/jeeee25Fn19PxWIxisVi3TtauampqdrfUks5LtVqNT7++OM4f/58bdvExETd70s91Wo1Ll68GMVisXYsANZRqx86A2i1WOECDMViMYuI7MqVK1mWZVmlUsmKxWJtUYtKpVJbwGD2ogvT09NZsVjMisVibfvg4GDW09NTa5PvK/98RGQ9PT3ZjRs35uw3X1QhX1gjX+gjr2NycrJ2zFKptOgiDUtZqpZG+lOv3unp6bpjk2XfLDCx2OIgsz9bb1GJRq30fGfZN2Mxu/+5ycnJOWOQalzqnZ/8NTo6Wmu32LiNj48vqHMlLLgBsHJ+awKb3mouxvOV5fJAkgexfH+zX7NVKpVsYGCg9t7g4OCCIFGpVGoX3KVSqXaxX2+/+cp6sy+6Z//c19eXXbt2bTXDsmQtjfSnXr1Ljc34+HgWEQuOUe9z9T7fqNWc7yx7EGJGR0eznp6e2vGLxWI2MDBQC7u5FOMyu475r8W+M838bghfACtXyDJ/mh7Y3AqFQgwPD0dnZ2erSyEB57s5RkZG4ujRowv+vhwAi/PMFwAAQALCFwAAQAJbWl0AAGkVCoWG2plOBgDNJXwBbDJCFQC0hmmHAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACQhfAAAACWxpdQEA7eDatWutLoGEnO+1M4YAK1fIsixrdREArVQoFFpdAmxYLiMAGufOF7DpuXhsX52dnRERMTIy0uJKAGDtPPMFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQgPAFAACQwJZWFwAAERG/+MUvYmJiYs62W7duRUTEwMDAnO3PPPNM7Nu3L1ltANAMwhcAbaFarcZf/dVfRUdHRzzyyIOJGVmWRUTET37yk4iI+Prrr+P+/fsxOjrasjoBYLUKWf4vGwC00L179+Lxxx+PX//610u2e/TRR+Orr76Kbdu2JaoMAJrDM18AtIWtW7fGsWPHlgxVW7duja6uLsELgA1J+AKgbXR1dcXdu3cXff/evXtx/PjxhBUBQPOYdghA2/j666/jBz/4QVQqlbrvP/HEE/Ff//VftWfCAGAj8a8XAG3jkUceiZMnT9adVrht27b4i7/4C8ELgA3Lv2AAtJXFph7evXs3urq6WlARADSHaYcAtJ3du3fHv//7v8/ZtmvXrvjiiy9aUxAANIE7XwC0nZMnT8bWrVtrP2/bti1+/OMft7AiAFg7d74AaDv/9m//Fr//+78/Z9uNGzdiz549LaoIANbOnS8A2s7u3bvjmWeeiUKhEIVCIZ555hnBC4ANT/gCoC29/PLL0dHRER0dHfHyyy+3uhwAWDPTDgFoS//xH/8Rv/d7vxdZlsXU1FT88Ic/bHVJALAmwhew6RUKhVaXABuWywiAxm1pdQEA7eD111+P/fv3t7oM5vn444+jUCjEwYMHm7bPo0ePOt9NcO3atbh48WKrywDYUNz5Aja9QqEQw8PD0dnZ2epSmOe///u/IyLie9/7XtP26Xw3x8jISBw9etSdL4AVcOcLgLbVzNAFAK1mtUMAAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC8AAIAEhC+AFahWqzE0NBSHDx9eU5v1OjYA0L6EL4AVOHfuXHR1dUW5XF5Tm9U4depUQ/utVqvR29sbhUIhCoVCDA0NNbWOVpiamorTp09HoVCI06dPx9WrV1tSx9jY2Jyx7e3tjYmJiahWq1EoFJLXs9y45HXWe124cCHK5XLMzMwkrxtgsxK+AFbg0qVLTWmzGqOjo8u2qVarcevWrTh//nxkWRaDg4PR1dUVFy5cWJeaUpiZmYmJiYm4dOlSTE9Px4EDB+LgwYNND7fL6e3tjXfeeSe6u7sjy7LIsixee+21mJqaih07diStJaKxccmyLCqVSu3n6enpWu2HDh2Ky5cvR3d3d1Sr1eT1A2xGhSzLslYXAdBKhUIhhoeHo7Ozs+H2EQ8ubNfSZjWW2+/Y2Fjs27cvSS2plMvlKBaLc7atpU8rPd8RUbvDtVgAHhsbi/379ycd45WMy2Lbq9VqnDp1KiIi3n333XjssccaPv7IyEgcPXp0w36vAFrBnS+AVapWq3HhwoXalK+pqallPzMzMxNDQ0O1qV+XL19ecNehXpvFXL16dc5UsvnBK59SViqVVtHD5WtZqj/zn1Erl8tRKBTi8OHDMTU1FWNjYwumwuXycS0UCrF37966tfX09KyqTys1NjYWb775ZrzxxhuLtqk37hthXLZv3x6vv/56lMvl+OSTTxr+HACrI3wBrNKtW7fizJkzUalU4vbt27Fr165lp291d3fHnTt3atPByuVynDp1as5zN93d3XH9+vXa9LDPP/88ent76+5v9+7dMTAwEJVKZcEdiKmpqejr66vtczWWq2Wp/sx+Rm1sbCyKxWJMTk5GuVyOt956K/bt2xdXrlyJiAfhcHb9Z86ciVKpFOPj47Fz5845NeVj9eKLL66qTyv1s5/9LCIinnzyySXbza5/I43Ls88+GxERH3744Yo+B8AqZACbXERkw8PDK2o//9fnjRs3sojIBgYGFm1z5cqVLCKySqVS23bt2rUsIrLBwcEsy7JscHCwbptisbhgv+Pj47XPzTc5OVlrGxFZX19fw/3LLVdLI/2pNw7zt5VKpSwisunp6dq26enprFQq1a3rypUrWbFYnNN+JZpxvpfSjuOyXB9W2scsy7Lh4eEVfwZgs3PnC6AJ9uzZExERr7766qJt3n///Yh4MNUr9/TTT0dExHvvvTfnf2e32bdv34JnjcbGxqK/vz+OHTtW91g7d+6MLMtifHw8SqVSnD17dsnpi/UsV0sj/WnESy+9FBERH330UW3bZ599Vts+38WLF+ONN95Y0fNJKRkXABYjfAEk0t/fv2BbfqGcr1DX6Ap+X3zxRfT398fY2NiS7fbu3VubcrhUMKxnuVoa6U8j9u7dG8VicU4w+Zd/+Ze6zzQNDQ1FsVhc8IzVesqfoWp0SfaNNi5rfS4QgMYJXwBNtNRiB/nKdPWeC8s/l7eZmJhY8jjHjh2LUqkU+/fvX/Y5s/yu3EotV0sj/WnU8ePHa89ATU1NxY9+9KMFbSYmJuL69evxyiuvrGjfa5U/Q/XFF1801H6jjctnn30WERHPP//8qj4PQOOEL4AmyAPKgQMHFm1z/PjxiHiwUEcuv+tw5MiRiPjmwr2/v7/2Xv6HdOc7e/ZsFIvFOHfu3JK15fsZHBxsqC+55WpppD+NeuGFFyIi4p133olPP/00nnvuuTnvV6vV+Pjjj+P8+fO1bRMTE3XHpdmKxWIUi8W6d7RyU1NTtb+ltpHGpVqtxsWLF6NYLNaOBcA6avVDZwCtFitcgKFYLGYRkV25ciXLsiyrVCpZsVisLWpRqVRqCxjMXnRheno6KxaLWbFYrG0fHBzMenp6am3yfcWsxTJ6enqyGzduzNlvvqhCvrBGvtBHXsfk5GTtmKVSadFFGpayVC2N9KdevdPT03XHJsu+WWBi/uIg9erIX6Ojoyvu10rP9+waZvc/Nzk5OWcM2m1cZu979mIc4+PjC+pcCQtuAKyc35rApreai/F8Zbk8kORBLN/f7NdslUolGxgYqL03ODi4YHW6SqVSu+AulUq1i/16+81X1pt90T37576+vuzatWurGZYla2mkP/XqXWpsxsfHs4hYcIyenp66AaNe20as5nxn2YMQMzo6OqeeYrGYDQwM1MJurl3GZbH3m/HdEL4AVq6QZf40PbC5FQqFGB4ejs7OzlaXQgLOd3OMjIzE0aNHF/x9OQAW55kvAACABIQvAACABLa0ugAA0ioUCg21M50MAJpL+ALYZIQqAGgN0w4BAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASEL4AAAASKGRZlrW6CIBWKhQKrS4BNiyXEQCN29LqAgBabXh4uNUlsIif/vSnERHxN3/zNy2uBADWzp0vANpWZ2dnRESMjIy0uBIAWDvPfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACQgfAEAACSwpdUFAEBExP/+7//Gb37zmznb7t69GxER//M//zNn+7e+9a349re/naw2AGiGQpZlWauLAIC///u/j5/85CcNtX377bfjr//6r9e5IgBoLuELgLbwq1/9Kr7//e/H/fv3l2zX0dER//mf/xlPPPFEosoAoDk88wVAW3jiiSfihRdeiI6OjkXbdHR0xMGDBwUvADYk4QuAtnHy5MlYakJGlmVx8uTJhBUBQPOYdghA27hz50488cQTCxbeyG3bti1+9atfxXe+853ElQHA2rnzBUDbePTRR+PP//zPY+vWrQve27JlSxw+fFjwAmDDEr4AaCsnTpyI//u//1uw/f79+3HixIkWVAQAzWHaIQBt5e7du/H444/HnTt35mz/7d/+7fjqq6/iW9/6VosqA4C1cecLgLaybdu2eOmll2Lbtm21bVu3bo3Ozk7BC4ANTfgCoO0cP3487t69W/uj9MIyAAAgAElEQVT53r17cfz48RZWBABrZ9ohAG3n66+/jh07dsRXX30VERHf+973olKpLPk3wACg3bnzBUDbeeSRR+LEiROxbdu22Lp1a5w8eVLwAmDDE74AaEtdXV1x9+5dUw4BeGhsaXUBAK125MiRVpfAIr797W9HRMTf/d3ftbgSFvP++++3ugSADcOdL2DT++CDD+LLL79sdRnUsWvXrti1a1dT9+l8N8eXX34ZH3zwQavLANhQLLgBbHqFQiGGh4ejs7Oz1aUwz/Xr1yMi4g//8A+btk/nuzlGRkbi6NGj4TICoHGmHQLQtpoZugCg1Uw7BAAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AgAASED4AliBarUaQ0NDcfjw4TW1Wa9jAwDtS/gCWIFz585FV1dXlMvlNbVZjVOnTjW032q1Gr29vVEoFKJQKMTQ0FBT62iFdunT2NjYnDp6e3tjYmIiqtVqFAqF5PVMTU3F6dOno1AoxOnTp+Pq1atz3s/rrPe6cOFClMvlmJmZSV43wGYlfAGswKVLl5rSZjVGR0eXbVOtVuPWrVtx/vz5yLIsBgcHo6urKy5cuLAuNaXQLn3q7e2Nd955J7q7uyPLssiyLF577bWYmpqKHTt2JK0lImJmZiYmJibi0qVLMT09HQcOHIiDBw/OCedZlkWlUqn9PD09Xav90KFDcfny5eju7o5qtZq8foDNqJBlWdbqIgBaqVAoxPDwcHR2djbcPuLBhe1a2qzGcvsdGxuLffv2JakllWb3aaXnOyJqd7gWC8BjY2Oxf//+pGNcLpejWCzO2bbYuCy2vVqtxqlTpyIi4t13343HHnus4eOPjIzE0aNHN+z3CqAV3PkCWKVqtRoXLlyoTfmamppa9jMzMzMxNDRUm/p1+fLlBXcd6rVZzNWrV+dMJZsfUvIpZaVSaRU9XL6Wpfoz/xm1crkchUIhDh8+HFNTUzE2NrZgKlwuH9dCoRA/+MEPmtqnlRobG4s333wz3njjjUXb1Bv39R6XvXv31q2lp6en4b5t3749Xn/99SiXy/HJJ580/DkAVkf4AlilW7duxZkzZ6JSqcTt27dj165dy07f6u7ujjt37tSmg5XL5Th16tSc5266u7vj+vXrtelhn3/+efT29tbd3+7du2NgYCAqlcqCOxBTU1PR19dX2+dqLFfLUv2Z/Yza2NhYFIvFmJycjHK5HG+99Vbs27cvrly5EhEPgtTs+s+cOROlUinGx8dj586dTe3TSv3sZz+LiIgnn3xyyXaz6089LhHfhNIXX3xxRf179tlnIyLiww8/XNHnAFiFDGCTi4hseHh4Re3n//q8ceNGFhHZwMDAom2uXLmSRURWqVRq265du5ZFRDY4OJhlWZYNDg7WbVMsFhfsd3x8vPa5+SYnJ2ttIyLr6+truH+55WpppD/1xmH+tlKplEVENj09Xds2PT2dlUqlpvcpP/5az/dSUo/L7OMWi8U57Rvtw0r7mGVZNjw8vOLPAGx27nwBNMGePXsiIuLVV19dtM37778fEQ+meuWefvrpiIh477335vzv7Db79u1b8KzR2NhY9Pf3x7Fjx+oea+fOnZFlWYyPj0epVIqzZ88uOX2xnuVqaaQ/jXjppZciIuKjjz6qbfvss89q23PN6FMKqccld/HixXjjjTdW9NwWAGlZcAPY9Jq14Mbs7fXarPZz9drmK/5du3ZtwfNG8928eTOeeuqpJfe71LGWq6UZ45A//5QHu97e3jh//vyita22T/nxV3K+T58+Hf39/TE9Pd1QsGnFuAwNDcWdO3filVdeWVFNEQ+mK373u9+NUqm05JjPZ8ENgJVz5wugiZZa7CBfma7ec2H55/I2ExMTSx7n2LFjUSqVYv/+/cs+Z5bflVup5WpppD+NOn78eO0ZqKmpqfjRj360ZPvV9mk18meovvjii4bapx6XiYmJuH79+qLBazmfffZZREQ8//zzq/o8AI0TvgCaIA8oBw4cWLTN8ePHI+LBQh25fJGEI0eORMQ3F+79/f219/I/pDvf2bNno1gsxrlz55asLd/P4OBgQ33JLVdLI/1p1AsvvBAREe+88058+umn8dxzzy3ZfrV9Wo1isRjFYjH6+/sXbTM1NVX7u2Mpx6VarcbHH388547VxMRE3e9LPdVqNS5evBjFYrF2LADWUcLnywDaUqxwAYZisZhFRHblypUsy7KsUqlkxWKxtgBEpVKpLWAwe9GF6enprFgsZsVisbZ9cHAw6+npqbXJ95V/PiKynp6e7MaNG3P2my+qkC9CkS/0kdcxOTlZO2apVFp0kYalLFVLI/2pV+/09HTdscmybxaYmL+QRjP7lGUrP995X4rF4pz+5yYnJ+eMQapxqXd+8tfo6Git3ex9z16MY3x8fEGdK2HBDYCV81sT2PRWczGeryyXB5I8iOX7m/2arVKpZAMDA7X3BgcHF6xOV6lUahfcpVKpdrFfb7/5ynqzL7pn/9zX15ddu3ZtNcOyZC2N9KdevUuNzfj4eBYRC47R7D6t5nxn2YMQMzo6mvX09NRqKRaL2cDAQC0Y5lKMy+w65r8W+840cxyFL4CVs+AGsOmtdAEGNjbnuzksuAGwcp75AgAASED4AgAASGBLqwsAIK38bz4tx3QyAGgu4QtgkxGqAKA1TDsEAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIQPgCAABIoJBlWdbqIgBaqVAoxL59++KHP/xhq0shgQ8++MD5boIvv/wyxsbGwmUEQOOEL2DTO3LkSKtLYBH/+q//GhERTz/9dIsrYTHvv/9+q0sA2DCELwDaVmdnZ0REjIyMtLgSAFg7z3wBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkIHwBAAAkUMiyLGt1EQDwT//0T/GP//iP8fXXX9e23bhxIyIinnrqqdq2Rx55JP7yL/8yTpw4kbxGAFgL4QuAtjAxMRF/9Ed/1FDb8fHx2Lt37zpXBADNJXwB0Db+4A/+oHa3azG7d++OX/7yl4kqAoDm8cwXAG2ju7s7tm7duuj7W7dujR//+McJKwKA5nHnC4C2cevWrdi9e3cs9U/TL3/5y9i9e3fCqgCgOdz5AqBtPPnkk/HHf/zHUSgUFrxXKBTi2WefFbwA2LCELwDayssvvxwdHR0Ltnd0dMTLL7/cgooAoDlMOwSgrVSr1fj+978/Z8n5iAdLzN++fTt+53d+p0WVAcDauPMFQFvZvn17PPfcc3PufnV0dMSBAwcELwA2NOELgLbT3d3d0DYA2EhMOwSg7fz617+Oxx9/PO7duxcRD5aYr1ar8d3vfrfFlQHA6rnzBUDb+c53vhN/9md/Flu2bIktW7bEiy++KHgBsOEJXwC0pZMnT8b9+/fj/v37ceLEiVaXAwBrtqXVBQCs1MjISKtLIIF79+7Ftm3bIsuy+M1vfuO8bxKdnZ2tLgFg3XjmC9hw6v0BXuDh4LIEeJiZdghsSMPDw5FlmdcGfK3k/H300Ufxz//8zy2v2Wv9X8PDwy3+rQKw/kw7BKBtHTp0qNUlAEDTCF8AtK0tW/wzBcDDw7RDAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQvAACABIQv4KFWrVZjaGgoDh8+vKY263Xsjehh7Vc7WWyMe3t7o7e3t0VVAbBWwhfwUDt37lx0dXVFuVxeU5vVOHXqVEP7rVar0dvbG4VCIQqFQgwNDTW1jmZbr/GqJx+T/DU2NrZo27GxsQXt16uO/HX48OG4fPlyVKvVph0rIu0Y56ampuL06dNRKBTi9OnTcfXq1TnvLzYGhUIhLly4EOVyOWZmZpLVC7ARCV/AQ+3SpUtNabMao6Ojy7apVqtx69atOH/+fGRZFoODg9HV1RUXLlxYl5qaYb3Gq54sy2JycrL28zvvvLNo29nvVSqVyLKsqXVUKpU5P2dZFm+//XZMTU3Fjh074ubNm0073mJjfP78+Th//nzTjpObmZmJiYmJuHTpUkxPT8eBAwfi4MGDc8Lf/DGYnp6ujcOhQ4fi8uXL0d3d3fQgCvAwEb4AWujWrVuxb9++2s/Hjh2LiIizZ8+2qqS2s3PnzoiI6Ovri/7+/piamlrQZmpqKnbv3l37efv27U2vo94+d+7cGa+99lpERPz0pz9t+jFT+eSTT6JYLEZExGOPPVb7Hs6f9jh7DB577LHaf+/duzf+4R/+ISIe3PF1BwygPuEL2DSq1WpcuHChNq2q3kX8fDMzMzE0NFSbXlVvilm9Nou5evXqnOlas4NXvq+IiFKptOK+lcvl2sXy5cuXa/2cf0dmtX1q9R2NQ4cORUTEp59+uuC9Tz/9tPZ+PTMzM7UxKRQK0dvbW+tPvamKK5m+mAeS/v7+Ocdr9hjXew5s/rZyuVybDjn/+3316tU4fPhwbZrg7GPlwWu+np6eJfs+2/bt2+P111+Pcrkcn3zyScOfA9hMhC9g07h161acOXMmKpVK3L59O3bt2rVsoOju7o47d+7UplyVy+UF/5/97u7uuH79em0K1ueff77oogi7d++OgYGButPipqamoq+vr7bPldixY0ccPnw4yuVyjI2NxSuvvBLT09MREfHUU0/NCWCN9mm5Nqnt3bs3enp6oqura8F7P//5z2Pv3r2LfvZv//Zv49VXX41KpRKTk5Px5ptvxrlz5yLiwXS6gYGBiIjatLpKpRLFYjHGx8eXnb6Yj8nsoLIeY1zvGcLZ28bGxqJYLMbk5GSUy+V46623au3K5XIcPHgw3njjjciyLH73d383duzYsWi4zGt48cUXl+z7fM8++2xERHz44Ycr+hzAppEBbDARkQ0PD6+o/fxfdzdu3MgiIhsYGFi0zZUrV7KIyCqVSm3btWvXsojIBgcHsyzLssHBwbptisXigv2Oj4/XPjff5ORkrW1EZH19fQ33b6l+jo+Pz9lfI31qpE29Y62kzpWcv/wzs2u7du3anD5euXJlybpKpVLW09MzZ3/z2/X09NT63dfXN6f/8z83Pj6eZVmWTU9PZ6VSaU5N6znGq922WJvFvmdXrlzJisViNj09vegYLGa1343h4eFVf6cANgq/5YANpxnha/72pS7GZ5uens4iohauisViQxei165dm3Pxv5jx8fHaxXweDBvVSD8b6VMjbVoVvvL/nj2WpVJpzntL1TU5OZn19fXVbVepVGp9vHHjxqJ1zH+VSqVaGMuy9R3j1W6rd7ylxqpYLM4JuI1+rpH3FyN8AZuB33LAhpMqfK32c/Xa5nfIFrugnS2/K7fSC9G11NusNo3WuZbwlY/l5ORkVqlU5txNXKqugYGBWrBarN1y56mRfq/nGK92W34HNB+r+XdEZxscHFwy+C81BnmAnB2IGyV8AZuBZ76ATW2pBQXyRQjqPReWfy5vMzExseRxjh07FqVSKfbv37/sc2Z79uxZ8v3VmF9vI31aqk0r/cmf/ElEPFhk4+rVq7WflzI0NBSvvvpqvP3224uOb7Vajdu3b0dfX19D52kx7TjGe/fujdHR0bh9+3ZtwZHBwcE4c+bMnHYTExNx/fr1eOWVV1Z1nM8++ywiIp5//vk11wzwMBK+gE0pD0sHDhxYtM3x48cj4sFCHbl8IYIjR45ExDcX0f39/bX38j9WO9/Zs2ejWCzWFnpYTL6fwcHBhvqylHyhjXzhhEb61EibVtq5c2eUSqXo6uqK27dv15aiX0q+SMdSbd999904c+ZMnDp1qqHztJh2HONyuRzPPfdcnDlzJrIsi9HR0dpy8rlqtRoff/zxnL8jNjExUfe7XE+1Wo2LFy9GsViMF154oan1Azw0Wn3rDWClYoXT1vLnsvJFGSqVSlYsFmtTrvJnfSLmLoAwPT2dFYvFrFgs1rYPDg7Oed4o31f++fj/zyPduHFjzn7zhQvyhTXyaV15HZOTk7VjlkqlVU3byo+VTy3L95U/Q9Ron5Zrs9h4raTOlZy//Hizj5VPm5v9rNVSdeXnaHJycs60w0qlUhun2YtL1Js+l29brt/rNcbLbcvrr1fn7O/n/O9qpVKp+z3OX6Ojo3XHYPZ4jY+PL+jPSpl2CGwGfssBG85KL96z7JvV2/ILzjyI5fub/ZqtUqlkAwMDc4LN/BXgKpVKbZGMUqlUW6yh3n7zVe5mX9jO/rmvr6+h58LqyfeRXwjnIa9evY30abE2S41Xo3U2ev7qhYFcvdULF2ubh7VSqVQ7Xz09PQtWmVxuf432fT3GeC3bZn8n6gWwfEGOeq/Fvs/N+t7mhC9gMyhk2TJ/wASgzRQKhRgeHo7Ozs5Wl9JW8r/X1O6/1p2/9G7evBm/9Vu/tWDa5c2bN+Opp55qi+/MyMhIHD16tC1qAVgvnvkCgIfY0NBQ7Nmzp+7zbjt27GjKs4UANGZLqwsAYO1mr5pXrVZj+/btLayGdvLee+/FnTt34k//9E/nBLCbN2/Gz3/+81WvbAjAyrnzBdDmCoXCsq8dO3bU2s/+b3j33Xfj0Ucfjbfeeqv2fent7Y0vv/xS8AJIzJ0vgDbnGRjW4rHHHotjx47FsWPH4tKlS60uB2BTc+cLAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAgAeELAAAggS2tLgBgNa5du9bqElgD54/5fCeAzaCQZVnW6iIAVqJQKLS6BGCduCwBHmbufAEbjouzzaOzszMiIkZGRlpcCQCsnWe+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEhC+AAAAEtjS6gIAICLiF7/4RUxMTMzZduvWrYiIGBgYmLP9mWeeiX379iWrDQCaQfgCoC1Uq9X4q7/6q+jo6IhHHnkwMSPLsoiI+MlPfhIREV9//XXcv38/RkdHW1YnAKxWIcv/ZQOAFrp37148/vjj8etf/3rJdo8++mh89dVXsW3btkSVAUBzeOYLgLawdevWOHbs2JKhauvWrdHV1SV4AbAhCV8AtI2urq64e/fuou/fu3cvjh8/nrAiAGge0w4BaBtff/11/OAHP4hKpVL3/SeeeCL+67/+q/ZMGABsJP71AqBtPPLII3Hy5Mm60wq3bdsWf/EXfyF4AbBh+RcMgLay2NTDu3fvRldXVwsqAoDmMO0QgLaze/fu+Pd///c523bt2hVffPFFawoCgCZw5wuAtnPy5MnYunVr7edt27bFj3/84xZWBABr584XAG3n3/7t3+L3f//352y7ceNG7Nmzp0UVAcDaufMFQNvZvXt3PPPMM1EoFKJQKMQzzzwjeAGw4QlfALSll19+OTo6OqKjoyNefvnlVpcDAGtm2iEAbek//uM/4vd+7/ciy7KYmpqKH/7wh60uCQDWRPgCNr1CodDqEmDDchkB0LgtrS4AoB28/vrrsX///laXwTwff/xxFAqFOHjwYNP2efToUee7Ca5duxYXL15sdRkAG4o7X8CmVygUYnh4ODo7O1tdCvP893//d0T8P/buLzSuK88T+K/iP7000+2BTuzu2d4Ygjc9YaA1QyDY2xCT2NBMmKunWP6rLM0kXpnpQAbnYTEl/OBAHsam/dCDhex5MM1EkuOXVpFkHiKH8UNcM+CgejCDu3eNJeKdreosU2rDQDuT3H1w34pKKklVUvmWHH8+UES6de6t3zmlluvb95yjiO985ztdu6b3uzsuXboU+/fvd+cLoAPufAGwbnUzdAFAr9ntEAAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBdKBWq8X4+Hj09/evqc2Dem0AYP0SvgA6cPLkyTh48GCUSqU1tVmNV199dVXXPX/+fBQKha7Wkre5ubkol8tx/vz5nobPcrkcw8PDUSgUolAoxPDwcFQqlajVaj0Z49nZ2Th27FgUCoU4duxYXLlypen5rM5WjzNnzkSpVIq5ubnc6wZ4VAlfAB04d+5cV9qsxuTkZMfnVCqVOHr06AOoJl+nT5+O9957L44ePdr1UNuu4eHhuHjxYgwODkaappGmabz++usxOzsb27Zty72eubm5qFQqce7cuajX67F79+7Ys2dP0/ikaRrVarXxfb1eb9S+d+/eOH/+fAwODkatVsu9foBHkfAF8DU1NzcXly9f7nUZXXHq1Kk4depUz14/u8N17ty5ePrppxvHt27dGkmSxLVr13Kv6erVq5EkSUREbNmyJQ4cOBARsejO4NatWxtfb9mypfF1X19fXLhwISLu31V1BwzgwRO+AFapVqvFmTNnGlO+ZmdnVzxnbm4uxsfHG1O/zp8/v+iuQ6s2S7ly5UrTVLL5Lly4EK+//vrqOtdmLcv1Z+EatVKpFIVCIfr7+2N2djbK5fKiqXCZbFwLhUJb4/oglcvleOutt+LEiRNLttm5c2fT93mMS19fX8tahoaG2u7b1q1b44033ohSqRRXr15t+zwAVkf4AlilW7duxfHjx6NarcadO3di+/btK07fGhwcjLt37zamg5VKpUV3HQYHB+PGjRuN6WGffPJJDA8Pt7zejh07YnR0NKrVaqRp2jh+5cqV+NGPftR012M1Vqpluf7MX6NWLpcjSZKYmZmJUqkUb7/9duzcuTOmpqYiIqJYLDbVf/z48SgWizE9PR1PPvnkmvqwVu+9915ERDz11FPLtptffy/GJfsZeumllzrq37PPPhsREe+//35H5wGwCinAIy4i0omJiY7aL/z1efPmzTQi0tHR0SXbTE1NpRGRVqvVxrFr166lEZGOjY2laZqmY2NjLdskSbLoutPT043z5qtWq406lqqlHSvV0k5/Wr32wmPFYjGNiLRerzeO1ev1tFgsLqpptX1ZeI21vt/L6cW4ZK+bJElT+3b7sJpxnZiYWPN7AfCocecLoAuydUDLbW7x7rvvRkTzGpxnnnkmIiLeeeedpv/Ob7Nz585Fm22Uy+UYGRlprPOZ75e//GW89tprq+lGk5Vqaac/7Xj55ZcjIuKDDz5oHLt+/Xrj+MOmV+Ny9uzZOHHiRNO6LgDWF+ELICcjIyOLjmUflLMd6trdye/27dsxMjIS5XK56XipVIof//jHa6z0q2stp53+tKOvry+SJGkKJh999NGSa5rylq2handDil6My/j4eCRJsmjtWTuyfhWLxY7PBaAzwhdAFy232UG2M12rdWHZeVmbSqWy7OscOHAgisVi7Nq1q+l6/f39sX379pabNXT6d6hWqqWd/rTr0KFDjTVQs7Oz8dxzz3V0/oOUraG6fft2W+3zHpdKpRI3btxY9d3O69evR0TECy+8sKrzAWif8AXQBVlA2b1795JtDh06FBH3N+rIZHcd9u3bFxFffXAfGRlpPJf9Id2F3nzzzUiSJE6ePNk4lv5+Y4z5j/nPdWKlWtrpT7tefPHFiIi4ePFifPzxx/H88893dP6DlCRJJEnS8o5WZnZ2Ns6cORMR+Y5LrVaLDz/8sGkb/kql0vLnpZVarRZnz56NJEkarwXAA9TLBWcA60F0uAFDkiRpRKRTU1Npmt7f4CJJkvT06dON7+P3GxjM33ShXq+nSZKkSZI0jo+NjaVDQ0ONNtm1svMjIh0aGkpv3rzZdN1sU4WZmZmmjT6W6t9qft0vV0s7/WlVb71ebzk2afrVBhPZOC40/9xWm0q0q9P3O02/Gov5/c/MzMw0jUFe49Lq/ckek5OTjXZLjdv09PSiOjthww2AzvmtCTzyVvNhPNtZLgskWRDLrjf/MV+2E2H23NjY2KIgUa1WGx+4i8Vi48N+q+tmO+stF7BWG76Wq6Wd/rSqd7mxmZ6eTiNi0Wu0Om8tfVrN+52m90PM5ORkOjQ01Hj9JEnS0dHRdGZmpqltHuMyv46Fj6V+ZuY/Tp8+nV67dq3jccgIXwCdK6Rph/NQAL5mCoVCTExMxMDAQK9LIQfe7+64dOlS7N+/v+PprACPMmu+AAAAciB8AQAA5GBjrwsAIF/tbjlvOhkAdJfwBfCIEaoAoDdMOwQAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHBTSNE17XQRALxUKhV6XAA8tHyMA2rex1wUA9NrExESvS2AJP/vZzyIi4q//+q97XAkArJ07XwCsWwMDAxERcenSpR5XAgBrZ80XAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AqYE6u8AACAASURBVAAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAcbe10AAERE/Pu//3v87ne/azp27969iIj4t3/7t6bj3/jGN+Kb3/xmbrUBQDcU0jRNe10EAPzt3/5t/PSnP22r7c9//vP4q7/6qwdcEQB0l/AFwLrwm9/8Jr73ve/FF198sWy7DRs2xL/+67/GE088kVNlANAd1nwBsC488cQT8eKLL8aGDRuWbLNhw4bYs2eP4AXAQ0n4AmDdOHLkSCw3ISNN0zhy5EiOFQFA95h2CMC6cffu3XjiiScWbbyR2bx5c/zmN7+Jb3/72zlXBgBr584XAOvGt771rfiLv/iL2LRp06LnNm7cGP39/YIXAA8t4QuAdeXw4cPxH//xH4uOf/HFF3H48OEeVAQA3WHaIQDryr179+Lxxx+Pu3fvNh3/gz/4g/jss8/iG9/4Ro8qA4C1cecLgHVl8+bN8fLLL8fmzZsbxzZt2hQDAwOCFwAPNeELgHXn0KFDce/evcb3n3/+eRw6dKiHFQHA2pl2CMC68+WXX8a2bdvis88+i4iI73znO1GtVpf9G2AAsN658wXAuvPYY4/F4cOHY/PmzbFp06Y4cuSI4AXAQ0/4AmBdOnjwYNy7d8+UQwC+Njb2ugCAXtu3b1+vS2AJ3/zmNyMi4m/+5m96XAlLeffdd3tdAsBDw50v4JF3+fLl+PTTT3tdBi1s3749tm/f3tVrer+749NPP43Lly/3ugyAh4oNN4BHXqFQiImJiRgYGOh1KSxw48aNiIj4kz/5k65d0/vdHZcuXYr9+/eHjxEA7TPtEIB1q5uhCwB6zbRDAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AXQgVqtFuPj49Hf37+mNg/qtQGA9Uv4AujAyZMn4+DBg1EqldbUZjVeffXVVV33/PnzUSgUulpL3mZnZ+PYsWNRKBTi2LFjceXKlZ7UUS6XY3h4OAqFQhQKhRgeHo5KpRK1Wq0nY7zSuGR1tnqcOXMmSqVSzM3N5V43wKNK+ALowLlz57rSZjUmJyc7PqdSqcTRo0cfQDX5mZubi0qlEufOnYt6vR67d++OPXv2dD3crmR4eDguXrwYg4ODkaZppGkar7/+eszOzsa2bdtyrSWivXFJ0zSq1Wrj+3q93qh97969cf78+RgcHIxarZZ7/QCPIuEL4Gtqbm4uLl++3Osy1uzq1auRJElERGzZsiUOHDgQEZHr9MvsDte5c+fi6aefbhzfunVrJEkS165dy62WTLvjsnXr1sbXW7ZsaXzd19cXFy5ciIj7d1XdAQN48IQvgFWq1Wpx5syZxpSv2dnZFc+Zm5uL8fHxxtSv8+fPL7rr0KrNUq5cudI0lWy+CxcuxOuvv766zrVZy3L9WbhGrVQqRaFQiP7+/pidnY1yubxoKlwmG9dCoRB9fX0taxsaGlpT39pVLpfjrbfeihMnTizZZufOnU3fPyzjsnXr1njjjTeiVCrF1atX2z4PgNURvgBW6datW3H8+PGoVqtx586d2L59+4rTtwYHB+Pu3buN6WClUmnRXYfBwcG4ceNGY3rYJ598EsPDwy2vt2PHjhgdHY1qtRppmjaOX7lyJX70ox813fVYjZVqWa4/89eolcvlSJIkZmZmolQqxdtvvx07d+6MqampiIgoFotN9R8/fjyKxWJMT0/Hk08+2VRTNlYvvfTSmvrWrvfeey8iIp566qll282v/2Eal2effTYiIt5///2OzgNgFVKAR1xEpBMTEx21X/jr8+bNm2lEpKOjo0u2mZqaSiMirVarjWPXrl1LIyIdGxtL0zRNx8bGWrZJkmTRdaenpxvnzVetVht1LFVLO1aqpZ3+tHrthceKxWIaEWm9Xm8cq9frabFYbFnX1NRUmiRJU/tOdOP9Xs56HJeV+rCan5GJiYlV/VwBPMrc+QLogmwd0HKbW7z77rsR0bwG55lnnomIiHfeeafpv/Pb7Ny5c9FmG+VyOUZGRhrrfOb75S9/Ga+99tpqutFkpVra6U87Xn755YiI+OCDDxrHrl+/3ji+0NmzZ+PEiRNN65fWE+MCwFKEL4CcjIyMLDqWfVDOdqhrdwe/27dvx8jISJTL5abjpVIpfvzjH6+x0q+utZx2+tOOvr6+SJKkKZh89NFHLdc0jY+PR5Iki9ZYPUjZGqp2N6R42MYl61exWOz4XAA6I3wBdNFymx1kO9O1WheWnZe1qVQqy77OgQMHolgsxq5du5qu19/fH9u3b2+5WUOnf4dqpVra6U+7Dh061FgDNTs7G88999yiNpVKJW7cuNGVu3qdyNZQ3b59u632D9u4XL9+PSIiXnjhhVWdD0D7hC+ALsgCyu7du5dsc+jQoYi4v1FHJrvrsG/fvoj46oP7yMhI47nsD+ku9Oabb0aSJHHy5MnGsfT3G2PMf8x/rhMr1dJOf9r14osvRkTExYsX4+OPP47nn3++6flarRYffvhhnDp1qnGsUqm0HJduS5IkkiRpeUcrMzs7G2fOnImIh2tcarVanD17NpIkabwWAA9QLxecAawH0eEGDEmSpBGRTk1NpWl6f4OLJEnS06dPN76P329gMH/ThXq9niZJkiZJ0jg+NjaWDg0NNdpk18rOj4h0aGgovXnzZtN1s00VZmZmmjb6WKp/q/l1v1wt7fSnVb31er3l2KTpVxtMZOO4XB3ZY3JysuN+dfp+z69hfv8zMzMzTWOw3sZl/rXnb8YxPT29qM5O2HADoHN+awKPvNV8GM92lssCSRbEsuvNf8yX7USYPTc2NrZod7pqtdr4wF0sFhsf9ltdN9tZb7mAtdrwtVwt7fSnVb3Ljc309HQaEYteY2hoqGXAaNW2Hat5v9P0foiZnJxsqidJknR0dDSdmZlpartexmWp57Mwd+3atY7HISN8AXSukKYdzkMB+JopFAoxMTERAwMDvS6FHHi/u+PSpUuxf//+jqezAjzKrPkCAADIgfAFAACQg429LgCAfLW75bzpZADQXcIXwCNGqAKA3jDtEAAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByUEjTNO11EQC9VCgUYufOnfH973+/16WQg8uXL3u/u+DTTz+NcrkcPkYAtE/4Ah55+/bt63UJLOFf/uVfIiLimWee6XElLOXdd9/tdQkADw3hC4B1a2BgICIiLl261ONKAGDtrPkCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyEEhTdO010UAwN///d/H3/3d38WXX37ZOHbz5s2IiPjBD37QOPbYY4/FX/7lX8bhw4dzrxEA1kL4AmBdqFQq8ad/+qdttZ2eno6+vr4HXBEAdJfwBcC68cd//MeNu11L2bFjR/z617/OqSIA6B5rvgBYNwYHB2PTpk1LPr9p06b4yU9+kmNFANA97nwBsG7cunUrduzYEcv90/TrX/86duzYkWNVANAd7nwBsG489dRT8Wd/9mdRKBQWPVcoFOLZZ58VvAB4aAlfAKwrr7zySmzYsGHR8Q0bNsQrr7zSg4oAoDtMOwRgXanVavG9732vacv5iPtbzN+5cye++93v9qgyAFgbd74AWFe2bt0azz//fNPdrw0bNsTu3bsFLwAeasIXAOvO4OBgW8cA4GFi2iEA685vf/vbePzxx+Pzzz+PiPtbzNdqtfjDP/zDHlcGAKvnzhcA6863v/3t+PM///PYuHFjbNy4MV566SXBC4CHnvAFwLp05MiR+OKLL+KLL76Iw4cP97ocAFizjb0uAKDXLl261OsSaOHzzz+PzZs3R5qm8bvf/c77tE4NDAz0ugSAh4Y1X8Ajr9Uf9AXa42MEQPtMOwSIiImJiUjT1GOdPT744IP4h3/4h65e0/vdncfExESP/1cL8PAx7RCAdWvv3r29LgEAukb4AmDd2rjRP1MAfH2YdggAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAB2o1WoxPj4e/f39a2rzoF4bAFi/hC+ADpw8eTIOHjwYpVJpTW1W49VXX13Vdc+fPx+FQqGrteStVqvF8PBwFAqFKBQKMT4+3pM6yuVyUx3Dw8NRqVSiVqv1ZIxnZ2fj2LFjUSgU4tixY3HlypWm57M6Wz3OnDkTpVIp5ubmcq8b4FElfAF04Ny5c11psxqTk5Mdn1OpVOLo0aMPoJr81Gq1uHXrVpw6dSrSNI2xsbE4ePBgnDlzJtc6hoeH4+LFizE4OBhpmkaapvH666/H7OxsbNu2LddaIiLm5uaiUqnEuXPnol6vx+7du2PPnj1N4TxN06hWq43v6/V6o/a9e/fG+fPnY3BwMGq1Wu71AzyKhC+Ar6m5ubm4fPlyr8tYs1u3bsXOnTsb3x84cCAiIt58883casjucJ07dy6efvrpxvGtW7dGkiRx7dq13GrJXL16NZIkiYiILVu2NMZl4bTUrVu3Nr7esmVL4+u+vr64cOFCRNy/q+oOGMCDJ3wBrFKtVoszZ840pnzNzs6ueM7c3FyMj483pn6dP39+0V2HVm2WcuXKlaapZPNduHAhXn/99dV1rs1aluvPwjVqpVIpCoVC9Pf3x+zsbJTL5UVT4TLZuBYKhfijP/qjRa8ZEVEsFtfUt3aVy+V466234sSJE0u2mR8OI/IZl76+vpa1DA0Ntd23rVu3xhtvvBGlUimuXr3a9nkArI7wBbBKt27diuPHj0e1Wo07d+7E9u3bV5y+NTg4GHfv3m1MByuVSovuOgwODsaNGzca08M++eSTGB4ebnm9HTt2xOjoaFSr1UjTtHH8ypUr8aMf/ajprsdqrFTLcv2Zv0atXC5HkiQxMzMTpVIp3n777di5c2dMTU1FxP0gNb/+48ePR7FYjOnp6XjyyScbx2dnZ+P06dON187De++9FxERTz311LLt5tef97hEfBVKX3rppY769+yzz0ZExPvvv9/ReQCsQgrwiIuIdGJioqP2C3993rx5M42IdHR0dMk2U1NTaUSk1Wq1cezatWtpRKRjY2Npmqbp2NhYyzZJkiy67vT0dOO8+arVaqOOpWppx0q1tNOfVq+98FixWEwjIq3X641j9Xo9LRaLTefNzMw0zo2I9PTp0x33KXv9tb7fy8l7XOa/bpIkTe3b7cNqfkYmJiZW9XMF8Chz5wugC7J1QMttbvHuu+9GRPManGeeeSYiIt55552m/85vs3PnzkWbbZTL5RgZGWms85nvl7/8Zbz22mur6UaTlWpppz/tePnllyMi4oMPPmgcu379euN45sknn4w0TWN6ejqKxWK8+eaby07J7JW8xyVz9uzZOHHiRNO6LgDWF+ELICcjIyOLjmUflLMd6trdRv727dsxMjIS5XK56XipVIof//jHa6z0q2stp53+tKOvry+SJGkKJh999NGSa5r6+voaUw7z2MkxW0PV7oYUvRiX8fHxSJJk0dqzduS9hg7gUSZ8AXTRcpsdZDvTtVoXlp2XtalUKsu+zoEDB6JYLMauXbuartff3x/bt29vuVlDp3+HaqVa2ulPuw4dOtRYAzU7OxvPPffcsu3n7zj4oGVrqG7fvt1W+7zHpVKpxI0bN1Z9t/P69esREfHCCy+s6nwA2id8AXRBFlB27969ZJtDhw5FxP2NOjLZXYd9+/ZFxFcf3EdGRhrPZX9Id6E333wzkiSJkydPNo6lv98YY/5j/nOdWKmWdvrTrhdffDEiIi5evBgff/xxPP/888u2z15nbGyso9dZjSRJIkmSlne0MrOzs42/O5bnuNRqtfjwww/j1KlTjWOVSqXlz0srtVotzp49G0mSNF4LgAeoh+vNANaF6HADhiRJ0ohIp6am0jS9v8FFkiSNDSCq1WpjA4P5my7U6/U0SZI0SZLG8bGxsXRoaKjRJrtWzNtYYmhoKL1582bTdbNNFbJNKOZvsNGqf6v5db9cLe30p1W99Xq95dik6VcbTCzcSCMb25mZmcY1isXikhtPrKTT9zvrS5IkTf3PzMzMNI1BXuPS6v3JHpOTk4128689fzOO6enpRXV2woYbAJ3zWxN45K3mw3i2s1wWSLIgll1v/mO+bCfC7LmxsbFFu9NVq9XGB+5isdj4sN/qutnOessFrNWGr+Vqaac/repdbmymp6fTiFj0GpOTk4t2Obx27dqq+pPV0On7nab3Q8zk5GQ6NDTUqCVJknR0dLQRDDN5jMv8OhY+lvqZ6eY4Cl8AnSukaYfzUAC+ZgqFQkxMTMTAwECvSyEH3u/uuHTpUuzfv7/j6awAjzJrvgAAAHIgfAEAAORgY68LACBf7W45bzoZAHSX8AXwiBGqAKA3TDsEAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBxs7HUBAOvBtWvXel0COfJ+r50xBOhcIU3TtNdFAPRSoVDodQnw0PIxAqB97nwBjzwfHtevgYGBiIi4dOlSjysBgLWz5gsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgBxt7XQAARET80z/9U1QqlaZjt27dioiI0dHRpuM//OEPY+fOnbnVBgDdIHwBsC7UarX4H//jf8SGDRviscfuT8xI0zQiIn76059GRMSXX34ZX3zxRUxOTvasTgBYrUKa/csGAD30+eefx+OPPx6//e1vl233rW99Kz777LPYvHlzTpUBQHdY8wXAurBp06Y4cODAsqFq06ZNcfDgQcELgIeS8AXAunHw4MG4d+/eks9//vnncejQoRwrAoDuMe0QgHXjyy+/jD/6oz+KarXa8vknnngi/u///b+NNWEA8DDxrxcA68Zjjz0WR44caTmtcPPmzfHf//t/F7wAeGj5FwyAdWWpqYf37t2LgwcP9qAiAOgO0w4BWHd27NgR//t//++mY9u3b4/bt2/3piAA6AJ3vgBYd44cORKbNm1qfL958+b4yU9+0sOKAGDt3PkCYN35X//rf8V//a//tenYzZs34+mnn+5RRQCwdu58AbDu7NixI374wx9GoVCIQqEQP/zhDwUvAB56whcA69Irr7wSGzZsiA0bNsQrr7zS63IAYM1MOwRgXfo//+f/xH/5L/8l0jSN2dnZ+P73v9/rkgBgTYQv4KFTKBR6XQLwgPhYAnydbex1AQCr8cYbb8SuXbt6XQarsH///rbfvw8//DAKhULs2bMnh8ropWvXrsXZs2d7XQbAA+XOF/DQKRQKMTExEQMDA70uhVXo5P37f//v/0VExHe+850HXRY9dunSpdi/f787X8DXmjtfAKxbQhcAXyd2OwQAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfwNdarVaL8fHx6O/vX1ObB/XaD6Ova7/Wk6XGeHh4OIaHh3tUFQBrJXwBX2snT56MgwcPRqlUWlOb1Xj11VdXdd3z589HoVDoai3d9KDGq5VCodD0KJfLS7Ytl8uL2j+oOrJHf39/nD9/Pmq1WtdeKyLfMc7Mzs7GsWPHolAoxLFjx+LKlStNzy81BoVCIc6cOROlUinm5uZyqxfgYSR8AV9r586d60qb1ZicnOz4nEqlEkePHn0A1XTPgxqvVtI0jZmZmcb3Fy9eXLLt/Oeq1WqkadrVOqrVatP3aZrGz3/+85idnY1t27bFr371q6693lJjfOrUqTh16lTXXiczNzcXlUolzp07F/V6PXbv3h179uxpCn8Lx6BerzfGYe/evXH+/PkYHBzsehAF+DoRvgDWibm5ubh8+XKvy1h3nnzyyYiIOH36dIyMjMTs7OyiNrOzs7Fjx47G91u3bu16Ha2u+eSTT8brr78eERE/+9nPuv6aebl69WokSRIREVu2bIkDBw5ERCya9jh/DLZs2dL4uq+vLy5cuBAR9+/4ugMG0JrwBTwyarVanDlzpjGtqtWH+IXm5uZifHy8Mb2q1RSzVm2WcuXKlSWnxV24cKHxQX41fSuVSo0Py9nUxWPHji26I7PaPvX6jsbevXsjIuLjjz9e9NzHH3/ceL6Vubm5xpgUCoUYHh5u9KfVVMVOpi9mgWRkZKTp9bo9xq3WgS08ViqVGtMhF/58X7lyJfr7+xvTBOe/Vha8FhoaGlq27/Nt3bo13njjjSiVSnH16tW2zwN4lAhfwCPj1q1bcfz48ahWq3Hnzp3Yvn37ioFicHAw7t6925hyVSqVFv0/+4ODg3Hjxo3GFKxPPvlkyU0RduzYEaOjo4umxV25ciV+9KMfrfqOzbZt26K/vz9KpVKUy+V47bXXol6vR0TED37wg6YA1m6fVmqTt76+vhgaGoqDBw8ueu4f//Efo6+vb8lz/+f//J9x9OjRqFarMTMzE2+99VacPHkyIu5PpxsdHY2IaEyrq1arkSRJTE9Przh9MRuT+UHlQYxxqzWE84+Vy+VIkiRmZmaiVCrF22+/3WhXKpViz549ceLEiUjTNP7zf/7PsW3btiXDZVbDSy+9tGzfF3r22WcjIuL999/v6DyAR0YK8JCJiHRiYqKj9gt/3d28eTONiHR0dHTJNlNTU2lEpNVqtXHs2rVraUSkY2NjaZqm6djYWMs2SZIsuu709HTjvPmq1WqjjqVqWW0/p6en04hIT58+3Xaf2mmz2hqzczt5/7Jz5td27dq1pj5OTU0tW1exWEyHhoaarrew3dDQUKPfp0+fbur/wvOmp6fTNE3Ter2eFovFppoe5Biv9thSbbKfi4WmpqbSJEnSer2+5BgsZbU/GxMTE6v+mQJ4WPgtBzx0uhG+Fh5f7sP4fPV6PY2IRrhKkqStD6LXrl1r+vA/3/zgtVy9K2mnn+30qZ02vQpf2dfzx7JYLDY9t1xdMzMz6enTp1u2q1arjT7evHlzyToWPorFYiOMpemDHePVHmv1esuNVZIkTQG33fPaeX4pwhfwKPBbDnjo5BW+Vnteq7bZHbKFH2gnJyfTmZmZtl53JWupt1tt2q1zLeErG8uZmZm0Wq023U1crq7R0dFGsFqq3VLvUzvXX6lNN8Z4tceyO6DZWC28Izrf2NjYov9DoJ3+pelXAXJ+IG6X8AU8Cqz5Ah5py20okG1C0GpdWHZe1qZSqSz7OgcOHIhisRi7du1qul5/f39s37695eYO3fw7VQvrbadPy7Xppf/23/5bRNzfZOPKlSuN75czPj4eR48ejZ///Ofx9NNPt2xTq9Xizp07cfr06UXvUyfW4xj39fXF5ORk3Llzp7HhyNjYWBw/frypXaVSiRs3bsRrr722qte5fv16RES88MILa64Z4OtI+AIeSVlY2r1795JtDh06FBH3N+rIZBsR7Nu3LyK++hA9MjLSeC77Y7ULvfnmm5EkSWOjh4hobNIx/zH/ubXKNtrINk5op0/ttOmlJ598MorFYhw8eDDu3LnT2Ip+OdkmHcu1/cUvfhHHjx+PV199ddH71In1OMalUimef/75OH78eKRpGpOTk43t5DO1Wi0+/PDDpr8jVqlUWv4st1Kr1eLs2bORJEm8+OKLXa0f4Gujh3fdAFYlOpy2lq3LyjZlqFaraZIkjSlX2VqfiOYNEOr1epokSZokSeP42NhY03qj7FrZ+fH79Ug3b95sum62ccHMzEwaEaue1rWc7Lxsalm2GUS2hqjdPq3UZqnx6qTOTt6/7PXmv1Y2bW7+Wqvl6sreo5mZmaZph9VqtTFO8zeXaDV9Lju2Ur8f1BivdCyrv1Wd838+F/6sVqvVlj/H2WNycrLlGMwfr+np6UX96ZRph8CjwG854KHT6Yf3NP1q97bsA2cWxLLrzX/Ml+1EOD/YLNwBrlqtNna8KxaLjc0aWl032+VuuYC11vCVfRDOQl6retvp01Jtlhuvduts9/1rFQYyrXYvXKptFtaKxWLj/RoaGmqE4YXtl7peu31/EGO8lmPzfyZaBbBsQ45Wj6V+nuc/Tp8+veQ6uXYJX8CjoJCmXZjXApCjQqEQExMTMTAw0OtS1pVsjdh6/7Xu/cvfr371q/hP/+k/LZp2+atfmnKGUAAAIABJREFU/Sp+8IMfrIufmUuXLsX+/fvXRS0AD4o1XwDwNTY+Ph5PP/10y/Vu27Zti7GxsR5UBfBo2tjrAgBYu/m75tVqtdi6dWsPq2E9eeedd+Lu3bvx4x//uCmA/epXv4p//Md/XPXOhgB0zp0vgHVu/jb0Sz22bdvWaD//a/jFL34R3/rWt+Ltt99u/LwMDw/Hp59+KngB5MydL4B1zhoY1mLLli1x4MCBOHDgQJw7d67X5QA80tz5AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcFNI0TXtdBEAnCoVCr0sAHhAfS4Cvs429LgCgUxMTE70ugZz87Gc/i4iIv/7rv+5xJQCwdu58AbBuDQwMRETEpUuXelwJAKydNV8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHGzsdQEAEBHx7//+7/G73/2u6di9e/ciIuLf/u3fmo5/4xvfiG9+85u51QYA3VBI0zTtdREA8Ld/+7fx05/+tK22P//5z+Ov/uqvHnBFANBdwhcA68JvfvOb+N73vhdffPHFsu02bNgQ//qv/xpPPPFETpUBQHdY8wXAuvDEE0/Eiy++GBs2bFiyzYYNG2LPnj2CFwAPJeELgHXjyJEjsdyEjDRN48iRIzlWBADdY9ohAOvG3bt344knnli08UZm8+bN8Zvf/Ca+/e1v51wZAKydO18ArBvf+ta34i/+4i9i06ZNi57buHFj9Pf3C14APLSELwDWlcOHD8d//Md/LDr+xRdfxOHDh3tQEQB0h2mHAKwr9+7di8cffzzu3r3bdPwP/uAP4rPPPotvfOMbPaoMANbGnS8A1pXNmzfHyy+/HJs3b24c27RpUwwMDAheADzUhC8A1p1Dhw7FvXv3Gt9//vnncejQoR5WBABrZ9ohAOvOl19+Gdu2bYvPPvssIiK+853vRLVaXfZvgAHAeufOFwDrzmOPPRaHDx+OzZs3x6ZNm+LIkSOCFwAPPeELgHXp4MGDce/ePVMOAfja2NjrAgB6bd++fb0ugSV885vfjIiIv/mbv+lxJSzl3Xff7XUJAA8Nd76AR97ly5fj008/7XUZtLB9+/bYvn17V6/p/e6OTz/9NC5fvtzrMgAeKjbcAB55hUIhJiYmYmBgoNelsMCNGzciIuJP/uRPunZN73d3XLp0Kfbv3x8+RgC0z7RDANatboYuAOg10w4BAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCF0AHarVajI+PR39//5raPKjXBgDWL+ELoAMnT56MgwcPRqlUWlOb1Xj11Vfbvm6lUolCodB4HDt2rKu15G1ubi7K5XKcP3++p+GzXC7H8PBwY1yHh4ejUqlErVaLQqGQez2zs7Nx7Nixxnt85cqVpufn/wwsfJw5cyZKpVLMzc3lXjfAo0r4AujAuXPnutJmNSYnJ9tu+8///M9N37/00kvdLidXp0+fjvfeey+OHj3a9VDbruHh4bh48WIMDg5GmqaRpmm8/vrrMTs7G9u2bcu9nrm5uahUKnHu3Lmo1+uxe/fu2LNnT9P4pGka1Wq18X29Xm/Uvnfv3jh//nwMDg5GrVbLvX6AR1EhTdO010UA9FKhUIiJiYkYGBhou33E/Q+2a2mzGu1et1QqRZIkXX3t9aAb49rp+x0RjTtcSwXgcrkcu3bt6vr7vZxW7/FS47PU8VqtFq+++mpERPziF7+ILVu2tP36ly5div379+faZ4CHnTtfAKtUq9XizJkzjSlfs7OzK54zNzcX4+Pjjalf58+fX3TXoVWbpVy5cqVpKlnE/alo/f39MTw8HOVyeU19XKmW5fqzcI1aqVSKQqEQ/f39MTs7G+VyedFUuEw2roVCoa1xfZDK5XK89dZbceLEiSXb7Ny5s+n7PMalr6+vZS1DQ0Nt923r1q3xxhtvRKlUiqtXr7Z9HgCrI3wBrNKtW7fi+PHjUa1W486dO7F9+/YVp28NDg7G3bt3G9PBSqVSvPrqq03rbgYHB+PGjRuN6WGffPJJDA8Pt7zejh07YnR0NKrVauMORKVSiYiIt956K3bt2hX9/f2rnla2Ui3L9Wf+GrVyuRxJksTMzEyUSqV4++23Y+fOnTE1NRUREcVisekOyvHjx6NYLMb09HQ8+eSTq6q9W957772IiHjqqaeWbTe//l6MS/Yz1OkU02effTYiIt5///2OzgNgFVKAR1xEpBMTEx21X/jr8+bNm2lEpKOjo0u2mZqaSiMirVarjWPXrl1LIyIdGxtL0zRNx8bGWrZJkmTRdaenpxvnLVSv19Pp6em0WCw21dWJlWpppz+txmHhsazGer3eVH+xWFxUU6vrdaob7/dyejEu2esmSdLUvt0+rGZcJyYm1vxeADxq3PkC6IKnn346IiKOHj26ZJt33303Iu5P9co888wzERHxzjvvNP13fpudO3cuWmtULpdjZGQkDhw40PK1tmzZEn19fXHq1KkYHR1d1SYVK9XSTn/a8fLLL0dExAcffNA4dv369cbxh02vxuXs2bNx4sSJjtZtAZAv4QsgJyMjI4uOZR+Us3DUbki6fft2jIyMtLWma2BgYFXha6Vz2ulPO/r6+iJJkqZg8tFHHy25pilv2Rqqdrdk78W4jI+PR5Iki9aetSPrV7FY7PhcADojfAF00XKbHWQ707Vaf5Wdl7XJ1m0t5cCBA1EsFmPXrl0rrufasmVLR5swLKx3qVra6U+7Dh061FgDNTs7G88991yH1T442Rqq27dvt9U+73GpVCpx48aNeO211zq6dub69esREfHCCy+s6nwA2id8AXRBFlB27969ZJtDhw5FxP2NOjLZXYd9+/ZFxFcf3EdGRhrPZX9Id6E333wzkiSJkydPLlvb3Nxc4/qdWKmWdvrTrhdffDEiIi5evBgff/xxPP/88x3X+6AkSRJJkrS8o5WZnZ2NM2fORES+41Kr1eLDDz+MU6dONY5VKpW2/6h2rVaLs2fPRpIkjdcC4AHq9aIzgF6LDjdgSJIkjYh0amoqTdM0rVaraZIk6enTpxvfx+83MJi/6UK9Xk+TJEmTJGkcHxsbS4eGhhptsmtl50dEOjQ0lN68ebPputmmCjMzM00baoyNjTXqyp6fnJxc1bgsV0s7/WlVb71ebzk2afrVBhPZOC40/9xWm0q0q9P3O02/Gov5/c/MzMw0jUFe49Lq/cke89/zpcZtenp6UZ2dsOEGQOf81gQeeav5MJ7tLJcFkvmBZ+EH4fmq1Wo6OjraeG5sbGxRkKhWq40P3MVisfFhv9V1s5315n/ozr4uFovp9PT0aoZkxVra6U+repcbm+np6TQiFr1Gq/Nand+u1bzfaXo/xExOTqZDQ0ON10+SJB0dHU1nZmaa2uYxLvPrWPhY6mdm/uP06dPptWvXOh6HjPAF0LlCmvrT9MCjrVAoxMTERAwMDPS6FHLg/e6OS5cuxf79+8PHCID2WfMFAACQA+ELAAAgBxt7XQAA+SoUCm21M50MALpL+AJ4xAhVANAbph0CAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA4KaZqmvS4CoJcKhULs3Lkzvv/97/e6FHJw+fJl73cXfPrpp1Eul8PHCID2CV/AI2/fvn29LoEl/Mu//EtERDzzzDM9roSlvPvuu70uAeChIXwBsG4NDAxERMSlS5d6XAkArJ01XwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5EL4AAAByIHwBAADkQPgCAADIgfAFAACQA+ELAAAgB8IXAABADoQvAACAHAhfAAAAORC+AAAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QsAACAHwhcAAEAOhC8AAIAcCF8AAAA5KKRpmva6CAD4+7//+/i7v/u7+PLLLxvHbt68GRERP/jBDxrHHnvssfjLv/zLOHz4cO41AsBaCF8ArAuVSiX+9E//tK2209PT0dfX94ArAoDuEr4AWDf++I//uHG3ayk7duyIX//61zlVBADdY80XAOvG4OBgbNq0acnnN23aFD/5yU9yrAgAusedLwDWjVu3bsWOHTtiuX+afv3rX8eOHTtyrAoAusOdLwDWjaeeeir+7M/+LAqFwqLnCoVCPPvss4IXAA8t4QuAdeWVV16JDRs2LDq+YcOGeOWVV3pQEQB0h2mHAKwrtVotvve97zVtOR9xf4v5O3fuxHe/+90eVQYAa+POFwDrytatW+P5559vuvu1YcOG2L17t+AFwENN+AJg3RkcHGzrGAA8TEw7BGDd+e1vfxuPP/54fP755xFxf4v5Wq0Wf/iHf9jjygBg9dz5AmDd+fa3vx1//ud/Hhs3boyNGzfGSy+9JHgB8NATvgBYl44cORJffPFFfPHFF3H48OFelwMAa7ax1wUA9NqlS5d6XQItfP7557F58+ZI0zR+97vfeZ/WqYGBgV6XAPDQsOYLeOS1+oO+QHt8jABon2mHABExMTERaZp6rLPHBx98EP/wD//Q1Wt6v7vzmJiY6PH/agEePqYdArBu7d27t9clAEDXCF8ArFsbN/pnCoCvD9MOAQAAciB8AQAA5ED4AgAAyIHwBQAAkAPhCwAAIAfCFwAAQA6ELwAAgBwIXwAAADkQvgAAAHIgfAEAAORA+AIAAMiB8AUAAJAD4QugA7VaLcbHx6O/v39NbR7UawMA65fwBdCBkydPxsGDB6NUKq2pzWq8+uqrbV+3UqlEoVBoPI4dO9bVWvI2Ozsbx44da/TlypUrPamjXC7H8PBwY1yHh4ejUqlErVaLQqGQez0rjcv8n4GFjzNnzkSpVIq5ubnc6wZ4VAlfAB04d+5cV9qsxuTkZNtt//mf/7np+5deeqnb5eRmbm4uKpVKnDt3Lur1euzevTv27NnT9XC7kuHh4bh48WIMDg5GmqaRpmm8/vrrMTs7G9u2bcu1loj2xiVN06hWq43v6/V6o/a9e/fG+fPnY3BwMGq1Wu71AzyKhC+Ar6Hvfve7jQ/ZaZpGkiS9LmnVrl692qh/y5YtceDAgYiIXKdfZne4zp07F08//XTj+NatWyNJkrh27VputWTaHZetW7c2vt6yZUvj676+vrhw4UJE3L+r6g4YwIMnfAGsUq1WizNnzjSmfM3Ozq54ztzcXIyPjzemfp0/f37RXYdWbZZy5cqVpqlkEfenovX398fw8HCUy+U19XGlWpbrz8I1aqVSKQqFQvT398fs7GyUy+VFU+Ey2bgWCoXo6+trWdvQ0NCa+taucrkcb731Vpw4cWLJNjt37mz6/mEZl61bt8Ybb7wRpVIprl692vZ5AKyO8AWwSrdu3Yrjx49HtVqNO3fuxPbt21ecvjU4OBh3795tTAcrlUqL7joMDg7GjRs3GnetPvnkkxgeHm55vR07dsTo6GhUq9VI0zQi7q/3ioh46623YteuXdHf37/qaWUr1bJcf+avUSuXy5EkSczMzESpVIq33347du7cGVNTUxERUSwWG/VHRBw/fjyKxWJMT0/Hk08+2VRTNlZ5TaV87733IiLiqaeeWrbd/PofpnF59tlnIyLi/fff7+g8AFYhBXjERUQ6MTHRUfuFvz5v3ryZRkQ6Ojq6ZJupqak0ItJqtdo4du3atTQi0rGxsTRN03RsbKxlmyRJFl13enq6cd5C9Xo9nZ6eTovFYlNdnViplnb602ocFh7LaqzX6031F4vFlnVNTU2lSZI0te9EN97v5azHcVmpD532MU3TdGJiouNzAB517nwBdEG2Dujo0aNLtnn33XcjonkNzjPPPBMREe+8807Tf+e32blz56LNNsrlcoyMjDTW+Sy0ZcuW6Ovri1OnTsXo6OiqNqdYqZZ2+tOOl19+OSIiPvjgg8ax69evN44vdPbs2Thx4kTT+qX1xLgAsBThCyAnIyMji45lH5SzcNRuSLp9+3aMjIy0taZrYGBgVeFrpXPa6U87+vr6IkmSpmDy0UcftVzTND4+HkmSLFpj9SBla6ja3ZDiYRuXrF/FYrHjcwHojPAF0EXLbXaQ7UzXav1Vdl7WJlu3tZQDBw5EsViMXbt2rbiea8uWLavanGKlWtrpT7sOHTrUWAM1Ozsbzz333KI2lUolbty4Ea+99lpH116rbA3V7du322r/sI3L9evXIyLihRdeWNX5ALRP+ALogiyg7N69e8k2hw4dioj7G3VksrsO+/bti4ivPriPjIw0nsv+kO5Cb775ZiRJEidPnly2trm5ucb1O7FSLe30p10vvvhiRERcvHgxPv7443j++eebnq/VavHhhx/GqVOnGscqlUoufzw6SZJIkqTlHa3M7OxsnDlzJiIernGp1Wpx9uzZSJKk8VoAPEC9XnQG0GvR4QYMSZKkEZFOTU2laZqm1Wo1TZIkPX36dOP7+P0GBvM3XajX62mSJGmSJI3jY2Nj6dDQUKNNdq3s/IhIh4aG0ps3bzZdN9tUYWZmpmlDjbGxsUZd2fOTk5OrGpflammnP63qrdfrLccm/f/t3X90VPWd//HXkB/2aBFaMUFUaF2K1e0x2223B7SrX364VfRGBSYhQOLpWbVht93VA3/s8UyWPQdP+0fDKWePe6BB9xSyJT8GETOLWgW6dbck9iw9k7OlbaClJAXrjFCT0qJC4X7/oPc6M5mZ3JnMfO4keT7OmaPcufO57/tz7iv33s/YH3Yw4SzHbHU4r3zmLdf1nVhD4vw7BgcHk5ZBqS2XxLYTO+OIRqOj6swFHW4AQO44agKY8vI5GXd6lnMCSWLgST0RThSLxey2tjb3vY6OjlG908ViMfeEOxQKuSf76dp1etZLPOl2/j8UCtnRaDSfRTJmLV7mJ1292ZZNNBq1JY2aRnNzc9qAkW5cL/JZ37Z9JcT09PQk1WNZlt3W1mYPDg4mjVsqyyXT+06Y6+3tzXk5OAhfAJC7gG0n/IAIAExBgUBAXV1dqqur87sUGMD6Lozu7m7V19eL0wgA8I5nvgAAAADAAMIXAAAAABhQ7ncBAACzAoGAp/G4nQwAgMIifAHAFEOoAgDAH9x2CAAAAAAGEL4AAAAAwADCFwAAAAAYQPgCAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYEC53wUAQCno7e31uwQYxPoeP5YhAOQuYNu27XcRAOCnQCDgdwnAhMVpBAB4x5UvAFMeJ4+lq66uTpLU3d3tcyUAAIwfz3wBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AAAAAMIDwBQAAAAAGEL4AAAAAwADCFwAAAAAYQPgCAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIAB5X4XAACAJL355pvq7+9PGnbixAlJUltbW9LwO+64QwsXLjRWGwAAhUD4AgCUhHg8rq985SsqKyvTtGlXbsywbVuS9NWvflWSdPnyZV26dEk9PT2+1QkAQL4CtvPNBgCAjy5evKhZs2bpd7/7Xdbxpk+frjNnzqiystJQZQAAFAbPfAEASkJFRYVWr16dNVRVVFSooaGB4AUAmJAIXwCAktHQ0KALFy5kfP/ixYtas2aNwYoAACgcbjsEAJSMy5cva86cOYrFYmnfv/766/X222+7z4QBADCR8O0FACgZ06ZN07p169LeVlhZWalHH32U4AUAmLD4BgMAlJRMtx5euHBBDQ0NPlQEAEBhcNshAKDkzJ8/X7/85S+Ths2bN08nT570pyAAAAqAK18AgJKzbt06VVRUuP+urKzUl7/8ZR8rAgBg/LjyBQAoOb/4xS/0qU99KmnYwMCAFixY4FNFAACMH1e+AAAlZ/78+brjjjsUCAQUCAR0xx13ELwAABMe4QsAUJKamppUVlamsrIyNTU1+V0OAADjxm2HAICS9NZbb+nmm2+WbdsaGhrSTTfd5HdJAACMC+ELwJQXCAT8LgGYsDiNAADvyv0uAABKwZNPPqlFixb5XQZSHDhwQIFAQEuXLi1Ym/X19azvAujt7dXWrVv9LgMAJhSufAGY8gKBgLq6ulRXV+d3KUhx9uxZSdJ1111XsDZZ34XR3d2t+vp6rnwBQA648gUAKFmFDF0AAPiN3g4BAAAAwADCFwAAAAAYQPgCAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBQA7i8bg6OztVW1s7rnGKNW0AAFC6CF8AkINNmzapoaFBkUhkXOPk47HHHvPcbn9/vwKBgPtav359QWsxLR6Pq6WlxZ2fzs5OX+ro6+tLqqOlpUX9/f2Kx+MKBALG6xkaGtL69evddXzo0KGk9xO3gdTXli1bFIlENDIyYrxuAJiqCF8AkINt27YVZJx89PT0eB73Rz/6UdK/ly9fXuhyjInH4zpx4oQ2b94s27bV0dGhhoYGbdmyxWgdLS0t2rlzpxobG2Xbtmzb1te+9jUNDQ2purraaC2SNDIyov7+fm3btk3Dw8O65557tHTp0qRwbtu2YrGY++/h4WG39mXLlmnHjh1qbGxUPB43Xj8ATEWELwCYhGbPnu2eZNu2Lcuy/C4pbydOnNDChQvdf69evVqStHHjRmM1OFe4tm3bpgULFrjDq6qqZFmWent7jdXieOONN9z1OmPGDHe5pN6WWlVV5f7/jBkz3P+vqanRc889J+nKVVWugAFA8RG+ACBP8XhcW7ZscW/5GhoaGvMzIyMj6uzsdG/92rFjx6irDunGyeTQoUNJt5JJV25Fq62tVUtLi/r6+sY1j2PVkm1+Up9Ri0QiCgQCqq2t1dDQkPr6+kbdCudwlmsgENCcOXNGTVOSQqHQuObNq76+Pj3zzDN6+umnM46TGA4lM8ulpqYmbS3Nzc2e562qqkpPPvmkIpGI3njjDc+fAwDkh/AFAHk6ceKENmzYoFgsptOnT2vevHlj3r7V2Nioc+fOubeDRSKRUVcdGhsbdfToUfeq1Y9//GO1tLSkbW/+/Plqa2tTLBaTbduSrjzvJUnPPPOMFi1apNra2rxvKxurlmzzk/iMWl9fnyzL0uDgoCKRiL7xjW9o4cKFOnjwoKQrQcqpX5I2bNigUCikaDSquXPnusOHhobU2trqTtuE/fv3S5JuueWWrOMl1m96uUgfhtJcbzH93Oc+J0l6+eWXc/ocACAPNgBMcZLsrq6unMZPPXwODAzYkuy2traM4xw8eNCWZMdiMXdYb2+vLcnu6Oiwbdu2Ozo60o5jWdaodqPRqPu5VMPDw3Y0GrVDoVBSXbkYqxYv85NuOaQOc2ocHh5Oqj8UCiV9bnBw0P2sJLu1tTXneXKmP971nY3p5ZI4Xcuyksb3Og+5zqNt23ZXV1fOnwGAqY4rXwBQAM5zQE888UTGccLhsKTkZ3Buu+02SdLu3buT/ps4zsKFC0d1ttHX16ft27e7z/mkmjFjhmpqarR582a1tbXl1fPiWLV4mR8vVq1aJUl65ZVX3GFHjhxxhzvmzp0r27YVjUYVCoW0cePGrLdk+sX0cnFs3bpVTz/9dNJzXQCA0kL4AgBDtm/fPmqYc6LshCOvIenkyZPavn27p2e66urq8gpfY33Gy/x4UVNTI8uykoLJ97///YzPNNXU1Li3HGYLu4XiPEPltUMKP5ZLZ2enLMsa9eyZF6afoQOAqYzwBQAFlK2zA6dnunTPXzmfc8ZxntvKZPXq1QqFQlq0aNGYz3PNmDEjp04YUuvNVIuX+fFqzZo17jNQQ0ND+sIXvpB1/MQeB4vNeYbq5MmTnsY3vVz6+/t19OhRPf744zm17Thy5IgkafHixXl9HgDgHeELAArACSj33HNPxnHWrFkj6UpHHQ7nqkMwGJT04Yn79u3b3fecH9JNtXHjRlmWpU2bNmWtbWRkxG0/F2PV4mV+vFqyZIkkaefOnTp8+LDuvvvurOM70+no6MhpOvmwLEuWZaW9ouUYGhpyf3fM5HKJx+M6cOCANm/e7A7r7+/3/KPa8XhcW7dulWVZ7rQAAEXk90NnAOA35dgBg2VZtiT74MGDtm3bdiwWsy3LcjuAiMVibgcGiZ0uDA8P25Zl2ZZlucM7Ojrs5uZmdxynLSV0LNHc3GwPDAwktet0quB0QuF0qNHR0eESeJ8IAAAgAElEQVTW5bzf09OT13LJVouX+UlX7/DwcNplY9sfdjCR2pGGs2wHBwfdNkKhUMaOJ8aS6/p25sWyrKT5dwwODiYtA1PLJd36cV6J6zyx7cTOOKLR6Kg6c0GHGwCQO46aAKa8fE7GnZ7lnECSGHhST4QTxWIxu62tzX2vo6NjVO90sVjMPeEOhULuyX66dp2e9RJPup3/D4VCdjQazWeRjFmLl/lJV2+2ZRONRm1Jo6aROE9OCOnt7c17nvJZ37Z9JcT09PTYzc3Nbi2WZdltbW1uMHSYWC6JdaS+Mm0zhVyOhC8AyF3AthN+QAQApqBAIKCuri7V1dX5XQoMYH0XRnd3t+rr68VpBAB4xzNfAAAAAGAA4QsAAAAADCj3uwAAgFmBQMDTeNxOBgBAYRG+AGCKIVQBAOAPbjsEAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwIGDbtu13EQDgp0Ag4HcJwITFaQQAeFfudwEA4Leuri6/S0AG3/rWtyRJTz31lM+VAAAwflz5AgCUrLq6OklSd3e3z5UAADB+PPMFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AAAAAMIDwBQAAAAAGEL4AAAAAwADCFwAAAAAYQPgCAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AAAAAMKDc7wIAAJCk8+fP64MPPkgaduHCBUnSu+++mzT8qquu0tVXX22sNgAACiFg27btdxEAAPzbv/2bvvrVr3oa99lnn9Xf//3fF7kiAAAKi/AFACgJ77zzjm644QZdunQp63hlZWX6zW9+o+uvv95QZQAAFAbPfAEASsL111+vJUuWqKysLOM4ZWVlWrp0KcELADAhEb4AACVj3bp1ynZDhm3bWrduncGKAAAoHG47BACUjHPnzun6668f1fGGo7KyUu+8846uvfZaw5UBADB+XPkCAJSM6dOn68EHH1RFRcWo98rLy1VbW0vwAgBMWIQvAEBJWbt2rf74xz+OGn7p0iWtXbvWh4oAACgMbjsEAJSUCxcuaNasWTp37lzS8I9+9KM6c+aMrrrqKp8qAwBgfLjyBQAoKZWVlVq1apUqKyvdYRUVFaqrqyN4AQAmNMIXAKDkrFmzRhcuXHD/ffHiRa1Zs8bHigAAGD9uOwQAlJzLly+rurpaZ86ckSRdd911isViWX8DDACAUseVLwBAyZk2bZrWrl2ryspKVVRUaN26dQQvAMCER/gCAJSkhoYGXbhwgVsOAQCTRrnfBQBAroLBoN8lwJCrr75akvTNb37T50pgSjgc9rsEACgarnwBmHD27NmjU6dO+V0G8pTL+ps3b57mzZtX5IpQCk6dOqU9e/b4XQYAFBUdbgCYcAKBgLq6ulRXV+d3KchDLuvv6NGjkqQ///M/L3ZZ8Fl3d7fq6+vFaQmAyYzbDgEAJYvQBQCYTLjtEAAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AAAAAMIDwBQAAAAAGEL4AAAAAwADCF4BJLR6Pq7OzU7W1teMap1jTnogm63yVkkzLuKWlRS0tLT5VBQAYL8IXgElt06ZNamhoUCQSGdc4+Xjsscc8t9vf369AIOC+1q9fX9BaCqlYyyudxGUSCATU19eXcdy+vr5R4xerDudVW1urHTt2KB6PF2xaktll7BgaGtL69evd7e/QoUNJ72daBoFAQFu2bFEkEtHIyIixegFgIiJ8AZjUtm3bVpBx8tHT0+N53B/96EdJ/16+fHmhyymYYi2vdGzb1uDgoPvvnTt3Zhw38b1YLCbbtgtaRywWS/q3bdt69tlnNTQ0pOrqah07dqxg08u0jDdv3qzNmzcXbDqOkZER9ff3a9u2bRoeHtY999yjpUuXJoW/1GUwPDzsLodly5Zpx44damxsLHgQBYDJhPAFACVg9uzZ7omsbduyLMvvkkrG3LlzJUmtra3avn27hoaGRo0zNDSk+fPnu/+uqqoqeB3p2pw7d66+9rWvSZK+9a1vFXyaprzxxhvuNjdjxgytXr1akkbd9pi4DGbMmOH+f01NjZ577jlJV674cgUMANIjfAGYMuLxuLZs2eLeVpXuJD7VyMiIOjs73dur0t1ilm6cTA4dOjTqtrihoSHV1taqpaUl6211Y81bJBJxT5Z37NjhzmfqFZl858nvKxrLli2TJB0+fHjUe4cPH3bfT2dkZMRdJoFAQC0tLe78pLtVMZfbF51Asn379qTpFXoZp3sOLHVYJBJxb4dM3b4PHTqk2tpa9zbBxGllCvvNzc1Z5z1RVVWVnnzySUUiEb3xxhuePwcAUwnhC8CUceLECW3YsEGxWEynT5/WvHnzxgwUjY2NOnfunHvLVSQSGfWX/cbGRh09etS9avXjH/84Y6cI8+fPV1tbW9Jtcf39/ZKkZ555RosWLVJtbW3OQae6ulq1tbWKRCLq6+vT448/ruHhYUnSrbfemhTAvM7TWOOYVlNTo+bmZjU0NIx67wc/+IFqamoyfvaf/umf9MQTTygWi2lwcFDPPPOMNm3aJOnK7XRtbW2S5N5WF4vFZFmWotHomLcvOsskMagUYxmne4YwcVhfX58sy9Lg4KAikYi+8Y1vuONFIhEtXbpUTz/9tGzb1o033qjq6uqM4dKpIdfbXz/3uc9Jkl5++eWcPgcAU4YNABOMJLurqyun8VMPdwMDA7Yku62tLeM4Bw8etCXZsVjMHdbb22tLsjs6Omzbtu2Ojo6041iWNardaDTqfi7V8PCwHY1G7VAolFRXLtLNQzQatSXZra2tnufJyzjpppVLnbmsP+czibX19vYmzePBgwez1hUKhezm5uak9lLHa25udue7tbU1af5TPxeNRm3bvrLenHXm1FTMZZzvsEzjONtFqoMHD9qWZdnDw8MZl0Em+W4bXV1deW9TADBRcJQDMOEUInylDs92Mp5oeHjYluSGK8uyPJ2I9vb2Jp38Z9PW1ua2nwsv8+llnryM41f4cv4/cVmGQqGk97LVNTg4aLe2tqYdLxaLufM4MDCQsY7UVygUcsOYbRd3Gec7LN30si0ry7KSAq7Xz3l5PxPCF4CpgKMcgAnHVPjK93PpxnWukGU6oU3knITnajz1Fmocr3WOJ3w5y3JwcNCOxWJJVxOz1eWEWueqZ7rxxlpPXua7mMs432HOFVBnWaVeEU3U0dGR9cprtmXgbLuJgdgrwheAqYBnvgBMadk6FHA6IUj3/JXzOWcc57mtTFavXq1QKKRFixaN+TzXjBkzcurowIvUer3MU7Zx/HTnnXdKutLJxqFDh9x/Z9PZ2aknnnhCzz77rBYsWJB2nHg8rtOnT6u1tdXTesqkFJdxTU2Nenp6dPr0abfDkY6ODm3YsCFpvP7+fh09elSPP/54XtM5cuSIJGnx4sXjrhkAJiPCF4ApyQlL99xzT8Zx1qxZI+lKRx0OpyOCYDAo6cOT6O3bt7vvOT9Wm2rjxo2yLMvt6CGTkZERt/3xcjracDpO8DJPXsbx09y5cxUKhdTQ0KDTp0+7XdFn43TSkW3c9vZ2bdiwQY899pin9ZRJKS7jSCSiu+++Wxs2bJBt2+rp6XG7k3fE43EdOHAg6XfE+vv7Pf/gdzwe19atW2VZlpYsWVLQ+gFg0vD70hsA5Eo53rbmPJfldMoQi8Vsy7LcW66cZ32k5A4QhoeHbcuybMuy3OEdHR1Jzxs5bTmf15+eRxoYGEhq1+m4YHBw0JY+7FCjo6PDrct5v6enJ+/looRby5zOIBKfH/MyT2ONk2l55VJnLuvPmV7itJzb5hKftcpWl7OOBgcHk247jMVi7nJK7Fwi3e1zzrCx5rtYy3isYU796epM3D5Tt9VYLJZ2O3ZeidtjYtuJyysajY6an1xx2yGAqYCjHIAJJ9eTd9v+sPc254QzMfCknmwmisVidltbW1KwSe0BLhaLuT3ehUIht7OGdO06vdwlntg6/5/acUOunHacE2En5KWr18s8ZRon2/LyWqfX9ZcuDDjS9V6YaVwnrIVCIXd9NTc3u2E4dfxM7Xmd92Is4/EMS9wm0gUwp0OOdK9M23Piq7W11dPzjNkQvgBMBQHbHuMHTACgxAQCAXV1damurs7vUkqK83tNpX5YZ/2Zd+zYMX3kIx8ZddvlsWPHdOutt5bENtPd3a36+vqSqAUAioVnvgAAmMQ6Ozu1YMGCtM+7VVdXq6Ojw4eqAGBqKve7AADA+CX2mhePx1VVVeVjNSglu3fv1rlz5/SlL30pKYAdO3ZMP/jBD/Lu2RAAkDuufAFAiQsEAmO+qqur3fET/x9ob2/X9OnT9Y1vfMPdXlpaWnTq1CmCFwAYxpUvAChxPAOD8ZgxY4ZWr16t1atXa9u2bX6XAwBTGle+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADAjYtm37XQQA5CIQCGjhwoW66aab/C4FedizZw/rD6OcOnVKfX194rQEwGRG+AIw4QSDQb9LgCE/+9nPJEm33Xabz5XAlHA47HcJAFA0hC8AQMmqq6uTJHV3d/tcCQAA48czXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AAAAAMIDwBQAAAAAGEL4AAAAAwADCFwAAAAAYQPgCAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYEDAtm3b7yIAAPjud7+r559/XpcvX3aHDQwMSJJuvfVWd9i0adP0t3/7t1q7dq3xGgEAGA/CFwCgJPT39+sv/uIvPI0bjUZVU1NT5IoAACgswhcAoGR8+tOfdq92ZTJ//nwdP37cUEUAABQOz3wBAEpGY2OjKioqMr5fUVGhL3/5ywYrAgCgcLjyBQAoGSdOnND8+fOV7avp+PHjmj9/vsGqAAAoDK58AQBKxi233KLPfvazCgQCo94LBAL63Oc+R/ACAExYhC8AQElpampSWVnZqOFlZWVqamryoSIAAAqD2w4BACUlHo/rhhtuSOpyXrrSxfzp06c1e/ZsnyoDAGB8uPIFACgpVVVVuvvuu5OufpWVlemee+4heAEAJjTCFwCg5DQ2NnoaBgDARMJthwCAkvO73/1Os2bN0sWLFyVd6WI+Ho9r5syZPlcGAED+uPIFACg51157re6//36Vl5ervLxcy5cvJ3gBACY8whcAoCStW7dOly5d0qVLl7R27Vq/ywEAYNzK/S4AAPzS3d3tdwnI4uLFi6qsrJRt2/rggw9YXyWurq7O7xIAoOTxzBeAKSvdD/kCyA+nEwAwNm47BDCldXV1ybZtXiX6euWVV/Tqq6/6Xke6F9vPlVdXV5fPezEATBzcdggAKFnLli3zuwQAAAqG8AUAKFnl5XxNAQAmD247BAAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AKKJ4PK7Ozk7V1tZ6HqelpUUtLS1jtu11vELzMk9+tgcAQKkq97sAAJjMNm3apO3bt497nJGREc2cOVO2bReyvLx4qdfP9kpRIBDI+F5ra6sWLFigu+++WzNmzDBYFQDAtIBdCt/kAOCDQCCgrq4u1dXVFX06krIGp7HGiUQiqq2tLYnwJXmbJz/bMyHX7Scej6u6ulqSNDw87Aat/v5+9wrmc889p6qqquIUXCTd3d2qr6+fUOsOAPzCbYcAUOJGRka0Y8cOv8vAOCWGqsQrXDU1NXruueckSY899phGRkaM1wYAMIPwBQAeOSEoEAgoEAiopaVF8Xh81DidnZ0KBAKqra3VsWPH0raTaZx0zz+1trYqEolIkjvtbM9JJbYfCAS0Y8cOt87Uz0UiEbeOoaGhnOY1X16WUTwe15YtW9xxDh06lFP9ktzPO/OfeOtfpvb9UlVVpSeffFKRSERvvPFG0ntTbVkAwKRmA8AUJcnu6uryPH5zc7MtyY7FYvbg4KAtyW5ubk4ax7Isu7m52R4eHrZt27Y7OjpsSXbi4TbbOJZljRrfqTW1jXTjOe+1tbXZtm3bsVjMtizLtizLHh4eTvpcb2+vbdt22nkZa14zTduLsZaRU3NHR4dt27Z98OBBW5IdjUY919/a2moPDg7atm3bw8PDdigU8tR+LnLdfpzPZFpuw8PDo+ZjIiyLrq6uvLcFAJhqOFoCmLJyPXkOhUJZA0hPT48tyR4YGHCHOSfUznhexvESvjINc06eY7GYO6y3t9eW5J5ge2lrrHnNN3x5mX8njKXWFwqFPNefugxisZjn9r0qdPhK9/5EWBaELwDwjtsOAcCjzZs3a9u2bRoaGtKWLVtGvf/yyy9LkhYsWOAOS+29zss44xEOhyUlP1902223SZJ2797tuZ2x5jVfXubfqdO55dG5Re6ZZ57xPJ3m5mZVV1ers7NTIyMjqqqqcjuEKET7prAsAGByIXwBQA527Nihr371q7Isa9R7XrpLL3aX6unad8KN89yYV9nmNV9e5t+p075yd0bSy6unnnpKlmWpoaFBM2fOTAqQhWi/GJyONkKhkDtsqi4LAJisCF8A4FFnZ6eeeOIJPfvss0lXbkqJE5TSdY7R3NzsuZ1SmNd0HXF4tWDBAvX09Cgajaq5uVkbN24cdQVvPO0Xw5EjRyRJixcvHvXeVFsWADBZEb4AwKOGhgZJ0ty5c9O+39bWJunK7zZl4mWc8VizZo0k6cSJE+4w54pKMBj03M5Y85qvXJZRe3u7W7vTI59XgUBAIyMjqqmp0bZt2xSNRrVx48aCtV9o8XhcW7dulWVZWrJkiTt8Ki4LAJjUTD5gBgClRDl2mOD0Ljc4OGgPDAy4HRs4nRk4Pc1ZluX2Lud0gKE/9UA31jgrVqwY1W7itGOxmN3a2up2mpA6ntOjoWVZ7vCOjg6384zEzzm9DSZ2eOF8Jtu8Zpq2F16WUWL7ia/BwUHP9etPnUY40xgcHLRbW1tHLYPU9nOR6/aTWKdTu23bbs+FievMMRGWBR1uAIB3HC0BTFm5njxHo1H3RDYWi7k9AiaeqA4ODrrdtDtBwunKOzGkZRon9SQ407QzjWfbV06o29ra3Pc6Ojrck/N0n0s3LNu8Zpu2F16XkdMleuIy9lp/YlCV5IaNxBrStZ+LXLafdAHHebW2trpdxWdaXqW8LAhfAOBdwLZ5qhbA1BQIBNTV1aW6ujq/S8EExPZzRXd3t+rr6+mkAwA84JkvAAAAADCA8AUAAAAABpT7XQAAYOJzfpx3LNyaBgCYyghfAIBxI1QBADA2bjsEAAAAAAMIXwAAAABgAOELAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwoNzvAgDAT729vX6XMIpt23rnnXdUVVXldykYg+nt57e//a0++tGPqrKy0uh0synFfQgASlXAtm3b7yIAwA+BQMDvEoBJg9MJABgbtx0CmLJs2/b99ZOf/ESbNm3SrbfeKkmaN2+e/uEf/kH//d//7XttpfAKBoMKBoO+11EqrzNnzmjnzp168MEHVV5erquvvloPPvigdu7cqT/84Q++1gYAGBtXvgDAsMHBQe3bt0/hcFg//OEPddNNN2nFihUKBoO66667uCKXoK6uTpLU3d3tcyWl58yZM3r55ZcVDof1yiuv6KqrrtIDDzygxsZG/c3f/I2uuuoqv0sEAKQgfAGAAadOndILL7ygcDisw4cP6+Mf/7iWL1+upqYmLVmyRNOmcSNCOoQvb06fPq09e/a429eMGTNkWZaCwaC+9KUvldQzYgAwlRG+AKBIzp49q/3796u9vV0HDx7UzJkz9eCDDyoYDOq+++5TRUWF3yWWPMJX7lKDPkEMAEoH4QsACujdd99VJBJROBzWq6++qsrKSvdWME58c0f4Gp9f//rX2rt3rxvE+AMAAPiL8AUA43T+/Hnt379fu3bt0muvvaZp06Zp2bJlCgaDWrlypa655hq/S5ywCF+FMzQ0pBdffNENYh/72Mf0wAMPEMQAwCDCFwDk4f3339frr7+ucDisvXv36o9//KPuvfdeBYNBPfLII5o+fbrfJU4KhK/iSO305brrrtPy5csVDAZ1//33q7ycnwEFgGIgfAGARx988IFee+01hcNh7du3T+fPn9fChQsVDAa1du1azZo1y+8SJx3CV/GdPHlSL730EkEMAAwgfAFAFpcuXVJvb6/C4bB2796t3/72t1q0aJGCwaBWr16t6upqv0uc1AhfZv3qV79ST0+PG8RmzZqlFStWqLGxUXfeeSe9cgLAOBG+ACDF5cuXdfjwYYXDYXV1dSkWi+n2229XU1OTGhsbNWfOHL9LnDIIX/45evSowuGwuru79bOf/YzfowOAAiB8AcCfHD16VO3t7Wpvb9dbb72l22+/XcFgUOvWrdP8+fP9Lm9KInyVBieIdXV16ec//7luvvlmPfLIIwQxAMgR4QvAlOacVH73u9/VL37xC912222qq6vT6tWr9elPf9rv8qY8wlfpcfaZzs5ODQwMaO7cuXr44YcJYgDgAeELwJTz05/+VN3d3e5f8RNPHr/4xS/6XR4SEL5KmxPEOjo6dOzYMc2bN08PPfQQQQwAMiB8AZgSUrvWvvHGG7Vy5UpOEksc4WvicILY7t27dfz4cX3iE59QbW0tf9QAgASELwCT1qlTp/TCCy+k/VHZ5cuXq6yszO8SMQbC18TkBLH/+I//0C9/+Ut98pOflGVZBDEAUx7hC8CkcvbsWe3fv1/t7e06dOiQrr32Wvek77777lNFRYXfJSIHhK+Jzwli7e3tOnHihD75yU+qrq5OTU1Nuv322/0uDwCMInwBmPDeffddRSIRhcNhfe9731N5ebmWLl2qpqYmPfTQQ6qsrPS7ROSJ8DW5HDlyRLt27dKePXuSehStr6/Xbbfd5nd5AFB0hC8AE9L58+e1f/9+7dq1S6+99pqmTZumZcuWKRgMauXKlbrmmmv8LhEFQPianBJ/Sy8cDus3v/mNG8ToaRTAZEb4AjBhvP/++3r99dcVDoe1d+9evf/++1q8eLEaGxv18MMP69prr/W7RBQY4WvySwxi3d3devvtt90gtmbNGi1YsMDvEgGgYAhfAEraBx98oNdee03hcFj79u3T+fPntXDhQvfE7Prrr/e7RBQR4WtqyRbE1q5dq0996lN+lwgA40L4AlByLl26pN7eXvf3g86ePatFixa5z4bMnj3b7xJhCOFr6ko8DnR1dSkWi7lBbN26dZo/f77fJQJAzghfAEpCtr94NzU16ZZbbvG7RPiA8AUpOYh1dnYqHo+7x4fGxkb92Z/9md8lAoAnhC8Avjp69Kja29vV3t6e1PsZtxhBInxhtNQr4++8845uv/12NTU1ad26dbrxxhv9LhEAMiJ8ATDO+d2f3bt36/jx4+7v/jz66KN0N40khC9kc+nSJX3/+9/Xrl271NPTo3Pnzrm3KAeDQc2ZM8fvEgEgCeELgBG/+tWv1N3dre985zv6+c9/rrlz5+rhhx9WMBjUF7/4Rb/LQ4kifMGrxM55XnrpJf3+9793g1hdXZ1uuOEGv0sEAMIXgOIZGhrSiy++qHA4rB/+8Ie68cYbtXLlSgWDQd11110KBAJ+l4gSR/hCPhJ/lmLfvn36wx/+QKc9AEoC4QtAQZ0+fVp79uxROBzW4cOH9bGPfUwPPPCAgsGg7r//fpWXl/tdIiYQwhfGKzWIJf5cxerVq1VdXe13iQCmEMIXgHH77W9/q//8z/9UOBzWK6+8ounTp8uyLAWDQd13332qqKjwu0RMUIQvFNJ7772nAwcOKBwO68UXX9R7773nBrGGhgZVVVX5XSKASY7wBSAvw8PD6unpUTgc1ve+9z2Vl5dr6dKlampq0kMPPaTKykq/S8QkQPhCsSQGsb179+r999/nB9wBFB3hC4BnzslKe3u7XnrpJU2bNk3Lli1TMBjUihUr9NGPftTvEjHJEL5gwvnz53Xw4EGFw2G98MIL+uCDD7Rw4UI1NTWpvr5eM2bM8LtEAJME4QtAVonPSzi36SxevFiNjY16+OGHde211/pdIiYxwhdMO3/+vPbv369du3bptddeUyAQ0L333qtgMMgxD8C4Eb4AjJL42zmpXTbzXARMInzBT4m3VxPEABQC4QuAJOny5cs6fPiwwuGwOjo6dPbsWZ+8XgsAABH2SURBVLpmhu8IXygV7777riKRiBvEEm+7fuSRRzR9+nS/SwQwARC+gCksMXB1d3fr7bff1u23365gMKimpibdcsstfpeIKY7whVKUGMS+973vqaysjOdfAXhC+AKmoKNHjyocDqu9vV0nTpxwA9eaNWu0YMECv8vDFPXmm2+qv78/aVhbW5sk6Yknnkgafscdd2jhwoXGagMySfypjcSeX4PBoFauXKlrrrnG7xIBlBDCFzBFOIFr9+7dOn78uD7xiU+otrZWjz76qP7yL//S7/IARSIR1dbWqqysTNOmTZMkOV9RgUBA0pWrtZcuXVJPT48sy/KtViCds2fPav/+/QqHw3r11VdVUVFBEAOQhPAFTGK/+tWv1N3drZ07d+pnP/uZbr75Zj3yyCMKBoP64he/6Hd5QJKLFy9q1qxZ+t3vfpd1vOnTp+vMmTP8lhxKWmoQq6ys1JIlSxQMBrVq1SpdffXVfpcIwAeEL2CSGRoa0osvvqhwOKwf/vCHmjVrllasWKHGxkbddddd7hUEoBR95Stf0Xe+8x1duHAh7fsVFRX68pe/rG9/+9uGKwPyd+bMGe3du1e7du1Sb2+vpk+frtraWgWDQX3pS1/iDwnAFEL4AkrEO++8o1mzZuUVjk6fPq09e/YoHA7r8OHD+tjHPqYHHnhAwWBQ999/v8rLy4tQMVB4//Vf/6XFixePOc4999xjqCKgsE6dOqUXXnjBPV7PmDFDlmWNK4jZtq1z587R9T0wARC+gBLw5ptvauXKlers7PR8O2DiQ96vvvqqrrnmGvcvqffdd58qKiqKXDVQeJcvX9acOXMUi8XSvn/99dfr7bffdp8JAyayX//619q7d68bxGbOnKkHH3ww5+N4X1+fmpqatHfvXn3mM58pctUAxoNvL8Bn3/72t/XXf/3XOn36tLq6urKOOzw8rF27dsmyLM2ePVvNzc2SpOeff15vvfWW+x7BCxPVtGnTtG7durR//a+srNSjjz5K8MKkcfPNN+sf//Ef9T//8z86efKkNm3apBMnTuihhx7S7Nmz1dTUpEgkoosXL2Ztp7u7W8ePH9df/dVfaffu3YaqB5APrnwBPvnggw/0d3/3d/r3f/93d9jMmTP1zjvvJN0m+N577+nAgQNqb29XT0+PJOnee+/l92QwaR05ckSf//znM75H75yY7AYHB7Vv3z5Pt5Lbtq05c+bo7bffdoc9/vjjevbZZ3mWDChBhC/AB6dOndLDDz+saDSqS5cuJb134MAB3XXXXXr99dcVDof14osv6r333tPChQvV1NSk1atXc18/Jr358+frl7/8ZdKwefPm6eTJk/4UBPjk5MmTeumll9xOlK677jotX77cDWJvvvnmqNvVy8vL9ZnPfEb79u3TvHnzfKocQDqEL8CwH/zgB1qxYoXOnTs36laSiooK3Xnnnfrxj3+s8+fP6//9v/+n+vp6rVy5Uh//+Md9qhgw71/+5V/09a9/3d1HKisr9fTTT2vTpk0+Vwb4Z2BgQN3d3eru7tZPfvITzZkzRzfeeKP6+/tH9RBaUVGha665Rt3d3br33nt9qhhAKsIXYIht2/rXf/1XbdiwQZJGXfFyXH311fr617+u+vp6zZ4922SJQMn4xS9+oU996lNJwwYGBrRgwQKfKgJKy09/+lN1d3frm9/8ps6fP592HOf5yJaWFv3zP/8zz0sCJYC9EDDg97//vYLBoJ566ildunQpY/CSpPPnz2v+/PkEL0xp8+fP1x133KFAIKBAIKA77riD4AUkuP3227VkyZKMwUu60nvo5cuXtXnzZlmWpeHhYYMVAkiH8AUU2fHjx/X5z39eL730krxcaK6oqFBnZ6eByoDS1tTUpLKyMpWVlampqcnvcoCSEw6HPfVue/nyZb3++uv67Gc/q//7v/8zUBmATLjtECiiffv2ad26dXr//fezXu1KdfXVV+vs2bP6yEc+UsTqgNL21ltv6eabb5Zt2xoaGtJNN93kd0lAybh8+bKqq6t15swZz5+ZNm2aKisr9fzzz2vNmjVFrA5ARnaKrq4uWxIvXrx4+frq6upKPTwVDMc5XryK8yrmfuv3vPHixYtXrq9Vq1aNOpZ9+EMRKcb6sVcAmZ0/fz7pN1cysW3bvV//hRdekCStXLlSkjRr1izdcMMNxSuyhNXX1xuZDse50nfgwAEFAgEtXbrU71LS+ta3viVJeuqpp3yuxH8m9tsnn3xSixYtKvp0JoLTp0/r17/+9ajh11xzzahhlZWVo25PnDZtmm644QZdddVVRasRU09vb6+2bt3K96s+/H5IlTF81dXVFa0YAKP9/Oc/lyRt3rzZ50r8Zyp8cZwrfU7ouu6663yuJL1wOCyJbUkys98uWrSIZQ2UuK1bt7Kf6sPvh1QZwxcAAH4r1dAFAEA+6O0QAAAAAAwgfAEAAACAAYQvAAAAADCA8AUAAAAABhC+AAAAAMAAwhcAAAAAGED4AgAAAAADCF8AAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAgIKEr5aWFrW0tLj/jsfj6uzsVG1tbdZhJqTWhsxYVkB6po9ffh0vS2X6wGRQyt+pnLcB/ikvRqObNm3S9u3bxxwG/4yMjGjmzJmybdvvUowr5rybXK6BQCDje62trVqwYIHuvvtuzZgxo+i1THamj19+Hy8fe+wxRSIR36afDvstUDyct008HBMnMDtFV1eXnWZwziSNaifdMPijp6dnyq6LYs77eNpetWqVvWrVqpw+E4vF3P1qeHjYHR6NRm3LsmzLsuxYLJZXPX6SZHd1dRWt/XyOc6aPX34fL/2efir229JX7P222O1PdZy3TSylekzM5/t1sh4TM30/8MzXFDQyMqIdO3b4XYYvijnvfizXqqoq9/8T/ypUU1Oj5557TtKVqxgjIyNG6wIKif0WAD7EMXFiG3f4Gs89wYFAwH1lGpbafiQSUSAQ0Pr16zU0NCRJ6uzsHDUsU22Z2qutrU36rLPxObW0tLQoHo/n1IbTjlNfIBAYtUHH43Ft2bLF/fyhQ4c8L794PK5IJKLa2lqNjIxo/fr1o+7hTtd2a2ure0uRU9d4llW2aSWuT2edphvmVbrl6awXL9tTpnl3lqMkd72vX79ex44dG1fbfqqqqtKTTz6pSCSiN954I+m9TOsrl3XufN5ZB4nzO57teiIpxnGitrbW3e6ytePlGOilxmzHkESHDh1ivzWA/bYwvGwf+XyH9vX1ZfwOc8YNBAL63//934znRuPdH1Knl25djrVsOG/z57wt2zQ4JqY3KY+JqZfCcr1caFmW50vVqcMSLzM6BgcHk4Ylth+NRm3btu3e3l5bkt3c3Gz39vYmfa65uTlrbYnDsn22ubnZlmTHYrFR73ttwxk3FAoltev8OxaL2ZZl2R0dHbZt2/bBgweT5nMsqXVEo1F3+mO1nW255LqsxppWW1ubuywTx/c6n6nz3NbWltSOZVn28PCwp+0p3bw7/06cz+HhYXcbGBgYyLvtXORz+9JY0xweHs5pfXld562trfbg4KA7jVAo5NYw3u3amaeJcNthIY8Tzc3N7u0WHR0d7mfHcwzMtcbEY0i67b2trS2vWz/Yb0djv81dLu172T7y/Q51/j/xu90RCoVGrZNUhdgfsq3LsXDe5t95W+I0JusxMd/HlybjMTHT90NBnvnKdyf2OqzY7acbFgqFklZQPjU5J1CJJyu9vb22ZVlJ76e2ke6AnokzzcR7ZL20Xchl5WU+Eg+Kra2teZ3AORt+6vKU5O4chdyeotGoLclubW0dV9teFeMkLt37hdg2UteDc0D30r7XeZoI4asQxwnn3vqBgQF3mPNF44w3nv3Va42px5DE8aLRqLuP5Yr9Nj3229zl2n4u20eu36HOSVri55yTt2zTL+T+kGldelHIc4BM9RWz/XTDJsp522Q/JhYjfKV7fyIcEwlfeQyz7StJubW1Na+anOSdSWIyT315lWn8sdou5LLyMh/OBm1ZVtJJZi6cAJfIOUl1DoyF3J5Shxf7gGXqJK4Q24azLjo6OkadtBRqu54I4csxnuNEuu06dbzxHsdyrTFxeG9v76i/DOeC/TY99tvc5dp+vtuHbY+9PJwT2sQ/Shw8eDDpr+Lp2i7U/pBtXXoxnmNKIffXQg+z7dI/b5vsx0RT4WsiHBMJX3kMa2trc8NCPjXluiHlw8uO5vVzhVw/6Th/RXAuAeeqmAeVUjhgFfP2pbH+GjtWe6nDUm/Zcf6i5qV9L6SJE76KdZzIddsrZI2Jw9lvs2O/TZ7eZAlfXpaHc6uYI/Uv4sXcZrOtSy8KeQ6Qblix2880bLKct03kY2IxbzucaMdEejvMUWdnp5544gk9++yzWrBgQV5tWJYlServ7886XuLD9YVWzLZzmVY8Htfp06fV2tqqRYsWuQ+W5sJZnuk+29zcnHN7XhWz7WI7cuSIJGnx4sWj3hvPtrFgwQL19PQoGo2qublZGzdu1JYtWwrW/kRRiONEsY23xtWrVysUCrHfGsR+W3xet49sy2PNmjWKRCLq6+vT0NCQvvCFL4zZXqH2By/rcqqZKOdtHBNzN9mOiYSvDBoaGiRJc+fOzbsNZwfbvn272z3m0NCQ1q9fL0lqa2uTJLW3t7vvOz2rjFcx285nWu3t7dqwYYMee+wxWZalTZs25TydNWvWSJJOnDjhDnOmFwwG864/E2eHW758ecHbNiEej2vr1q2yLEtLlixxhxdi2wgEAhoZGVFNTY22bdumaDSqjRs3Fqz9iaIQxwlneY31ZZ+vQtS4ceNG9ltD2G+Ly+v24WV5OOtn586dOnz4sO6+++4xp1+o/SHbupyqJsp5G8fE3EzKY2LqpbBcLxcm9pyS2Judl2G2bSf1wmLbHz50KF3pkSTdD6+NZ5rp2kt8uN0Zz7kMOTg4mHT5OhaLeW7D6SnFGe7MkzOvie0kvpyeV3JZ9tneS9e2U1diBxj5Lqts03IeQE59KFnK7aFF53OpP7bX0dGRtrejTNtTunm37eRbrJxphUKhpFtK8m3bq3xuX0pcH15/mDDb+vK6zp3152xPzj32Y7XvlVRatx1mOn4V4jjh9MBkWZa7jJwHsiXZK1asyPsYmEuNmebXmaZTp9NDl1fst+mXCftt7nJtf6ztYzzfoQ6n443U7SbT/lio/SHbuhwL523+nbc5053Mx8R8bjucrMfEoj3zlVpULsOcGXVWck9Pj23bttu1Y7oZH+80vQ5zHqYNhUJ2LBZze9FJ7JLTy/w5n3XaSu1sYnBw0H3faT+fZZ+4Y3lpO3X+CrEe000r3biZ2vAiFou5Xdc7B5jEHXWs7SndvCfWlNhFaVtbW0Ha9irXk7h0BwXn1dramvUZHS/ra6ztwDkoO9Pz0n4u81ZK4SvTNluo48Tg4KD7heicvDjb1nj3Ta81Jh5D0rWVGAjZbz/Efps8b6UYvjJtH+P5DnU4207qd3u277lC7A9jrUsvyyXfYwrnbePbT5xpTNZj4ni/XyfTMTHT90PgTxN3dXd3q76+XimDgUnN+VE9P7d753aDcDjsWw2lIhAIqKurS3V1dUVpn+Pc5MB+W1qKvd/m2n4pbB+ASaWwzfP9+qFM3w888wUAAAAABhC+MOUl9jiUT29uAMxjv0U2bB+YatjmJ45yvwtAes6l47FMhsu6fs9rdXV10v9PhmUKFBv7LUrZVN0+/N4vpzK/l/1U3eYnIsJXiZpKO43f8+r39IGJyO/9xu/po7RN1e1jqs53KfB72fs9fXjHbYcAAAAAYADhCwAAAAAMIHwBAAAAgAGELwAAAAAwgPAFAAAAAAYQvgAAAADAAMIXAAAAABhA+AIAAAAAAwhfAAAAAGAA4QsAAAAADCB8AQAAAIABhC8AAAAAMIDwBQAAAAAGlGd6IxAImKwDwJ+w75nDskahsC2ZUV9fr/r6er/LADAGjolXrFq1atSwgG3bduKAU6dO6fDhw8aKAoB07rzzTt10001FaZvjHFAcxdxvu7u7i9IuABTLzTffrEWLFiUNGxW+AAAAAACFxzNfAAAAAGAA4QsAAAAADCB8AQAAAIAB5ZLCfhcBAAAAAJPd/wcalKVXhmaSYwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(multi_task_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "74260620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:42.818264Z",
     "start_time": "2023-10-24T17:31:42.812040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of the first layer: [(None, 224, 224, 3)]\n"
     ]
    }
   ],
   "source": [
    "first_layer = multi_task_model.layers[0]  # Get the first layer\n",
    "input_shape = first_layer.input_shape\n",
    "print(\"Input shape of the first layer:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f6d29847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:43.610924Z",
     "start_time": "2023-10-24T17:31:43.603410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'left_eye': (213, 232), 'right_eye': (306, 222), 'nose': (239, 283), 'mouth_left': (227, 342), 'mouth_right': (298, 332)}, {'left_eye': (215, 230), 'right_eye': (307, 222), 'nose': (238, 285), 'mouth_left': (228, 339), 'mouth_right': (299, 333)}, {'left_eye': (207, 242), 'right_eye': (299, 228), 'nose': (236, 291), 'mouth_left': (226, 352), 'mouth_right': (296, 340)}, {'left_eye': (218, 240), 'right_eye': (313, 232), 'nose': (245, 291), 'mouth_left': (231, 352), 'mouth_right': (304, 345)}, {'left_eye': (223, 246), 'right_eye': (304, 238), 'nose': (242, 295), 'mouth_left': (234, 350), 'mouth_right': (302, 344)}, {'left_eye': (214, 237), 'right_eye': (306, 233), 'nose': (241, 295), 'mouth_left': (227, 352), 'mouth_right': (298, 348)}]\n",
      "[0.516026363376736, 0.513045514422743, 0.5178306256293403, 0.5205153679947918, 0.5188656798350694, 0.5162518392838541]\n",
      "[0.516026363376736, 0.513045514422743, 0.5178306256293403, 0.5205153679947918, 0.5188656798350694, 0.5162518392838541]\n"
     ]
    }
   ],
   "source": [
    "# multi_task_model.fit()\n",
    "# trainLandmarks = trainLandmarks[:-1]\n",
    "# trainIllumsRaw = trainIllumsRaw[:-1]\n",
    "print(trainLandmarks)\n",
    "print(trainIllumsRaw)\n",
    "print(trainIllumsRet)\n",
    "\n",
    "trainIllumsRawArray = np.array(trainIllumsRaw)\n",
    "trainIllumsRetArray = np.array(trainIllumsRet)\n",
    "\n",
    "# print(trainIllumsRawArray)\n",
    "# print(trainIllumsRetArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d888c6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:44.545599Z",
     "start_time": "2023-10-24T17:31:44.541896Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'left_eye': (213, 232), 'right_eye': (306, 222), 'nose': (239, 283), 'mouth_left': (227, 342), 'mouth_right': (298, 332)}\n",
      "  0.516026363376736 0.516026363376736]\n",
      " [{'left_eye': (215, 230), 'right_eye': (307, 222), 'nose': (238, 285), 'mouth_left': (228, 339), 'mouth_right': (299, 333)}\n",
      "  0.513045514422743 0.513045514422743]\n",
      " [{'left_eye': (207, 242), 'right_eye': (299, 228), 'nose': (236, 291), 'mouth_left': (226, 352), 'mouth_right': (296, 340)}\n",
      "  0.5178306256293403 0.5178306256293403]\n",
      " [{'left_eye': (218, 240), 'right_eye': (313, 232), 'nose': (245, 291), 'mouth_left': (231, 352), 'mouth_right': (304, 345)}\n",
      "  0.5205153679947918 0.5205153679947918]\n",
      " [{'left_eye': (223, 246), 'right_eye': (304, 238), 'nose': (242, 295), 'mouth_left': (234, 350), 'mouth_right': (302, 344)}\n",
      "  0.5188656798350694 0.5188656798350694]\n",
      " [{'left_eye': (214, 237), 'right_eye': (306, 233), 'nose': (241, 295), 'mouth_left': (227, 352), 'mouth_right': (298, 348)}\n",
      "  0.5162518392838541 0.5162518392838541]]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.vstack((trainLandmarks, trainIllumsRaw, trainIllumsRet)).T\n",
    "print(Y_train)\n",
    "\n",
    "# Sample 2D NumPy array\n",
    "data = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6eff25d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:31:45.263899Z",
     "start_time": "2023-10-24T17:31:45.258931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213 232 306 222 239 283 227 342 298 332]\n",
      " [215 230 307 222 238 285 228 339 299 333]\n",
      " [207 242 299 228 236 291 226 352 296 340]\n",
      " [218 240 313 232 245 291 231 352 304 345]\n",
      " [223 246 304 238 242 295 234 350 302 344]\n",
      " [214 237 306 233 241 295 227 352 298 348]]\n"
     ]
    }
   ],
   "source": [
    "# Sample 2D NumPy array\n",
    "data = Y_train\n",
    "\n",
    "# Extract numerical values from the dictionaries\n",
    "numerical_values = []\n",
    "\n",
    "for row in data:\n",
    "    row_values = []\n",
    "    for element in row:\n",
    "        if isinstance(element, dict):\n",
    "            # Extract numerical values from the dictionary\n",
    "            dict_values = [val for key, val in element.items() if isinstance(val, tuple)]\n",
    "            for tpl in dict_values:\n",
    "                for value in tpl:\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        row_values.append(value)\n",
    "    numerical_values.append(row_values)\n",
    "\n",
    "# Print the numerical values\n",
    "# for row in numerical_values:\n",
    "#     print(row)\n",
    "\n",
    "numerical_values = np.array(numerical_values)\n",
    "print(numerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8a40ff52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:32:37.218964Z",
     "start_time": "2023-10-24T17:32:37.208383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'data\\Training', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=6, \n",
    "                                                    class_mode='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0fd87ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:32:38.754861Z",
     "start_time": "2023-10-24T17:32:38.721803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "for batch in train_generator:\n",
    "    images, labels = batch\n",
    "    break\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "47f00a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:32:39.419709Z",
     "start_time": "2023-10-24T17:32:39.411583Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "badf21bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:32:40.311678Z",
     "start_time": "2023-10-24T17:32:40.301935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([6], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "imageTensor = tf.convert_to_tensor(images)\n",
    "landmarkTensor = tf.convert_to_tensor(numerical_values)\n",
    "illuminanceTensor = tf.convert_to_tensor(trainIllumsRawArray)\n",
    "illumsRetTensor = tf.convert_to_tensor(trainIllumsRetArray)\n",
    "\n",
    "print(tf.shape(illuminanceTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ec3d61ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T17:35:48.932987Z",
     "start_time": "2023-10-24T17:35:48.898578Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using `keras.utils.Sequence` as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[188], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m multi_task_model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mtrain_generator,\n\u001b[0;32m      2\u001b[0m                               y\u001b[38;5;241m=\u001b[39milluminanceTensor,\n\u001b[0;32m      3\u001b[0m                               epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      4\u001b[0m                               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1011\u001b[0m, in \u001b[0;36mKerasSequenceAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1000\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1009\u001b[0m ):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_none_or_empty(y):\n\u001b[1;32m-> 1011\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1012\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`y` argument is not supported when using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1013\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.utils.Sequence` as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1014\u001b[0m         )\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_none_or_empty(sample_weights):\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_weight` argument is not supported when using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.utils.Sequence` as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: `y` argument is not supported when using `keras.utils.Sequence` as input."
     ]
    }
   ],
   "source": [
    "history = multi_task_model.fit(x=train_generator,\n",
    "                              y=illuminanceTensor,\n",
    "                              epochs=10,\n",
    "                              batch_size=4)\n",
    "\n",
    "\n",
    "# history = multi_task_model.fit(x={'input_80': imageTensor},\n",
    "#                                y={'landmark_output': landmarkTensor, \n",
    "#                                 'previous_illuminance_output': illuminanceTensor, \n",
    "#                                 'illuminance_retinex_output': illumsRetTensor},\n",
    "#                                epochs=10,\n",
    "#                                batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fab1e751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T09:11:38.404672Z",
     "start_time": "2023-10-24T09:11:38.396304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1603e-01, 5.1305e-01, 5.1783e-01, 5.2052e-01, 5.1887e-01,\n",
       "       5.1625e-01, 5.1905e-01, 5.2186e-01, 5.1639e-01, 5.1689e-01,\n",
       "       5.1621e-01, 5.1533e-01, 5.1777e-01])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_values\n",
    "trainIllumsRawArray\n",
    "trainIllumsRetArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f354310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T09:11:40.662748Z",
     "start_time": "2023-10-24T09:11:40.655325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9568e-01, 2.9298e-01, 2.9606e-01, 2.9911e-01, 2.9779e-01,\n",
       "       2.9541e-01, 2.9791e-01, 2.9995e-01, 2.9637e-01, 2.9697e-01,\n",
       "       2.9559e-01, 2.9536e-01, 2.9573e-01])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainIllumsRawArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e7e661e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T08:49:41.960426Z",
     "start_time": "2023-10-24T08:49:41.953075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1603e-01, 5.1305e-01, 5.1783e-01, 5.2052e-01, 5.1887e-01,\n",
       "       5.1625e-01, 5.1905e-01, 5.2186e-01, 5.1639e-01, 5.1689e-01,\n",
       "       5.1621e-01, 5.1533e-01, 5.1777e-01])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainIllumsRetArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8295d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
