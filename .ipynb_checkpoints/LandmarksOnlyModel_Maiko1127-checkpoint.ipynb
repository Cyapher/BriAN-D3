{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac1435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T07:31:30.525703Z",
     "start_time": "2023-11-27T07:31:30.512736Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== IMPORTS/LIBRARIES =====================\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650123b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T07:31:30.806349Z",
     "start_time": "2023-11-27T07:31:30.790393Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== TRAINING HISTORY FUNCTIONS =====================\n",
    "def historyToCsv():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Convert the datetime object to a string\n",
    "    filename_friendly_datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # save to csv: \n",
    "    hist_csv_file = 'history' + filename_friendly_datetime_string + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "def csvToHistory(csv_filename):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    hist_df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    history_dict = hist_df.to_dict(orient='list')\n",
    "\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa734c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T07:39:23.505582Z",
     "start_time": "2023-11-27T07:39:23.027604Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== MULTITASK MODEL SETUP =====================\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Dense(512, activation='linear', name='embedding')(flattened_features)\n",
    "\n",
    "additional_dense_layer1 = tf.keras.layers.Dense(64, name='additional_dense1')(embedding_layer)\n",
    "additional_dense_layer2 = tf.keras.layers.Dense(64, name='additional_dense2')(additional_dense_layer1)\n",
    "# additional_dense_layer3 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense3')(flattened_features)\n",
    "\n",
    "landmarks = tf.keras.layers.Dense(10, activation='linear', name='landmark_output')(additional_dense_layer2)\n",
    "# illum = tf.keras.layers.Dense(1, activation='linear', name='previous_illuminance_output')(additional_dense_layer2)\n",
    "\n",
    "# Reshape layer to the desired shape\n",
    "# reshaped_features = tf.keras.layers.Reshape((8, 8, 8))(embedding_layer)\n",
    "\n",
    "# Upsampling layers\n",
    "# upsample1 = tf.keras.layers.UpSampling2D(size=(7, 7))(reshaped_features)\n",
    "# upsample2 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample1)\n",
    "# upsample3 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample2)\n",
    "\n",
    "# retIllum = tf.keras.layers.Conv2D(3, kernel_size=(3, 3), activation='relu', padding='same', name='image_retinex_output')(upsample3)\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = [landmarks]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'landmark_output': 'mean_squared_error'\n",
    "#         'previous_illuminance_output': 'mean_squared_error',\n",
    "#         'image_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'landmark_output': ['mse', \"mae\"]\n",
    "#         'previous_illuminance_output': ['mse', \"mae\"],\n",
    "#         'image_retinex_output': ['mse', \"mae\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()\n",
    "# plot_model(multi_task_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565c5cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T07:42:37.055498Z",
     "start_time": "2023-11-27T07:42:37.037938Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== LANDMARKS ONLY DATA GEN =====================\n",
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True,\n",
    "                 random_seed=None):  # Add a new parameter for random seed\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed  # Store the random seed\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "        self.n_coords = 2  # Assuming landmark coordinates are 2-dimensional\n",
    "#         self.n_illuminance = 1  # Assuming a single illuminance value\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1, random_state=self.random_seed).reset_index(drop=True)  # Use the random seed\n",
    "    \n",
    "    def __get_input(self, path, target_size):\n",
    "    \n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = tf.image.resize(image_arr, (target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr / 255.\n",
    "    \n",
    "    def __get_output(self, label, output_type):\n",
    "        # Assuming output_type is 'coordinates', 'illuminance', or 'adjusted_image_path'\n",
    "        if output_type == 'coordinates':\n",
    "            # Assuming label is a string containing a dictionary-like structure\n",
    "            # Safely evaluate the string as a literal dictionary using ast.literal_eval\n",
    "            coordinates_dict = ast.literal_eval(label)\n",
    "            \n",
    "            # Extract x and y coordinates for each landmark\n",
    "            landmarks = ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']\n",
    "            coordinates_list = [coordinates_dict[landmark] for landmark in landmarks]\n",
    "            \n",
    "            # Flatten the list and convert to numpy array\n",
    "            coordinates_array = np.array([coord for landmark_coords in coordinates_list for coord in landmark_coords])\n",
    "            \n",
    "#             print(\"Shape of landmarks_array:\", coordinates_array.shape)\n",
    "            \n",
    "            # If there are exactly 10 values, return the array, otherwise raise an error\n",
    "            if len(coordinates_array) == 10:\n",
    "                return coordinates_array\n",
    "            else:\n",
    "                raise ValueError(\"Expected 10 coordinates, but found {}\".format(len(coordinates_array)))\n",
    "#         elif output_type == 'illuminance':\n",
    "#             # Convert the illuminance value to a float\n",
    "#             return float(label)\n",
    "#         elif output_type == 'adjusted_image_path':\n",
    "#             # Assuming label is the path to the adjusted image\n",
    "#             return self.__get_input(label, self.input_size)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        \n",
    "        coords_batch = batches[self.y_col['coordinates']]\n",
    "#         illuminance_batch = batches[self.y_col['illuminance']]\n",
    "#         adjusted_image_path_batch = batches[self.y_col['adjusted_image_path']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
    "\n",
    "        y0_batch = np.asarray([self.__get_output(y, 'coordinates') for y in coords_batch])\n",
    "#         y1_batch = np.asarray([self.__get_output(y, 'illuminance') for y in illuminance_batch])\n",
    "#         y2_batch = np.asarray([self.__get_output(y, 'adjusted_image_path') for y in adjusted_image_path_batch])\n",
    "\n",
    "        return X_batch, [y0_batch]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "\n",
    "        # Print a few examples of the data\n",
    "#         print(\"Sample X:\", tf.shape(X[0]))  # Print the first example in the batch\n",
    "#         print(\"Sample y[0] (landmarks):\", tf.shape(y[0][0]))  # Print the first example in the landmarks output\n",
    "#         print(\"Sample y[1] (illum):\", tf.shape(y[1][0]))  # Print the first example in the illum output\n",
    "#         print(\"Sample y[2] (adjusted_image_path):\", tf.shape(y[2][0]))  # Print the first example in the adjusted_image_path output\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3649c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T10:05:28.250161Z",
     "start_time": "2023-11-25T10:05:28.102044Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== DATA GEN SETUP (LANDMARKS ONLY TASK) =====================\n",
    "\n",
    "train_df = pd.read_csv(\"\") # path to train_data csv\n",
    "train_df[\"Filename\"] = \"./data/Training/\" + train_df[\"Filename\"] + \".jpg\"\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "X_col = {'path': 'Filename'}\n",
    "y_col = {'coordinates': 'LandmarksRaw'}\n",
    "\n",
    "# Create an instance of CustomDataGen\n",
    "train_gen = CustomDataGen(train_df, X_col, y_col, batch_size=32, input_size=(224, 224, 3))\n",
    "\n",
    "eval_df = pd.read_csv(\"\") # path to eval_data csv\n",
    "eval_df[\"Filename\"] = \"./data/Evaluation/\" + eval_df[\"Filename\"] + \".jpg\"\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "eval_X_col = {'path': 'Filename'}\n",
    "eval_y_col = {'coordinates': 'LandmarksRaw'}\n",
    "\n",
    "val_gen = CustomDataGen(eval_df, eval_X_col, eval_y_col, batch_size=32, input_size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d01800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T09:37:10.104205Z",
     "start_time": "2023-11-25T09:37:10.069299Z"
    }
   },
   "outputs": [],
   "source": [
    "history = multi_task_model.fit(train_gen, epochs=50, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29106a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== SAVE MODEL WEIGHTS =====================\n",
    "\n",
    "multi_task_model.save('LandmarksOnlyModel.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
