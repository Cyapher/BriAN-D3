{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69663c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.485246Z",
     "start_time": "2023-10-30T16:15:26.830262Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf89806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.492743Z",
     "start_time": "2023-10-30T16:15:38.488248Z"
    }
   },
   "outputs": [],
   "source": [
    "trainLandmarks = []\n",
    "trainLandmarksRet = []\n",
    "trainFileNames = []\n",
    "trainIllumsRaw = []\n",
    "trainIllumsRet = []\n",
    "evalLandmarks = []\n",
    "evalLandmarksRet = []\n",
    "evalFileNames = []\n",
    "evalIllumsRaw = []\n",
    "evalIllumsRet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096c8392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.523111Z",
     "start_time": "2023-10-30T16:15:38.495258Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def frame_capture(file):\n",
    "    \n",
    "    cap = cv2.VideoCapture(file)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "            \n",
    "    current_frame = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "#         print(file)\n",
    "        if not ret:\n",
    "            current_frame = 0\n",
    "            break \n",
    "\n",
    "        if current_frame % 15 == 0:\n",
    "            \n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "            \n",
    "            parentDir = os.path.dirname(os.path.dirname(file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "            \n",
    "            childDir = os.path.dirname(file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "            \n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "            \n",
    "#             filename of txt document containing labels for current video\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                labelFile = labelFile.replace(\"nightno\", \"night_no\")\n",
    "            else:\n",
    "                scenario = \"\"\n",
    "                if \"sunglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                elif \"night_noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"night_noglasses\"    \n",
    "                elif \"noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"noglasses\"\n",
    "                elif \"night_glasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                else:\n",
    "                    scenario = \"glasses\"\n",
    "                \n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + scenario + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                if not os.path.exists(labelFile):                    \n",
    "                    labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + \"wh\" + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                \n",
    "            with open(labelFile) as f:\n",
    "                labels = f.readline()\n",
    "            try:\n",
    "                \n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                else:\n",
    "                    save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                \n",
    "#                 Creating..../data/Testing/037_sunglasses_mix/037_sunglasses_mix_7110_1.jpg\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "            print('Creating...' + file_name)\n",
    "            cv2.imwrite(file_name, frame)\n",
    "            \n",
    "            img_file = Path(file_name) # for Retinex images, use replace() to get path of same named images in order to get post-retinex illum\n",
    "            \n",
    "            if save_path == \"./data/Training/\":\n",
    "                trainFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                trainLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                trainIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetTraining/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                trainIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                trainLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "                \n",
    "                \n",
    "\n",
    "            elif save_path == \"./data/Evaluation/\":\n",
    "                evalFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                evalLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                evalIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetEvaluation/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                evalIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                evalLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "            \n",
    "            \n",
    "        current_frame += 1\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf88578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.540279Z",
     "start_time": "2023-10-30T16:15:38.527344Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Training Videos Path\n",
    "def trainingData_prep():\n",
    "    training_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Training Dataset\") #AVIs\n",
    "    training_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in training_videos.glob(\"*\"):\n",
    "        for scenario in driver.glob(\"*\"):\n",
    "            for videos_file in scenario.glob(\"*.avi\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "                datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "                indexDataset = datasetDir.rfind('\\\\')\n",
    "                datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "                parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "                currDir = parentDir\n",
    "\n",
    "                childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "                indexParent = parentDir.rfind('\\\\')\n",
    "                parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "                indexChild = childDir.rfind('\\\\')\n",
    "                childDir = childDir[indexChild:]\n",
    "\n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "                data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "                inputPath = save_path + folder_name\n",
    "\n",
    "                if not os.path.exists(inputPath):\n",
    "                    os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "                video_path = str(videos_file)\n",
    "                training_video_paths.append(video_path)\n",
    "                frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732f5fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:54:41.267995Z",
     "start_time": "2023-10-26T02:54:41.257009Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation Videos Path\n",
    "def evalData_prep():\n",
    "    evaluation_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset\") #AVIs\n",
    "    evaluation_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in evaluation_videos.glob(\"*\"):\n",
    "        for videos_file in driver.glob(\"*.mp4\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "            parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "\n",
    "            childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "            data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "            inputPath = save_path + folder_name\n",
    "\n",
    "            if not os.path.exists(inputPath):\n",
    "                os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "            video_path = str(videos_file)\n",
    "            evaluation_video_paths.append(video_path)\n",
    "            frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2243a300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:54:41.502677Z",
     "start_time": "2023-10-26T02:54:41.496660Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Testing Videos Path\n",
    "def testData_prep():\n",
    "    testing_videos = Path(r\"NTHU Dataset\\Testing_Dataset\") #MP4s\n",
    "    testing_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for videos_file in testing_videos.glob(\"*.mp4\"):\n",
    "        print(videos_file)\n",
    "\n",
    "#         note: videos_file refers to direct path of current video file\n",
    "\n",
    "        print(os.path.dirname(videos_file))\n",
    "\n",
    "        datasetDir = os.path.dirname(videos_file)\n",
    "        indexDataset = datasetDir.rfind('\\\\')\n",
    "        datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "        save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "        folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "        print(save_path + folder_name)\n",
    "\n",
    "        data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "        inputPath = save_path + folder_name\n",
    "\n",
    "        if not os.path.exists(inputPath):\n",
    "            os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "        video_path = str(videos_file)\n",
    "        testing_video_paths.append(video_path)\n",
    "        frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0936f309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.637673Z",
     "start_time": "2023-10-30T16:15:38.543364Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- ILLUM EST FUNCTIONS\n",
    "\"\"\"\n",
    "Module for hyper spectral image simulation\n",
    "==========================================\n",
    "\n",
    " :_HYPSPCIM_PATH: path to module\n",
    "\n",
    " :_HYPSPCIM_DEFAULT_IMAGE: path + filename to default image\n",
    " \n",
    " :_CSF_NIKON_D700: Nikon D700 camera sensitivity functions\n",
    " \n",
    " :_ROUNDING: rounding of input to xyz_to_rfl() search algorithm for improved speed\n",
    "\n",
    " :xyz_to_rfl(): approximate spectral reflectance of xyz based on k nearest \n",
    "                neighbour interpolation of samples from a standard reflectance \n",
    "                set.\n",
    "\n",
    " :render_image(): Render image under specified light source spd.\n",
    "\n",
    " :get_superresolution_hsi(): Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "\n",
    " :hsi_to_rgb(): Convert HyperSpectral Image to rgb\n",
    " \n",
    " :rfl_to_rgb(): Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "     \n",
    ".. codeauthor:: Kevin A.G. Smet (ksmet1977 at gmail.com)\n",
    "\"\"\"\n",
    "\n",
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "\n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "illum_out = 0\n",
    "\n",
    "__all__ =['_HYPSPCIM_PATH','_HYPSPCIM_DEFAULT_IMAGE','render_image','xyz_to_rfl',\n",
    "          'get_superresolution_hsi','hsi_to_rgb','rfl_to_rgb','_CSF_NIKON_D700']             \n",
    "\n",
    "_HYPSPCIM_PATH = _PKG_PATH + _SEP + 'hypspcim' + _SEP\n",
    "_HYPSPCIM_DEFAULT_IMAGE = _PKG_PATH + _SEP + 'toolboxes' + _SEP + 'hypspcim' +  _SEP + 'data' + _SEP + 'testimage1.jpg'\n",
    "\n",
    "\n",
    "_ROUNDING = 6 # to speed up xyz_to_rfl search algorithm, increase if kernel dies!!!\n",
    "\n",
    "# Nikon D700 camera sensitivity functions:\n",
    "_CSF_NIKON_D700 = np.vstack((np.arange(400,710,10),\n",
    "                             np.array([[0.005, 0.007, 0.012, 0.015, 0.023, 0.025, 0.030, 0.026, 0.024, 0.019, 0.010, 0.004, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  0.000,  0.000,  0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000], \n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.002, 0.003, 0.005, 0.007, 0.012, 0.013, 0.015, 0.016, 0.017, 0.020, 0.013, 0.011, 0.009, 0.005,  0.001,  0.001,  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.002, 0.002, 0.003],\n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.003, 0.010, 0.012,  0.013,  0.022,  0.020, 0.020, 0.018, 0.017, 0.016, 0.016, 0.014, 0.014, 0.013]])[::-1]))\n",
    "\n",
    "\n",
    "def xyz_to_rfl(xyz, CSF = None, rfl = None, out = 'rfl_est', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {},\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, verbosity = 0,\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Approximate spectral reflectance of xyz values based on nd-dimensional linear interpolation \n",
    "    or k nearest neighbour interpolation of samples from a standard reflectance set.\n",
    "    \n",
    "    Args:\n",
    "        :xyz: \n",
    "            | ndarray with xyz values of target points.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb (float) values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'rfl_est' or str, optional\n",
    "        :refspd: \n",
    "            | None, optional\n",
    "            | Refer ence spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65.\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set used for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | :rfl_est:\n",
    "            | ndarrays with estimated reflectance spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    \n",
    "    wlr = rfl[0]\n",
    "    \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "        \n",
    "    # Calculate rgb values of standard rfl set under refspd:\n",
    "    if CSF is None:\n",
    "        # Calculate lab coordinates:\n",
    "        xyz_rr, xyz_wr = spd_to_xyz(refspd, relative = True, rfl = rfl, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_rr = colortf(xyz_rr, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)[:,0,:]\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions\n",
    "        rgb_rr = rfl_to_rgb(rfl, spd = refspd, CSF = CSF, wl = None)   \n",
    "        lab_rr = rgb_rr\n",
    "        xyz = xyz\n",
    "        lab_rr = np.round(lab_rr,csf_based_rgb_rounding) # speed up search\n",
    "        \n",
    "        global illum_out\n",
    "        illum_out = np.mean(lab_rr)\n",
    "        print(\"Illuminance: \" + str(np.mean(lab_rr)))\n",
    "        \n",
    "    # Convert xyz to lab-type values under refspd:\n",
    "    if CSF is None:\n",
    "        lab = colortf(xyz, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)\n",
    "    else:\n",
    "        lab = xyz # xyz contained rgb values !!!\n",
    "        rgb = xyz\n",
    "        lab = np.round(lab,csf_based_rgb_rounding) # speed up search\n",
    "    \n",
    "    if interp_type == 'nearest':\n",
    "        # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "        # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "        # Construct cKDTree:\n",
    "        tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "        \n",
    "        # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "        d, inds = tree.query(lab, k = k_neighbours )\n",
    "        if k_neighbours  > 1:\n",
    "            d += _EPS\n",
    "            w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "            rfl_est = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "        else:\n",
    "            rfl_est = rfl[inds+1,:].copy()\n",
    "    elif interp_type == 'nd':\n",
    "\n",
    "        rfl_est = math.ndinterp1_scipy(lab_rr, rfl[1:], lab)\n",
    "            \n",
    "        _isnan = np.isnan(rfl_est[:,0]) \n",
    "\n",
    "        if (_isnan.any()): #do nearest neigbour method for those that fail using Delaunay (i.e. ndinterp1_scipy)\n",
    "\n",
    "            # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "            # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "            # Construct cKDTree:\n",
    "            tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "\n",
    "            # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "            d, inds = tree.query(lab[_isnan,...], k = k_neighbours )\n",
    "\n",
    "            if k_neighbours  > 1:\n",
    "                d += _EPS\n",
    "                w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "                rfl_est_isnan = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "            else:\n",
    "                rfl_est_isnan = rfl[inds+1,:].copy()\n",
    "            rfl_est[_isnan, :] = rfl_est_isnan\n",
    "\n",
    "    else:\n",
    "        raise Exception('xyz_to_rfl(): unsupported interp_type!')\n",
    "    \n",
    "    rfl_est[rfl_est<0] = 0 #can occur for points outside convexhull of standard rfl set.\n",
    "\n",
    "    rfl_est = np.vstack((rfl[0],rfl_est))\n",
    "        \n",
    "    if ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('lab_est' in out.split(',')) | ('DEi_ab' in out.split(',')) | ('DEa_ab' in out.split(','))) & (CSF is None):\n",
    "        xyz_est, _ = spd_to_xyz(refspd, rfl = rfl_est, relative = True, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_est = colortf(xyz_est, tf = cspace, fwtf = cspace_tf_copy)[:,0,:]\n",
    "        DEi_ab = np.sqrt(((lab_est[:,1:3]-lab[:,1:3])**2).sum(axis=1))\n",
    "        DEa_ab = DEi_ab.mean()\n",
    "    elif ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('rgb_est' in out.split(',')) | ('DEi_rgb' in out.split(',')) | ('DEa_rgb' in out.split(','))) & (CSF is not None):\n",
    "        rgb_est = rfl_to_rgb(rfl_est[1:], spd = refspd, CSF = CSF, wl = wlr) \n",
    "        xyz_est = rgb_est\n",
    "        DEi_rgb = np.sqrt(((rgb_est - rgb)**2).sum(axis=1))\n",
    "        DEa_rgb = DEi_rgb.mean()\n",
    "\n",
    "        \n",
    "    if verbosity > 0:\n",
    "        if CSF is None:\n",
    "            ax = plot_color_data(lab[...,1], lab[...,2], z = lab[...,0], \\\n",
    "                            show = False, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'ro', label = 'Original')\n",
    "            plot_color_data(lab_est[...,1], lab_est[...,2], z = lab_est[...,0], \\\n",
    "                            show = True, axh = ax, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'bd', label = 'Rendered')\n",
    "        else:\n",
    "            n = 100 #min(rfl.shape[0]-1,rfl_est.shape[0]-1)\n",
    "            s = np.random.permutation(rfl.shape[0]-1)[:min(n,rfl.shape[0]-1)]\n",
    "            st = np.random.permutation(rfl_est.shape[0]-1)[:min(n,rfl_est.shape[0]-1)]\n",
    "            fig = plt.figure()\n",
    "            ax = np.zeros((3,),dtype=np.object)\n",
    "            ax[0] = fig.add_subplot(131)\n",
    "            ax[1] = fig.add_subplot(132)\n",
    "            ax[2] = fig.add_subplot(133,projection='3d')\n",
    "            ax[0].plot(rfl[0],rfl[1:][s].T, linestyle = '-')\n",
    "            ax[0].set_title('Original RFL set (random selection of all)')\n",
    "            ax[0].set_ylim([0,1])\n",
    "            ax[1].plot(rfl_est[0],rfl_est[1:][st].T, linestyle = '--')\n",
    "            ax[0].set_title('Estimated RFL set (random selection of targets)')\n",
    "            ax[1].set_ylim([0,1])\n",
    "            ax[2].plot(rgb[st,0],rgb[st,1],rgb[st,2],'ro', label = 'Original')\n",
    "            ax[2].plot(rgb_est[st,0],rgb_est[st,1],rgb_est[st,2],'bd', label = 'Rendered')\n",
    "            ax[2].legend()\n",
    "    if out == 'rfl_est':\n",
    "        return rfl_est\n",
    "    elif out == 'rfl_est,xyz_est':\n",
    "        return rfl_est, xyz_est\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "\n",
    "def render_image(img = None, spd = None, rfl = None, out = 'img_hyp', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {}, CSF = None,\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, show = True,\n",
    "                 verbosity = 0, show_ref_img = True,\\\n",
    "                 stack_test_ref = 12,\\\n",
    "                 write_to_file = None,\\\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Render image under specified light source spd.\n",
    "    \n",
    "    Args:\n",
    "        :img: \n",
    "            | None or str or ndarray with float (max = 1) rgb image.\n",
    "            | None load a default image.\n",
    "        :spd: \n",
    "            | ndarray, optional\n",
    "            | Light source spectrum for rendering\n",
    "            | If None: use CIE illuminant F4\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'img_hyp' or str, optional\n",
    "            |  (other option: 'img_ren': rendered image under :spd:)\n",
    "        :refspd:\n",
    "            | None, optional\n",
    "            | Reference spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65 (srgb has a D65 white point)\n",
    "        :D: \n",
    "            | None, optional\n",
    "            | Degree of (von Kries) adaptation from spd to refspd. \n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :show: \n",
    "            | True, optional\n",
    "            |  Show images.\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "              rendered image pixels.\n",
    "        :show_ref_img:\n",
    "            | True, optional\n",
    "            | True: shows rendered image under reference spd. False: shows\n",
    "            |  original image.\n",
    "        :write_to_file:\n",
    "            | None, optional\n",
    "            | None: do nothing, else: write to filename(+path) in :write_to_file:\n",
    "        :stack_test_ref: \n",
    "            | 12, optional\n",
    "            |   - 12: left (test), right (ref) format for show and imwrite\n",
    "            |   - 21: top (test), bottom (ref)\n",
    "            |   - 1: only show/write test\n",
    "            |   - 2: only show/write ref\n",
    "            |   - 0: show both, write test\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | img_hyp, img_ren, \n",
    "            | ndarrays with float hyperspectral image and rendered images \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get image:\n",
    "    #imread = lambda x: plt.imread(x) #matplotlib.pyplot\n",
    "   \n",
    "    if img is not None:\n",
    "        if isinstance(img,str):\n",
    "            img = plt.imread(img).copy() # use matplotlib.pyplot's imread\n",
    "    else:\n",
    "        img = plt.imread(_HYPSPCIM_DEFAULT_IMAGE).copy()\n",
    "    \n",
    "    if img.dtype == np.uint8: \n",
    "        img = img/255\n",
    "    elif img.dtype == np.uint16:\n",
    "        img = img/(2**16-1)\n",
    "    elif (img.dtype == np.float64) | (img.dtype == np.float32):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    if img.max() > 1.0: raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    \n",
    "    \n",
    "    # Convert to 2D format:\n",
    "    rgb = img.reshape(img.shape[0]*img.shape[1],3) # *1.0: make float\n",
    "    rgb[rgb==0] = _EPS # avoid division by zero for pure blacks.\n",
    "\n",
    "    \n",
    "    # Get unique rgb values and positions:\n",
    "    rgb_u, rgb_indices = np.unique(rgb, return_inverse=True, axis = 0)\n",
    "\n",
    "    \n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    wlr = rfl[0] # spectral reflectance set determines wavelength range for estimation (xyz_to_rfl())\n",
    "        \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "\n",
    "\n",
    "    # Convert rgb_u to xyz and lab-type values under assumed refspd:\n",
    "    if CSF is None:\n",
    "        xyz_wr = spd_to_xyz(refspd, cieobs = cieobs, relative = True)\n",
    "        xyz_ur = colortf(rgb_u*255, tf = 'srgb>xyz')\n",
    "    else:\n",
    "        xyz_ur = rgb_u # for input in xyz_to_rfl (when CSF is not None: this functions assumes input is indeed rgb !!!)\n",
    "    \n",
    "    # Estimate rfl's for xyz_ur:\n",
    "    rfl_est, xyzri = xyz_to_rfl(xyz_ur, rfl = rfl, out = 'rfl_est,xyz_est', \\\n",
    "                 refspd = refspd, D = D, cieobs = cieobs, \\\n",
    "                 cspace = cspace, cspace_tf = cspace_tf, CSF = CSF,\\\n",
    "                 interp_type = interp_type, k_neighbours = k_neighbours, \n",
    "                 verbosity = verbosity,\n",
    "                 csf_based_rgb_rounding = csf_based_rgb_rounding)\n",
    "\n",
    "    # Get default test spd if none supplied:\n",
    "    if spd is None:\n",
    "        spd = _CIE_ILLUMINANTS['F4']\n",
    "        \n",
    "    if CSF is None:\n",
    "        # calculate xyz values under test spd:\n",
    "        xyzti, xyztw = spd_to_xyz(spd, rfl = rfl_est, cieobs = cieobs, out = 2)\n",
    "    \n",
    "        # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            xyzti = cat.apply(xyzti, xyzw1 = xyztw, xyzw2 = xyz_wr, D = D)\n",
    "    \n",
    "        # Convert xyzti under test spd to srgb:\n",
    "        rgbti = colortf(xyzti, tf = 'srgb')/255\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions under spd:\n",
    "        rgbti = rfl_to_rgb(rfl_est, spd = spd, CSF = CSF, wl = None) \n",
    "        \n",
    "         # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            white = np.ones_like(spd)\n",
    "            white[0] = spd[0]\n",
    "            rgbwr = rfl_to_rgb(white, spd = refspd, CSF = CSF, wl = None)\n",
    "            rgbwt = rfl_to_rgb(white, spd = spd, CSF = CSF, wl = None)\n",
    "            rgbti = cat.apply_vonkries2(rgbti,rgbwt,rgbwr,xyzw0=np.array([[1.0,1.0,1.0]]), in_type='rgb',out_type= 'rgb',D=1)\n",
    "        \n",
    "    \n",
    "    # Reconstruct original locations for rendered image rgbs:\n",
    "    img_ren = rgbti[rgb_indices]\n",
    "    img_ren.shape = img.shape # reshape back to 3D size of original\n",
    "    img_ren = img_ren\n",
    "    \n",
    "    # For output:\n",
    "    if show_ref_img == True:\n",
    "        rgb_ref = colortf(xyzri, tf = 'srgb')/255 if (CSF is None) else xyzri # if CSF not None: xyzri contains rgbri !!!\n",
    "        img_ref = rgb_ref[rgb_indices]\n",
    "        img_ref.shape = img.shape # reshape back to 3D size of original\n",
    "        img_str = 'Rendered (under ref. spd)'\n",
    "        img = img_ref\n",
    "    else:\n",
    "        img_str = 'Original'\n",
    "        img = img\n",
    "       \n",
    "    \n",
    "    if (stack_test_ref > 0) | show == True:\n",
    "        if stack_test_ref == 21:\n",
    "            img_original_rendered = np.vstack((img_ren,np.ones((4,img.shape[1],3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd)\\n ' + img_str \n",
    "        elif stack_test_ref == 12:\n",
    "            img_original_rendered = np.hstack((img_ren,np.ones((img.shape[0],4,3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd) | ' + img_str \n",
    "        elif stack_test_ref == 1:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str = 'Rendered (under test spd)' \n",
    "        elif stack_test_ref == 2:\n",
    "            img_original_rendered = img\n",
    "            img_original_rendered_str = img_str\n",
    "        elif stack_test_ref == 0:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str =  'Rendered (under test spd)' \n",
    "            \n",
    "    if write_to_file is not None:\n",
    "        # Convert from RGB to BGR formatand write:\n",
    "        #print('Writing rendering results to image file: {}'.format(write_to_file))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imsave(write_to_file, img_original_rendered)\n",
    "            \n",
    "    if show == True:\n",
    "        # show images using pyplot.show():\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.imshow(img_original_rendered)\n",
    "        plt.title(img_original_rendered_str)\n",
    "        plt.gca().get_xaxis().set_ticklabels([])\n",
    "        plt.gca().get_yaxis().set_ticklabels([])\n",
    "        \n",
    "        if stack_test_ref == 0:\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title(img_str)\n",
    "            plt.axis('off')\n",
    "      \n",
    "    if 'img_hyp' in out.split(','):\n",
    "        # Create hyper_spectral image:\n",
    "        rfl_image_2D = rfl_est[rgb_indices+1,:] # create array with all rfls required for each pixel\n",
    "        img_hyp = rfl_image_2D.reshape(img.shape[0],img.shape[1],rfl_image_2D.shape[1])\n",
    "\n",
    "\n",
    "    # Setup output:\n",
    "    if out == 'img_hyp':\n",
    "        return img_hyp\n",
    "    elif out == 'img_ren':\n",
    "        return img_ren\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "def rfl_to_rgb(rfl, spd = None, CSF = None, wl = None, normalize_to_white = True):\n",
    "    \"\"\" \n",
    "    Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "    \n",
    "    Args:\n",
    "        :rfl:\n",
    "            | ndarray with spectral reflectance functions (1st row is wavelengths if wl is None).\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True: white-balance output rgb to a perfect white diffuser.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb values for each spectral reflectance functions\n",
    "    \"\"\"\n",
    "    rfl_cp = rfl.copy()\n",
    "    if (wl is None): \n",
    "        wl = rfl_cp[0] \n",
    "        rfl_cp = rfl_cp[1:]\n",
    "    wlr = getwlr(wl)\n",
    "    if spd is not None:\n",
    "        spd = cie_interp(spd,wlr,kind='linear')[1:]\n",
    "    else:\n",
    "        spd = np.ones_like(wlr)\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    CSF = cie_interp(CSF,wlr,kind='linear')\n",
    "    CSF[1:] = CSF[1:]*spd\n",
    "    rgb = rfl_cp @ CSF[1:].T \n",
    "    if normalize_to_white:\n",
    "        white = np.ones_like(spd)\n",
    "        white = white/white.sum()*spd.sum()\n",
    "        rgbw = white @ CSF[1:].T  \n",
    "        rgb = rgb/rgbw.max(axis = 0,keepdims=True) \n",
    "    \n",
    "    return rgb\n",
    "\n",
    "    \n",
    "    \n",
    "def hsi_to_rgb(hsi, spd = None, cieobs = _CIEOBS, srgb = False, \n",
    "               linear_rgb = False, CSF = None, normalize_to_white = True, \n",
    "               wl = [380,780,1]):\n",
    "    \"\"\" \n",
    "    Convert HyperSpectral Image to rgb.\n",
    "    \n",
    "    Args:\n",
    "        :hsi:\n",
    "            | ndarray with hyperspectral image [M,N,L]\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set to convert spectral data to xyz tristimulus values.\n",
    "        :srgb:\n",
    "            | False, optional\n",
    "            | If False: Use xyz_to_srgb(spd_to_xyz(...)) to convert to srgb values\n",
    "            | If True: use camera sensitivity functions.\n",
    "        :linear_rgb:\n",
    "            | False, optional\n",
    "            | If False: use gamma = 2.4 in xyz_to_srgb, if False: use gamma = 1 and set :use_linear_part: to False.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True & CSF is not None: white-balance output rgb to a perfect white diffuser.\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb image [M,N,3]\n",
    "    \"\"\"\n",
    "    if spd is None:\n",
    "        spd = _CIE_E.copy()\n",
    "    wlr = getwlr(wl)\n",
    "    spd = cie_interp(spd,wl,kind='linear')\n",
    "    \n",
    "    hsi_2d = np.reshape(hsi,(hsi.shape[0]*hsi.shape[1],hsi.shape[2]))\n",
    "    if srgb:\n",
    "        xyz = spd_to_xyz(spd, cieobs = cieobs, relative = True, rfl = np.vstack((wlr,hsi_2d)))\n",
    "        gamma = 1 if linear_rgb else 2.4\n",
    "        rgb = xyz_to_srgb(xyz, gamma = gamma, use_linear_part = not linear_rgb)/255\n",
    "    else:\n",
    "        if CSF is None: CSF = _CSF_NIKON_D700\n",
    "        rgb = rfl_to_rgb(hsi_2d, spd = spd, CSF = CSF, wl = wl, normalize_to_white = normalize_to_white)        \n",
    "    return np.reshape(rgb,(hsi.shape[0],hsi.shape[1],3))\n",
    "\n",
    "       \n",
    "def get_superresolution_hsi(lrhsi, hrci, CSF, wl = [380,780,1], csf_based_rgb_rounding = _ROUNDING,\n",
    "                            interp_type = 'nd', k_neighbours = 4, verbosity = 0):\n",
    "    \"\"\" \n",
    "    Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "    \n",
    "    Args:\n",
    "        :lrhsi:\n",
    "            | ndarray with float (max = 1) LowResolution HSI [m,m,L].\n",
    "        :hrci:\n",
    "            | ndarray with float (max = 1) HighResolution HSI [M,N,3].\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | Verbosity level for sub-call to render_image().\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :hrhsi:\n",
    "            | ndarray with HighResolution HSI [M,N,L].\n",
    "        \n",
    "    Procedure:\n",
    "        | Call render_image(hrci, rfl = lrhsi_2, CSF = ...) to estimate a hyperspectral image\n",
    "        | from the high-resolution color image hrci with the reflectance spectra \n",
    "        | in the low-resolution hyper-spectral image as database for the estimation.\n",
    "        | Estimation is done in raw RGB space with the lrhsi converted using the\n",
    "        | camera sensitivity functions in CSF.\n",
    "    \"\"\"\n",
    "    wlr = getwlr(wl)\n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "    lrhsi_2d = np.vstack((wlr,np.reshape(lrhsi,(lrhsi.shape[0]*lrhsi.shape[1],lrhsi.shape[2])))) # create 2D rfl database\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    hrhsi = render_image(hrci, spd = eew,\n",
    "                         refspd = eew, rfl = lrhsi_2d, D = None,\n",
    "                         interp_type = interp_type, k_neighbours = k_neighbours,\n",
    "                         verbosity = verbosity, show = bool(verbosity),\n",
    "                         CSF = CSF, csf_based_rgb_rounding = csf_based_rgb_rounding) # render HR-hsi from HR-ci using LR-HSI rfls as database        \n",
    "    return hrhsi\n",
    "\n",
    "\n",
    "def illuminanceEstimation(input_img):\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for HSI simulation and rendering:\n",
    "    #--------------------------------------------------------------------------\n",
    "    # plt.close('all')\n",
    "    # from luxpy.toolboxes import spdbuild as spb\n",
    "    # S = spb.spd_builder(peakwl = [460,525,590],fwhm=[20,40,20],target=4000, tar_type = 'cct') \n",
    "    # img = _HYPSPCIM_DEFAULT_IMAGE\n",
    "    # img_hyp,img_ren = render_image(img = img, \n",
    "    #                                 cspace = 'Yuv',interp_type='nd',\n",
    "    #                                 spd = S, D=1, \n",
    "    #                                 show_ref_img = True,\n",
    "    #                                 stack_test_ref = 21,\n",
    "    #                                 out='img_hyp,img_ren',\n",
    "    #                                 write_to_file = 'test.jpg') \n",
    "    # raise Exception('')\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for super resolution:\n",
    "    #--------------------------------------------------------------------------\n",
    "    import time\n",
    "    import luxpy as lx\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage import transform\n",
    "    import imageio\n",
    "    from skimage.transform import rescale,resize\n",
    "    \n",
    "    np.random.seed(1)    \n",
    "    \n",
    "    # Set some default parameters:\n",
    "    #----------------------------\n",
    "    load_hsi = False # If True: load hrci and hrhsi from npy-file.\n",
    "    file = input_img\n",
    "\n",
    "    cieobs = '1931_2' # CIE CMF set\n",
    "    linear_rgb = 1 # only used when srgb in hsi_to_rgb == True !!!\n",
    "    verbosity = 0\n",
    "    \n",
    "    # Create HR-rgb image and HR-HSI for code testing: \n",
    "    #---------------------------------------------------\n",
    "    # get an image:\n",
    "    im = imageio.v2.imread(file)/255\n",
    "    \n",
    "    # rescale to n x dimensions of typical hyperspectral camera:\n",
    "    n = 2 # downscale factor\n",
    "    w, h = 1280, 960\n",
    "    cr,cc = np.array(im.shape[:2])//2\n",
    "    crop = lambda im,cr,cc,h,w:im[(cr-h//2):(cr+h//2),(cc-w//2):(cc+w//2),:].copy()\n",
    "    im = crop(im,cr,cc,h*n,w*n)\n",
    "#     print('New image shape:',im.shape)\n",
    "    \n",
    "    # simulate HR hyperspectral image:\n",
    "    hrhsi = render_image(im,show=False)\n",
    "    wlr = getwlr([380,780,1]) #  = wavelength range of default TM30 rfl set\n",
    "    wlr = wlr[20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "    hrhsi = hrhsi[...,20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "#     print('Simulated HR-HSI shape:',hrhsi.shape)\n",
    "    # np.save(file[:-4]+'.npy',{'hrhsi':hrhsi,'im':im, 'wlr':wlr})\n",
    "    \n",
    "    # Illumination spectrum of HSI:    \n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "        \n",
    "    # Create fig and axes for plots:\n",
    "    if verbosity > 0: fig, axs = plt.subplots(1,3)\n",
    "    \n",
    "    # convert HR hsi to HR rgb image:\n",
    "    hrci = hsi_to_rgb(hrhsi, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[0].imshow(hrci)\n",
    "    \n",
    "    # create LR hsi image for testing:\n",
    "    dl = n \n",
    "    lrhsi = hrhsi[::dl,::dl,:]\n",
    "#     print('Simulated LR-HSI shape:',lrhsi.shape)\n",
    "    \n",
    "    # convert LR hsi to LR rgb image:\n",
    "    lrci = hsi_to_rgb(lrhsi, spd = eew, cieobs = cieobs, wl = wlr,linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[1].imshow(lrci)\n",
    "    \n",
    "    # # Perform rgb guided super-resolution:\n",
    "    #hrci = lrci # for testing of estimation code\n",
    "    tic = time.time()\n",
    "    hrhsi_est = get_superresolution_hsi(lrhsi, hrci, CSF = _CSF_NIKON_D700, wl = wlr)\n",
    "#     print('Elapsed time (s): {:1.4f}'.format(time.time() - tic))\n",
    "    hrci_est = hsi_to_rgb(hrhsi_est, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "\n",
    "    if verbosity > 0:  axs[2].imshow(hrci_est)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Plot some rfl to visually evaluate estimation accuracy:\n",
    "    \n",
    "    hsi_rmse = np.linalg.norm(hrhsi-hrhsi_est)/np.array(hrhsi.shape[:2]).prod()**0.5\n",
    "#     print('RMSE(ground-truth,estimate): {:1.4f}'.format(hsi_rmse))\n",
    "    \n",
    "    global illum_out\n",
    "    return illum_out\n",
    "    \n",
    "#     fig, axs = plt.subplots(1,4, figsize=(22,5))\n",
    "    \n",
    "#     axs[0].imshow(transform.rescale(lrci,dl,order=0,multichannel=True),aspect='auto')\n",
    "#     axs[0].set_title('Color image of LR-HSI\\n(HR-to-LR scale factor = {:1.2f})'.format(1/dl))\n",
    "#     axs[0].axis('off')\n",
    "#     axs[1].imshow(hrci_est,aspect='auto')\n",
    "#     axs[1].set_title('Color image of estimated HR-HSI')\n",
    "#     axs[1].axis('off')\n",
    "    \n",
    "#     px_rmse = ((hrhsi_est-hrhsi)**2).sum(axis=-1)**0.5 # rmse per pixel\n",
    "#     axs[2].set_title('RMSE(ground-truth, estimated) HR-HSI\\nRMSE = {:1.4f}, max = {:1.4f}'.format((px_rmse**2).mean()**0.5,px_rmse.max()))\n",
    "#     im = axs[2].imshow(px_rmse, cmap = 'jet',aspect='auto') # rmse per pixel\n",
    "#     cbar = axs[2].figure.colorbar(im, ax=axs[2])\n",
    "#     cbar.ax.set_ylabel('RMSE', rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    \n",
    "#     psorted = np.unravel_index(np.argsort(px_rmse, axis=None), px_rmse.shape) # index of pixels sorted by px_rmse\n",
    "#     np.random.seed(1)\n",
    "#     pxs = np.random.permutation(min(hrhsi.shape[:2]))[:12].reshape(2,3,2)\n",
    "#     iis = np.hstack((pxs[...,0].ravel(),psorted[0][-3:]))\n",
    "#     jjs = np.hstack((pxs[...,1].ravel(),psorted[1][-3:]))\n",
    "#     colors = np.array(['m','b','c','g','y','r','k','lightgrey','grey'])\n",
    "#     for t in range(len(iis)):\n",
    "#         ii,jj = iis[t],jjs[t]\n",
    "#         axs[1].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[2].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[3].plot(wlr,hrhsi[ii,jj,:],color = colors[t], linestyle ='-',label='ground-truth (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#         axs[3].plot(wlr,hrhsi_est[ii,jj,:],color = colors[t], linestyle = '--',label='estimate (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#     axs[3].legend(bbox_to_anchor=(1.05, 1))   \n",
    "#     axs[3].set_xlabel('Wavelengths (nm)')\n",
    "#     axs[3].set_ylabel('Spectral Reflectance')\n",
    "#     plt.subplots_adjust(right=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1ae358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.647198Z",
     "start_time": "2023-10-30T16:15:38.640680Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def illumEstOneFolder_prep():\n",
    "    images = Path(r\"data\\Training\\001_nonsleepyCombination\") #imgs\n",
    "    landmarks = []\n",
    "    fileNames = []\n",
    "    illums = []\n",
    "    \n",
    "    for img_file in images.glob(\"*.jpg\"):\n",
    "\n",
    "        print(os.path.basename(img_file)[:-4])\n",
    "        fileNames.append(os.path.basename(img_file)[:-4])\n",
    "        landmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "        illums.append(illuminanceEstimation(img_file))\n",
    "        retinexImplement(img_file)\n",
    "    \n",
    "    ilu_dis = pd.DataFrame({'File Names': fileNames, 'Landmark Confidence': landmarks, 'Illuminance': illums})\n",
    "    \n",
    "    print(ilu_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6f26ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:38.654391Z",
     "start_time": "2023-10-30T16:15:38.649202Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generateLandmarks(img):\n",
    "    img = cv2.imread(img)\n",
    "    detector = MTCNN()\n",
    "    output = detector.detect_faces(img)\n",
    "#     print(output[0]['confidence'])\n",
    "    \n",
    "    return output[0]['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a15479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:54:44.182865Z",
     "start_time": "2023-10-26T02:54:44.180882Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# notes:\n",
    "\n",
    "# average 2.67s per image for generating landmarks and illuminance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9a8d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:15:42.468103Z",
     "start_time": "2023-10-30T16:15:38.694647Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import URetinexNet\n",
    "from URetinex_Net import *\n",
    "\n",
    "# Import Arch_network\n",
    "import sys\n",
    "sys.path.append(r\"URetinex_Net\")\n",
    "\n",
    "# testing of URetinex.Net\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from network.Math_Module import P, Q\n",
    "from network.decom import Decom\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "from utils import *\n",
    "\n",
    "def one2three(x):\n",
    "    return torch.cat([x, x, x], dim=1).to(x)\n",
    "\n",
    "class Inference(nn.Module):\n",
    "    #Class Inference Methods\n",
    "    def __init__(self, opts):\n",
    "        super().__init__()\n",
    "        self.opts = opts\n",
    "        # loading decomposition model \n",
    "        self.model_Decom_low = Decom()\n",
    "        self.model_Decom_low = load_initialize(self.model_Decom_low, self.opts.Decom_model_low_path)\n",
    "        # loading R; old_model_opts; and L model\n",
    "        self.unfolding_opts, self.model_R, self.model_L= load_unfolding(self.opts.unfolding_model_path)\n",
    "        # loading adjustment model\n",
    "        self.adjust_model = load_adjustment(self.opts.adjust_model_path)\n",
    "        self.P = P()\n",
    "        self.Q = Q()\n",
    "\n",
    "        transform = [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform)\n",
    "        print(self.model_Decom_low)\n",
    "        print(self.model_R)\n",
    "        print(self.model_L)\n",
    "        print(self.adjust_model)\n",
    "        #time.sleep(8)\n",
    "\n",
    "    def unfolding(self, input_low_img):\n",
    "        for t in range(self.unfolding_opts.round):      \n",
    "            if t == 0: # initialize R0, L0\n",
    "                P, Q = self.model_Decom_low(input_low_img)\n",
    "            else: # update P and Q\n",
    "                w_p = (self.unfolding_opts.gamma + self.unfolding_opts.Roffset * t)\n",
    "                w_q = (self.unfolding_opts.lamda + self.unfolding_opts.Loffset * t)\n",
    "                P = self.P(I=input_low_img, Q=Q, R=R, gamma=w_p)\n",
    "                Q = self.Q(I=input_low_img, P=P, L=L, lamda=w_q) \n",
    "            R = self.model_R(r=P, l=Q)\n",
    "            L = self.model_L(l=Q)\n",
    "        return R, L\n",
    "    \n",
    "    def lllumination_adjust(self, L, ratio):\n",
    "        ratio = torch.ones(L.shape) * self.opts.ratio\n",
    "        return self.adjust_model(l=L, alpha=ratio)\n",
    "    \n",
    "    def forward(self, input_low_img):\n",
    "        if torch.cuda.is_available():\n",
    "            input_low_img = input_low_img\n",
    "        with torch.no_grad():\n",
    "            start = time.time()  \n",
    "            R, L = self.unfolding(input_low_img)\n",
    "            High_L = self.lllumination_adjust(L, self.opts.ratio)\n",
    "            I_enhance = High_L * R\n",
    "            p_time = (time.time() - start)\n",
    "        return I_enhance, p_time\n",
    "\n",
    "    def run(self, low_img_path):\n",
    "        file_name = os.path.basename(self.opts.img_path)\n",
    "        name = file_name.split('.')[0]\n",
    "        low_img = self.transform(Image.open(low_img_path)).unsqueeze(0)\n",
    "        enhance, p_time = self.forward(input_low_img=low_img)\n",
    "        if not os.path.exists(self.opts.output):\n",
    "            os.makedirs(self.opts.output)\n",
    "        save_path = os.path.join(self.opts.output, file_name.replace(name, \"%s_URetinexNet\"%(name)))\n",
    "        np_save_TensorImg(enhance, save_path)  \n",
    "        print(\"================================= time for %s: %f============================\"%(file_name, p_time))\n",
    "\n",
    "#         add to own function for input of img path\n",
    "def retinexImplement(img, outPath):\n",
    "    parser = argparse.ArgumentParser(description='Configure')\n",
    "    \n",
    "    # specify your data path here!\n",
    "    parser.add_argument('--img_path', type=str, default=img)\n",
    "    parser.add_argument('--output', type=str, default=outPath)\n",
    "    # ratio are recommended to be 3-5, bigger ratio will lead to over-exposure \n",
    "    parser.add_argument('--ratio', type=int, default=2)\n",
    "    # model path\n",
    "    parser.add_argument('--Decom_model_low_path', type=str, default=\"./URetinex_Net/ckpt/init_low.pth\")\n",
    "    parser.add_argument('--unfolding_model_path', type=str, default=\"./URetinex_Net/ckpt/unfolding.pth\")\n",
    "    parser.add_argument('--adjust_model_path', type=str, default=\"./URetinex_Net/ckpt/L_adjust.pth\")\n",
    "    parser.add_argument('--gpu_id', type=int, default=0)\n",
    "    \n",
    "#     opts = parser.parse_args() change parse_args() to parse_known_args\n",
    "    opts, _ = parser.parse_known_args()\n",
    "    for k, v in vars(opts).items():\n",
    "        print(k, v)\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(opts.gpu_id)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = Inference(opts)\n",
    "        print(\"CUDA (GPU) is available\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Loading the model on CPU...\")\n",
    "        model = Inference(opts).to(torch.device('cpu'))\n",
    "    \n",
    "#    \n",
    "    model.run(opts.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679d8739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T02:54:46.868723Z",
     "start_time": "2023-10-26T02:54:46.866229Z"
    }
   },
   "outputs": [],
   "source": [
    "# evalData_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4da41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:17:07.825603Z",
     "start_time": "2023-10-30T16:16:01.682695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_0_0.jpg\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illuminance: 0.29567792373263885\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_0_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_0_0.jpg: 4.860921============================\n",
      "Illuminance: 0.45679098484374997\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E786ACAE80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_15_0.jpg\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E7896B6200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "Illuminance: 0.2929762817534723\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_15_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_15_0.jpg: 4.375607============================\n",
      "Illuminance: 0.45493657617621525\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_30_0.jpg\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Illuminance: 0.29606498448350704\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_30_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 001_nonsleepyCombination_30_0.jpg: 4.372267============================\n",
      "Illuminance: 0.45702348750868055\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Creating..../data/Training/001_nonsleepyCombination/001_nonsleepyCombination_45_0.jpg\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "Illuminance: 0.2991066410894097\n",
      "img_path data\\Training\\001_nonsleepyCombination\\001_nonsleepyCombination_45_0.jpg\n",
      "output ./data/RetTraining/001_nonsleepyCombination/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 001_nonsleepyCombination_45_0.jpg: 4.340551============================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainingData_prep()\n",
      "Cell \u001b[1;32mIn[5], line 57\u001b[0m, in \u001b[0;36mtrainingData_prep\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(videos_file)\n\u001b[0;32m     56\u001b[0m training_video_paths\u001b[38;5;241m.\u001b[39mappend(video_path)\n\u001b[1;32m---> 57\u001b[0m frame_capture(video_path)\n",
      "Cell \u001b[1;32mIn[4], line 98\u001b[0m, in \u001b[0;36mframe_capture\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m#               post-retinex functions\u001b[39;00m\n\u001b[0;32m     97\u001b[0m                 retSave_path \u001b[38;5;241m=\u001b[39m retSave_path \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_file)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_URetinexNet.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 98\u001b[0m                 trainIllumsRet\u001b[38;5;241m.\u001b[39mappend(illuminanceEstimation(retSave_path))\n\u001b[0;32m    100\u001b[0m                 trainLandmarksRet\u001b[38;5;241m.\u001b[39mappend(generateLandmarks(retSave_path))\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m save_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/Evaluation/\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[6], line 728\u001b[0m, in \u001b[0;36milluminanceEstimation\u001b[1;34m(input_img)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;66;03m# # Perform rgb guided super-resolution:\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;66;03m#hrci = lrci # for testing of estimation code\u001b[39;00m\n\u001b[0;32m    727\u001b[0m     tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 728\u001b[0m     hrhsi_est \u001b[38;5;241m=\u001b[39m get_superresolution_hsi(lrhsi, hrci, CSF \u001b[38;5;241m=\u001b[39m _CSF_NIKON_D700, wl \u001b[38;5;241m=\u001b[39m wlr)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m#     print('Elapsed time (s): {:1.4f}'.format(time.time() - tic))\u001b[39;00m\n\u001b[0;32m    730\u001b[0m     hrci_est \u001b[38;5;241m=\u001b[39m hsi_to_rgb(hrhsi_est, spd \u001b[38;5;241m=\u001b[39m eew, cieobs \u001b[38;5;241m=\u001b[39m cieobs, wl \u001b[38;5;241m=\u001b[39m wlr, linear_rgb \u001b[38;5;241m=\u001b[39m linear_rgb)\n",
      "Cell \u001b[1;32mIn[6], line 638\u001b[0m, in \u001b[0;36mget_superresolution_hsi\u001b[1;34m(lrhsi, hrci, CSF, wl, csf_based_rgb_rounding, interp_type, k_neighbours, verbosity)\u001b[0m\n\u001b[0;32m    636\u001b[0m lrhsi_2d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((wlr,np\u001b[38;5;241m.\u001b[39mreshape(lrhsi,(lrhsi\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mlrhsi\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],lrhsi\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))) \u001b[38;5;66;03m# create 2D rfl database\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CSF \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: CSF \u001b[38;5;241m=\u001b[39m _CSF_NIKON_D700\n\u001b[1;32m--> 638\u001b[0m hrhsi \u001b[38;5;241m=\u001b[39m render_image(hrci, spd \u001b[38;5;241m=\u001b[39m eew,\n\u001b[0;32m    639\u001b[0m                      refspd \u001b[38;5;241m=\u001b[39m eew, rfl \u001b[38;5;241m=\u001b[39m lrhsi_2d, D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    640\u001b[0m                      interp_type \u001b[38;5;241m=\u001b[39m interp_type, k_neighbours \u001b[38;5;241m=\u001b[39m k_neighbours,\n\u001b[0;32m    641\u001b[0m                      verbosity \u001b[38;5;241m=\u001b[39m verbosity, show \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(verbosity),\n\u001b[0;32m    642\u001b[0m                      CSF \u001b[38;5;241m=\u001b[39m CSF, csf_based_rgb_rounding \u001b[38;5;241m=\u001b[39m csf_based_rgb_rounding) \u001b[38;5;66;03m# render HR-hsi from HR-ci using LR-HSI rfls as database        \u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hrhsi\n",
      "Cell \u001b[1;32mIn[6], line 362\u001b[0m, in \u001b[0;36mrender_image\u001b[1;34m(img, spd, rfl, out, refspd, D, cieobs, cspace, cspace_tf, CSF, interp_type, k_neighbours, show, verbosity, show_ref_img, stack_test_ref, write_to_file, csf_based_rgb_rounding)\u001b[0m\n\u001b[0;32m    358\u001b[0m rgb[rgb\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m _EPS \u001b[38;5;66;03m# avoid division by zero for pure blacks.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# Get unique rgb values and positions:\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m rgb_u, rgb_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(rgb, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# get rfl set:\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rfl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# use IESTM30['4880'] set \u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:317\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    314\u001b[0m     uniq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(uniq, \u001b[38;5;241m0\u001b[39m, axis)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniq\n\u001b[1;32m--> 317\u001b[0m output \u001b[38;5;241m=\u001b[39m _unique1d(consolidated, return_index,\n\u001b[0;32m    318\u001b[0m                    return_inverse, return_counts, equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[0;32m    319\u001b[0m output \u001b[38;5;241m=\u001b[39m (reshape_uniq(output[\u001b[38;5;241m0\u001b[39m]),) \u001b[38;5;241m+\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:338\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    336\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[1;32m--> 338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n\u001b[0;32m    339\u001b[0m mask[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (equal_nan \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfmM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    341\u001b[0m         np\u001b[38;5;241m.\u001b[39misnan(aux[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainingData_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8df106c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:17:10.623362Z",
     "start_time": "2023-10-30T16:17:10.620355Z"
    }
   },
   "outputs": [],
   "source": [
    "# requires images converted to feature array\n",
    "\n",
    "# base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.MeanSquaredError(),\n",
    "#               metrics=[tf.keras.metrics.Accuracy(),\n",
    "#                        tf.keras.metrics.Precision(),\n",
    "#                        tf.keras.metrics.Recall(),\n",
    "#                        tf.keras.metrics.F1Score()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4c5e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:17:19.742907Z",
     "start_time": "2023-10-30T16:17:19.020670Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)         1792      ['input_22[0][0]']            \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)         36928     ['block1_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)         0         ['block1_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)        73856     ['block1_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)        147584    ['block2_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)          0         ['block2_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)          295168    ['block2_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)          590080    ['block3_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)          590080    ['block3_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)          0         ['block3_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)          1180160   ['block3_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)          2359808   ['block4_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)          2359808   ['block4_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)          0         ['block4_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)          2359808   ['block4_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)          2359808   ['block5_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)          2359808   ['block5_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)            0         ['block5_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " flattened_features (Flatte  (None, 25088)                0         ['block5_pool[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " additional_dense (Dense)    (None, 64)                   1605696   ['flattened_features[0][0]']  \n",
      "                                                                                                  \n",
      " illuminance_retinex_output  (None, 1)                    65        ['additional_dense[0][0]']    \n",
      "  (Dense)                                                                                         \n",
      "                                                                                                  \n",
      " landmark_output (Dense)     (None, 10)                   650       ['additional_dense[0][0]']    \n",
      "                                                                                                  \n",
      " previous_illuminance_outpu  (None, 1)                    65        ['additional_dense[0][0]']    \n",
      " t (Dense)                                                                                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16321164 (62.26 MB)\n",
      "Trainable params: 16321164 (62.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "additional_dense_layer = tf.keras.layers.Dense(64, activation='relu', name='additional_dense')(flattened_features)\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = {\n",
    "    'landmark_output': tf.keras.layers.Dense(10, activation='relu', name='landmark_output')(additional_dense_layer),\n",
    "    'previous_illuminance': tf.keras.layers.Dense(1, activation='relu', name='previous_illuminance_output')(additional_dense_layer),\n",
    "    'illuminance_retinex': tf.keras.layers.Dense(1, activation='relu', name='illuminance_retinex_output')(additional_dense_layer)\n",
    "}\n",
    "\n",
    "# trainLandmarks = tf.keras.layers.Input(shape=(2))\n",
    "# trainIllumsRaw = tf.keras.layers.Input(shape=(1,))   \n",
    "# trainIllumsRet = tf.keras.layers.Input(shape=(1,))   \n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'landmark_output': 'mean_squared_error',\n",
    "        'previous_illuminance_output': 'mean_squared_error',\n",
    "        'illuminance_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'landmark_output': ['mse', \"accuracy\"],\n",
    "        'previous_illuminance_output': ['mse', \"accuracy\"],\n",
    "        'illuminance_retinex_output': ['mse', \"accuracy\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()\n",
    "# print(task_outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "3d821b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T08:39:01.364104Z",
     "start_time": "2023-10-26T08:39:01.165862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(multi_task_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6972d9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:17:25.507440Z",
     "start_time": "2023-10-30T16:17:25.502307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of the first layer: [(None, 224, 224, 3)]\n"
     ]
    }
   ],
   "source": [
    "first_layer = multi_task_model.layers[0]  # Get the first layer\n",
    "input_shape = first_layer.input_shape\n",
    "print(\"Input shape of the first layer:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37f2d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:07.750082Z",
     "start_time": "2023-10-30T16:18:07.745778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(trainLandmarks))\n",
    "print(len(trainIllumsRaw))\n",
    "print(len(trainIllumsRet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d29847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:04.838383Z",
     "start_time": "2023-10-30T16:18:04.833835Z"
    }
   },
   "outputs": [],
   "source": [
    "# multi_task_model.fit()\n",
    "trainLandmarks = trainLandmarks[:-1]\n",
    "trainIllumsRaw = trainIllumsRaw[:-1]\n",
    "# print(trainLandmarks)\n",
    "# print(trainIllumsRaw)\n",
    "# print(trainIllumsRet)\n",
    "\n",
    "trainIllumsRawArray = np.array(trainIllumsRaw)\n",
    "trainIllumsRetArray = np.array(trainIllumsRet)\n",
    "\n",
    "# print(trainIllumsRawArray)\n",
    "# print(trainIllumsRetArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d888c6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:09.578779Z",
     "start_time": "2023-10-30T16:18:09.574030Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'left_eye': (213, 232), 'right_eye': (306, 222), 'nose': (239, 283), 'mouth_left': (227, 342), 'mouth_right': (298, 332)}\n",
      "  0.29567792373263885 0.45679098484374997]\n",
      " [{'left_eye': (215, 230), 'right_eye': (307, 222), 'nose': (238, 285), 'mouth_left': (228, 339), 'mouth_right': (299, 333)}\n",
      "  0.2929762817534723 0.45493657617621525]\n",
      " [{'left_eye': (207, 242), 'right_eye': (299, 228), 'nose': (236, 291), 'mouth_left': (226, 352), 'mouth_right': (296, 340)}\n",
      "  0.29606498448350704 0.45702348750868055]]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.vstack((trainLandmarks, trainIllumsRaw, trainIllumsRet)).T\n",
    "print(Y_train)\n",
    "\n",
    "# Sample 2D NumPy array\n",
    "data = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eff25d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:13.562769Z",
     "start_time": "2023-10-30T16:18:13.554716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213 232 306 222 239 283 227 342 298 332]\n",
      " [215 230 307 222 238 285 228 339 299 333]\n",
      " [207 242 299 228 236 291 226 352 296 340]]\n"
     ]
    }
   ],
   "source": [
    "# Sample 2D NumPy array\n",
    "data = Y_train\n",
    "\n",
    "# Extract numerical values from the dictionaries\n",
    "numerical_values = []\n",
    "\n",
    "for row in data:\n",
    "    row_values = []\n",
    "    for element in row:\n",
    "        if isinstance(element, dict):\n",
    "            # Extract numerical values from the dictionary\n",
    "            dict_values = [val for key, val in element.items() if isinstance(val, tuple)]\n",
    "            for tpl in dict_values:\n",
    "                for value in tpl:\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        row_values.append(value)\n",
    "    numerical_values.append(row_values)\n",
    "\n",
    "# Print the numerical values\n",
    "# for row in numerical_values:\n",
    "#     print(row)\n",
    "\n",
    "numerical_values = np.array(numerical_values)\n",
    "print(numerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a40ff52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:17.619255Z",
     "start_time": "2023-10-30T16:18:17.600050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'data\\Training', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=11, \n",
    "                                                    class_mode='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e13d4b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:23.905407Z",
     "start_time": "2023-10-30T16:18:23.881752Z"
    }
   },
   "outputs": [],
   "source": [
    "for batch in train_generator:\n",
    "    images, labels = batch\n",
    "    break\n",
    "    print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "badf21bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:26.659543Z",
     "start_time": "2023-10-30T16:18:26.643416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  3 224 224   3], shape=(4,), dtype=int32)\n",
      "tf.Tensor([3], shape=(1,), dtype=int32)\n",
      "tf.Tensor([ 3 10], shape=(2,), dtype=int32)\n",
      "tf.Tensor([3], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "imageTensor = tf.convert_to_tensor(images)\n",
    "landmarkTensor = tf.convert_to_tensor(numerical_values)\n",
    "illuminanceTensor = tf.convert_to_tensor(trainIllumsRawArray)\n",
    "illumsRetTensor = tf.convert_to_tensor(trainIllumsRetArray)\n",
    "\n",
    "print(tf.shape(imageTensor))\n",
    "print(tf.shape(illuminanceTensor))\n",
    "print(tf.shape(landmarkTensor))\n",
    "print(tf.shape(illumsRetTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "72055f6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T08:42:21.716606Z",
     "start_time": "2023-10-26T08:42:21.709894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(imageTensor)[0].numpy())\n",
    "print(len(illuminanceTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "badb57bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:47.813248Z",
     "start_time": "2023-10-30T16:18:47.806678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  3 224 224   3], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "imageTensor = tf.reshape(imageTensor, (3, 224, 224, 3))\n",
    "print(tf.shape(imageTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e8ac7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:50.833217Z",
     "start_time": "2023-10-30T16:18:50.825727Z"
    }
   },
   "outputs": [],
   "source": [
    "class InputOutputShapeCallback(Callback):\n",
    "    def __init__(self, input_data, task_names):\n",
    "        super().__init__()\n",
    "        self.input_data = input_data\n",
    "        self.task_names = task_names\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Get the model's first layer (input layer) and last layer (output layer)\n",
    "        input_layer = self.model.layers[0]\n",
    "        output_layers = self.model.layers[1:]  # Exclude the input layer\n",
    "\n",
    "        # Print the shapes of the input and output tensors of the model\n",
    "        print(f\"Input Data Shape: {self.input_data.shape}\")\n",
    "        print(f\"Input Layer Shape: {input_layer.input_shape}\")\n",
    "\n",
    "        # Print the shapes of the output tensors for each task\n",
    "        for task_name, output_layer in zip(self.task_names, output_layers):\n",
    "            print(f\"Output Layer Shape for {task_name}: {output_layer.output_shape}\")\n",
    "\n",
    "# List of task names\n",
    "task_names = ['landmark_output', 'previous_illuminance_output', 'illuminance_retinex_output']\n",
    "\n",
    "# Create an instance of the callback with input data and task names\n",
    "shape_callback = InputOutputShapeCallback(input_data=imageTensor, task_names=task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3d61ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:18:58.644592Z",
     "start_time": "2023-10-30T16:18:56.828671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape: (3, 224, 224, 3)\n",
      "Input Layer Shape: [(None, 224, 224, 3)]\n",
      "Output Layer Shape for landmark_output: (None, 224, 224, 64)\n",
      "Output Layer Shape for previous_illuminance_output: (None, 224, 224, 64)\n",
      "Output Layer Shape for illuminance_retinex_output: (None, 112, 112, 64)\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['illuminance_retinex_output/kernel:0', 'illuminance_retinex_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['illuminance_retinex_output/kernel:0', 'illuminance_retinex_output/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1085, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1179, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n\n    ValueError: The two structures don't have the same sequence length. Input structure has length 5, while shallow structure has length 3.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m multi_task_model\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mimageTensor,\n\u001b[0;32m      2\u001b[0m                               y\u001b[38;5;241m=\u001b[39m[landmarkTensor, illuminanceTensor, illumsRetTensor],\n\u001b[0;32m      3\u001b[0m                               epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      4\u001b[0m                               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      5\u001b[0m                               callbacks\u001b[38;5;241m=\u001b[39m[shape_callback])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file299b0bt_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1085, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1179, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"C:\\Users\\michael\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n\n    ValueError: The two structures don't have the same sequence length. Input structure has length 5, while shallow structure has length 3.\n"
     ]
    }
   ],
   "source": [
    "history = multi_task_model.fit(x=imageTensor,\n",
    "                              y=[landmarkTensor, illuminanceTensor, illumsRetTensor],\n",
    "                              epochs=10,\n",
    "                              batch_size=4,\n",
    "                              callbacks=[shape_callback])\n",
    "\n",
    "\n",
    "# history = multi_task_model.fit(x=imageTensor,\n",
    "#                                y={'landmark_output': landmarkTensor, \n",
    "#                                 'previous_illuminance_output': illuminanceTensor, \n",
    "#                                 'illuminance_retinex_output': illumsRetTensor},\n",
    "#                                epochs=10,\n",
    "#                                batch_size=4,\n",
    "#                                callbacks=[shape_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "52600a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-26T08:25:25.942145Z",
     "start_time": "2023-10-26T08:25:25.934040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [10967.447265625,\n",
       "  10995.083984375,\n",
       "  10955.564453125,\n",
       "  10978.7080078125,\n",
       "  10981.8251953125,\n",
       "  10962.861328125,\n",
       "  10973.302734375,\n",
       "  10974.744140625,\n",
       "  10958.064453125,\n",
       "  10968.580078125],\n",
       " 'mse': [10967.447265625,\n",
       "  10995.083984375,\n",
       "  10955.564453125,\n",
       "  10978.7080078125,\n",
       "  10981.8251953125,\n",
       "  10962.8623046875,\n",
       "  10973.302734375,\n",
       "  10974.744140625,\n",
       "  10958.064453125,\n",
       "  10968.580078125],\n",
       " 'accuracy': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fab1e751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T09:11:38.404672Z",
     "start_time": "2023-10-24T09:11:38.396304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1603e-01, 5.1305e-01, 5.1783e-01, 5.2052e-01, 5.1887e-01,\n",
       "       5.1625e-01, 5.1905e-01, 5.2186e-01, 5.1639e-01, 5.1689e-01,\n",
       "       5.1621e-01, 5.1533e-01, 5.1777e-01])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_values\n",
    "trainIllumsRawArray\n",
    "trainIllumsRetArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f354310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T09:11:40.662748Z",
     "start_time": "2023-10-24T09:11:40.655325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9568e-01, 2.9298e-01, 2.9606e-01, 2.9911e-01, 2.9779e-01,\n",
       "       2.9541e-01, 2.9791e-01, 2.9995e-01, 2.9637e-01, 2.9697e-01,\n",
       "       2.9559e-01, 2.9536e-01, 2.9573e-01])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainIllumsRawArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e7e661e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T08:49:41.960426Z",
     "start_time": "2023-10-24T08:49:41.953075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1603e-01, 5.1305e-01, 5.1783e-01, 5.2052e-01, 5.1887e-01,\n",
       "       5.1625e-01, 5.1905e-01, 5.2186e-01, 5.1639e-01, 5.1689e-01,\n",
       "       5.1621e-01, 5.1533e-01, 5.1777e-01])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainIllumsRetArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8295d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
