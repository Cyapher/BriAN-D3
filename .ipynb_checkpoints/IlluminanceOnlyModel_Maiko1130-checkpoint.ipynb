{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22ff45d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:48:23.173899Z",
     "start_time": "2023-11-29T15:48:23.162383Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== IMPORTS/LIBRARIES =====================\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a8f96df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:32:45.073825Z",
     "start_time": "2023-11-30T01:32:45.027583Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== TRAINING HISTORY FUNCTIONS =====================\n",
    "def historyToCsv(history):\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Convert the datetime object to a string\n",
    "    filename_friendly_datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # save to csv: \n",
    "    hist_csv_file = 'history' + filename_friendly_datetime_string + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "def csvToHistory(csv_filename):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    hist_df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    history_dict = hist_df.to_dict(orient='list')\n",
    "\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32811683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T17:09:01.685641Z",
     "start_time": "2023-11-29T17:09:01.226296Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== MULTITASK MODEL SETUP =====================\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Dense(512, activation='linear', name='embedding')(flattened_features)\n",
    "\n",
    "# additional_dense_layer1 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense1')(embedding_layer)\n",
    "# additional_dense_layer2 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense2')(additional_dense_layer1)\n",
    "\n",
    "additional_dense_layer3 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense3')(embedding_layer)\n",
    "additional_dense_layer4 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense4')(additional_dense_layer3)\n",
    "\n",
    "# landmarks = tf.keras.layers.Dense(10, activation='linear', name='landmark_output')(additional_dense_layer2)\n",
    "illum = tf.keras.layers.Dense(1, activation='linear', name='previous_illuminance_output')(additional_dense_layer4)\n",
    "\n",
    "# # Reshape layer to the desired shape\n",
    "# reshaped_features = tf.keras.layers.Reshape((8, 8, 8))(embedding_layer)\n",
    "\n",
    "# # Conv2DTranspose layers instead of UpSampling2D\n",
    "# conv_transpose1 = tf.keras.layers.Conv2DTranspose(8, kernel_size=(3, 3), activation='relu', padding='same')(reshaped_features)\n",
    "# conv_transpose2 = tf.keras.layers.Conv2DTranspose(16, kernel_size=(3, 3), activation='relu', padding='same', strides=(2, 2))(conv_transpose1)\n",
    "# conv_transpose3 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), activation='relu', padding='same', strides=(2, 2))(conv_transpose2)\n",
    "\n",
    "# retIllum = tf.keras.layers.Conv2D(3, kernel_size=(3, 3), activation='relu', padding='same', name='image_retinex_output')(conv_transpose3 )\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = [illum]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss={\n",
    "#         'landmark_output': 'mean_squared_error',\n",
    "        'previous_illuminance_output': 'mean_squared_error'\n",
    "#         'image_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "#         'landmark_output': ['mse', \"mae\"],\n",
    "        'previous_illuminance_output': ['mse', \"mae\"]\n",
    "#         'image_retinex_output': ['mse', \"mae\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a57105f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:48:36.236039Z",
     "start_time": "2023-11-29T15:48:36.219037Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== ILLUMINANCE ONLY DATA GEN =====================\n",
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True,\n",
    "                 random_seed=None):  # Add a new parameter for random seed\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed  # Store the random seed\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "#         self.n_coords = 2  # Assuming landmark coordinates are 2-dimensional\n",
    "        self.n_illuminance = 1  # Assuming a single illuminance value\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1, random_state=self.random_seed).reset_index(drop=True)  # Use the random seed\n",
    "    \n",
    "    def __get_input(self, path, target_size):\n",
    "    \n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = tf.image.resize(image_arr, (target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr / 255.\n",
    "    \n",
    "    def __get_output(self, label, output_type):\n",
    "        # Assuming output_type is 'coordinates', 'illuminance', or 'adjusted_image_path'\n",
    "#         if output_type == 'coordinates':\n",
    "#             # Assuming label is a string containing a dictionary-like structure\n",
    "#             # Safely evaluate the string as a literal dictionary using ast.literal_eval\n",
    "#             coordinates_dict = ast.literal_eval(label)\n",
    "            \n",
    "#             # Extract x and y coordinates for each landmark\n",
    "#             landmarks = ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']\n",
    "#             coordinates_list = [coordinates_dict[landmark] for landmark in landmarks]\n",
    "            \n",
    "#             # Flatten the list and convert to numpy array\n",
    "#             coordinates_array = np.array([coord for landmark_coords in coordinates_list for coord in landmark_coords])\n",
    "            \n",
    "# #             print(\"Shape of landmarks_array:\", coordinates_array.shape)\n",
    "            \n",
    "#             # If there are exactly 10 values, return the array, otherwise raise an error\n",
    "#             if len(coordinates_array) == 10:\n",
    "#                 return coordinates_array\n",
    "#             else:\n",
    "#                 raise ValueError(\"Expected 10 coordinates, but found {}\".format(len(coordinates_array)))\n",
    "        if output_type == 'illuminance':\n",
    "            # Convert the illuminance value to a float\n",
    "            return float(label)\n",
    "#         elif output_type == 'adjusted_image_path':\n",
    "#             # Assuming label is the path to the adjusted image\n",
    "#             return self.__get_input(label, self.input_size)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        \n",
    "#         coords_batch = batches[self.y_col['coordinates']]\n",
    "        illuminance_batch = batches[self.y_col['illuminance']]\n",
    "#         adjusted_image_path_batch = batches[self.y_col['adjusted_image_path']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
    "\n",
    "#         y0_batch = np.asarray([self.__get_output(y, 'coordinates') for y in coords_batch])\n",
    "        y0_batch = np.asarray([self.__get_output(y, 'illuminance') for y in illuminance_batch])\n",
    "#         y2_batch = np.asarray([self.__get_output(y, 'adjusted_image_path') for y in adjusted_image_path_batch])\n",
    "\n",
    "        return X_batch, [y0_batch]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "\n",
    "        # Print a few examples of the data\n",
    "#         print(\"Sample X:\", tf.shape(X[0]))  # Print the first example in the batch\n",
    "#         print(\"Sample y[0] (landmarks):\", tf.shape(y[0][0]))  # Print the first example in the landmarks output\n",
    "#         print(\"Sample y[1] (illum):\", tf.shape(y[1][0]))  # Print the first example in the illum output\n",
    "#         print(\"Sample y[2] (adjusted_image_path):\", tf.shape(y[2][0]))  # Print the first example in the adjusted_image_path output\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97547b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T15:51:02.344996Z",
     "start_time": "2023-11-29T15:51:02.331718Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== CALLBACKS =====================\n",
    "\n",
    "class DynamicLearningRateScheduler(Callback):\n",
    "    def __init__(self, monitor_metric='val_loss', patience=3, factor=0.5, min_lr=1e-6):\n",
    "        super(DynamicLearningRateScheduler, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.wait = 0\n",
    "        self.best_metric = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_metric = logs.get(self.monitor_metric)\n",
    "\n",
    "        if current_metric is None:\n",
    "            raise ValueError(f\"Metric {self.monitor_metric} not found in training logs.\")\n",
    "\n",
    "        if current_metric < self.best_metric:\n",
    "            self.best_metric = current_metric\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                new_lr = max(self.model.optimizer.lr * self.factor, self.min_lr)\n",
    "                self.model.optimizer.lr = new_lr\n",
    "                print(f\"\\nLearning rate reduced to {new_lr}.\")\n",
    "                self.wait = 0\n",
    "\n",
    "dynamicLearningCallback = DynamicLearningRateScheduler(monitor_metric='val_loss', patience=3, factor=0.5, min_lr=1e-6)\n",
    "\n",
    "# class SaveModelEveryNEpochs(Callback):\n",
    "#     def __init__(self, save_path, save_freq=5):\n",
    "#         super(SaveModelEveryNEpochs, self).__init__()\n",
    "#         self.save_path = save_path\n",
    "#         self.save_freq = save_freq\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         if (epoch + 1) % self.save_freq == 0:\n",
    "#             model_filename = f\"{self.save_path}_epoch_{epoch + 1}.keras\"\n",
    "#             self.model.save('IllumsOnlyModel.keras')\n",
    "#             print(f\"\\nModel saved to {model_filename}.\")\n",
    "\n",
    "# callback_save_path = \"./data\"  # Change this to your desired save path\n",
    "# saveModelCallback = SaveModelEveryNEpochs(callback_save_path, save_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e36c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T16:25:36.429295Z",
     "start_time": "2023-11-29T16:25:36.354669Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== DATA GEN SETUP (ILLUMINANCE ONLY TASK) =====================\n",
    "\n",
    "train_df = pd.read_csv(\"./data/illuminance_results.csv\") # path to train_data csv\n",
    "train_df[\"Filename\"] = \"./data/Training/\" + train_df[\"Filename\"]\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "X_col = {'path': 'Filename'}\n",
    "y_col = {'illuminance': 'Illuminance'}\n",
    "\n",
    "# Create an instance of CustomDataGen\n",
    "train_gen = CustomDataGen(train_df, X_col, y_col, batch_size=32, input_size=(224, 224, 3))\n",
    "\n",
    "eval_df = pd.read_csv(\"./data/illuminance_results_eval.csv\") # path to eval_data csv\n",
    "eval_df[\"Filename\"] = \"./data/Evaluation/Evaluation/\" + eval_df[\"Filename\"]\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "eval_X_col = {'path': 'Filename'}\n",
    "eval_y_col = {'illuminance': 'Illuminance'}\n",
    "\n",
    "val_gen = CustomDataGen(eval_df, eval_X_col, eval_y_col, batch_size=32, input_size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e37cea76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T21:05:19.521188Z",
     "start_time": "2023-11-29T17:09:09.732259Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "940/940 [==============================] - 704s 747ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0166 - val_loss: 5.5465e-04 - val_mse: 5.5465e-04 - val_mae: 0.0173\n",
      "Epoch 2/20\n",
      "940/940 [==============================] - 718s 764ms/step - loss: 8.3595e-05 - mse: 8.3595e-05 - mae: 0.0070 - val_loss: 2.0239e-04 - val_mse: 2.0239e-04 - val_mae: 0.0122\n",
      "Epoch 3/20\n",
      "940/940 [==============================] - 708s 753ms/step - loss: 5.8534e-05 - mse: 5.8534e-05 - mae: 0.0059 - val_loss: 1.8996e-04 - val_mse: 1.8996e-04 - val_mae: 0.0098\n",
      "Epoch 4/20\n",
      "940/940 [==============================] - 736s 783ms/step - loss: 5.9918e-05 - mse: 5.9918e-05 - mae: 0.0059 - val_loss: 1.1838e-04 - val_mse: 1.1838e-04 - val_mae: 0.0076\n",
      "Epoch 5/20\n",
      "940/940 [==============================] - 741s 788ms/step - loss: 4.6381e-05 - mse: 4.6381e-05 - mae: 0.0052 - val_loss: 1.1114e-04 - val_mse: 1.1114e-04 - val_mae: 0.0077\n",
      "Epoch 6/20\n",
      "940/940 [==============================] - 728s 774ms/step - loss: 4.0894e-05 - mse: 4.0894e-05 - mae: 0.0049 - val_loss: 9.8082e-05 - val_mse: 9.8082e-05 - val_mae: 0.0084\n",
      "Epoch 7/20\n",
      "940/940 [==============================] - 721s 767ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0303 - val_loss: 0.0085 - val_mse: 0.0085 - val_mae: 0.0707\n",
      "Epoch 8/20\n",
      "940/940 [==============================] - 715s 760ms/step - loss: 5.8879e-04 - mse: 5.8879e-04 - mae: 0.0171 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0452\n",
      "Epoch 9/20\n",
      "940/940 [==============================] - ETA: 0s - loss: 2.1464e-04 - mse: 2.1464e-04 - mae: 0.0105\n",
      "Learning rate reduced to 4.999999873689376e-05.\n",
      "940/940 [==============================] - 723s 769ms/step - loss: 2.1464e-04 - mse: 2.1464e-04 - mae: 0.0105 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0460\n",
      "Epoch 10/20\n",
      "940/940 [==============================] - 718s 764ms/step - loss: 1.2683e-04 - mse: 1.2683e-04 - mae: 0.0078 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0469\n",
      "Epoch 11/20\n",
      "940/940 [==============================] - 723s 769ms/step - loss: 1.0977e-04 - mse: 1.0977e-04 - mae: 0.0074 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0440\n",
      "Epoch 12/20\n",
      "940/940 [==============================] - ETA: 0s - loss: 1.0014e-04 - mse: 1.0014e-04 - mae: 0.0072\n",
      "Learning rate reduced to 2.499999936844688e-05.\n",
      "940/940 [==============================] - 712s 757ms/step - loss: 1.0014e-04 - mse: 1.0014e-04 - mae: 0.0072 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0447\n",
      "Epoch 13/20\n",
      "940/940 [==============================] - 718s 764ms/step - loss: 7.7632e-05 - mse: 7.7632e-05 - mae: 0.0062 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0411\n",
      "Epoch 14/20\n",
      "940/940 [==============================] - 718s 764ms/step - loss: 7.4802e-05 - mse: 7.4802e-05 - mae: 0.0062 - val_loss: 0.0046 - val_mse: 0.0046 - val_mae: 0.0421\n",
      "Epoch 15/20\n",
      "940/940 [==============================] - ETA: 0s - loss: 6.9536e-05 - mse: 6.9536e-05 - mae: 0.0060\n",
      "Learning rate reduced to 1.249999968422344e-05.\n",
      "940/940 [==============================] - 673s 716ms/step - loss: 6.9536e-05 - mse: 6.9536e-05 - mae: 0.0060 - val_loss: 0.0051 - val_mse: 0.0051 - val_mae: 0.0430\n",
      "Epoch 16/20\n",
      "940/940 [==============================] - 684s 727ms/step - loss: 5.8980e-05 - mse: 5.8980e-05 - mae: 0.0054 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0411\n",
      "Epoch 17/20\n",
      "940/940 [==============================] - 683s 727ms/step - loss: 5.7248e-05 - mse: 5.7248e-05 - mae: 0.0053 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0413\n",
      "Epoch 18/20\n",
      "940/940 [==============================] - ETA: 0s - loss: 5.5777e-05 - mse: 5.5777e-05 - mae: 0.0053\n",
      "Learning rate reduced to 6.24999984211172e-06.\n",
      "940/940 [==============================] - 686s 729ms/step - loss: 5.5777e-05 - mse: 5.5777e-05 - mae: 0.0053 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0410\n",
      "Epoch 19/20\n",
      "940/940 [==============================] - 680s 724ms/step - loss: 4.9377e-05 - mse: 4.9377e-05 - mae: 0.0049 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0412\n",
      "Epoch 20/20\n",
      "940/940 [==============================] - 680s 724ms/step - loss: 4.8437e-05 - mse: 4.8437e-05 - mae: 0.0048 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0415\n"
     ]
    }
   ],
   "source": [
    "history = multi_task_model.fit(train_gen, epochs=20, validation_data=val_gen, callbacks=[dynamicLearningCallback])\n",
    "multi_task_model.save('IlluminanceOnlyModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97728945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T01:33:09.169081Z",
     "start_time": "2023-11-30T01:33:09.114208Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===================== SAVE MODEL WEIGHTS =====================\n",
    "\n",
    "historyToCsv(history)\n",
    "# multi_task_model.save('IlluminanceOnlyModel.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
