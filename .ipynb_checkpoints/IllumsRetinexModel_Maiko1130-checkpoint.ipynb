{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ac1435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:35:37.792270Z",
     "start_time": "2023-11-27T10:35:32.828343Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== IMPORTS/LIBRARIES =====================\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650123b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:06:21.854207Z",
     "start_time": "2023-11-27T10:06:21.835576Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== TRAINING HISTORY FUNCTIONS =====================\n",
    "def historyToCsv(history):\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Convert the datetime object to a string\n",
    "    filename_friendly_datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # save to csv: \n",
    "    hist_csv_file = 'history' + filename_friendly_datetime_string + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "def csvToHistory(csv_filename):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    hist_df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    history_dict = hist_df.to_dict(orient='list')\n",
    "\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa734c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:37:18.709862Z",
     "start_time": "2023-11-27T10:37:18.154632Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flattened_features (Flatten)   (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " embedding (Dense)              (None, 512)          12845568    ['flattened_features[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 8, 8, 8)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 8)   0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " additional_dense3 (Dense)      (None, 64)           32832       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 8)  0          ['up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " additional_dense4 (Dense)      (None, 64)           4160        ['additional_dense3[0][0]']      \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 8)  0          ['up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " previous_illuminance_output (D  (None, 1)           65          ['additional_dense4[0][0]']      \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " image_retinex_output (Conv2D)  (None, 224, 224, 3)  219         ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,597,532\n",
      "Trainable params: 27,597,532\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ===================== MULTITASK MODEL SETUP =====================\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Dense(512, activation='linear', name='embedding')(flattened_features)\n",
    "\n",
    "# additional_dense_layer1 = tf.keras.layers.Dense(64, name='additional_dense1')(embedding_layer)\n",
    "# additional_dense_layer2 = tf.keras.layers.Dense(64, name='additional_dense2')(additional_dense_layer1)\n",
    "\n",
    "additional_dense_layer3 = tf.keras.layers.Dense(64, name='additional_dense3')(embedding_layer)\n",
    "additional_dense_layer4 = tf.keras.layers.Dense(64, name='additional_dense4')(additional_dense_layer3)\n",
    "\n",
    "# additional_dense_layer3 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense3')(flattened_features)\n",
    "\n",
    "landmarks = tf.keras.layers.Dense(10, activation='linear', name='landmark_output')(additional_dense_layer4)\n",
    "illum = tf.keras.layers.Dense(1, activation='linear', name='previous_illuminance_output')(additional_dense_layer4)\n",
    "\n",
    "# Reshape layer to the desired shape\n",
    "reshaped_features = tf.keras.layers.Reshape((8, 8, 8))(embedding_layer)\n",
    "\n",
    "# Upsampling layers\n",
    "upsample1 = tf.keras.layers.UpSampling2D(size=(7, 7))(reshaped_features)\n",
    "upsample2 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample1)\n",
    "upsample3 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample2)\n",
    "\n",
    "retIllum = tf.keras.layers.Conv2D(3, kernel_size=(3, 3), activation='relu', padding='same', name='image_retinex_output')(upsample3)\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = [illum, retIllum]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "#         'landmark_output': 'mean_squared_error',\n",
    "        'previous_illuminance_output': 'mean_squared_error',\n",
    "        'image_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "#         'landmark_output': ['mse', \"mae\"],\n",
    "        'previous_illuminance_output': ['mse', \"mae\"],\n",
    "        'image_retinex_output': ['mse', \"mae\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()\n",
    "# plot_model(multi_task_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1565c5cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:38:19.074362Z",
     "start_time": "2023-11-27T10:38:19.056543Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== ILLUMS + RETINEX DATA GEN =====================\n",
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True,\n",
    "                 random_seed=None):  # Add a new parameter for random seed\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed  # Store the random seed\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "#         self.n_coords = 2  # Assuming landmark coordinates are 2-dimensional\n",
    "        self.n_illuminance = 1  # Assuming a single illuminance value\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1, random_state=self.random_seed).reset_index(drop=True)  # Use the random seed\n",
    "    \n",
    "    def __get_input(self, path, target_size):\n",
    "    \n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = tf.image.resize(image_arr, (target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr / 255.\n",
    "    \n",
    "    def __get_output(self, label, output_type):\n",
    "        # Assuming output_type is 'coordinates', 'illuminance', or 'adjusted_image_path'\n",
    "#         if output_type == 'coordinates':\n",
    "#             # Assuming label is a string containing a dictionary-like structure\n",
    "#             # Safely evaluate the string as a literal dictionary using ast.literal_eval\n",
    "#             coordinates_dict = ast.literal_eval(label)\n",
    "            \n",
    "#             # Extract x and y coordinates for each landmark\n",
    "#             landmarks = ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']\n",
    "#             coordinates_list = [coordinates_dict[landmark] for landmark in landmarks]\n",
    "            \n",
    "#             # Flatten the list and convert to numpy array\n",
    "#             coordinates_array = np.array([coord for landmark_coords in coordinates_list for coord in landmark_coords])\n",
    "            \n",
    "# #             print(\"Shape of landmarks_array:\", coordinates_array.shape)\n",
    "            \n",
    "#             # If there are exactly 10 values, return the array, otherwise raise an error\n",
    "#             if len(coordinates_array) == 10:\n",
    "#                 return coordinates_array\n",
    "#             else:\n",
    "#                 raise ValueError(\"Expected 10 coordinates, but found {}\".format(len(coordinates_array)))\n",
    "        if output_type == 'illuminance':\n",
    "            # Convert the illuminance value to a float\n",
    "            return float(label)\n",
    "        elif output_type == 'adjusted_image_path':\n",
    "            # Assuming label is the path to the adjusted image\n",
    "            return self.__get_input(label, self.input_size)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        \n",
    "#         coords_batch = batches[self.y_col['coordinates']]\n",
    "        illuminance_batch = batches[self.y_col['illuminance']]\n",
    "        adjusted_image_path_batch = batches[self.y_col['adjusted_image_path']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
    "\n",
    "#         y0_batch = np.asarray([self.__get_output(y, 'coordinates') for y in coords_batch])\n",
    "        y1_batch = np.asarray([self.__get_output(y, 'illuminance') for y in illuminance_batch])\n",
    "        y2_batch = np.asarray([self.__get_output(y, 'adjusted_image_path') for y in adjusted_image_path_batch])\n",
    "\n",
    "        return X_batch, [y1_batch, y2_batch]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b3649c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:33:14.414321Z",
     "start_time": "2023-11-27T10:33:11.790669Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== DATA GEN SETUP (LANDMARKS and ILLUMINANCE TASKS) =====================\n",
    "\n",
    "train_df = pd.read_csv(\"\") # path to train_data csv\n",
    "train_df[\"Filename\"] = \"./data/Training/\" + train_df[\"Filename\"]\n",
    "train_df[\"RetFilename\"] = \"./data/RetTraining/\" + train_df[\"RetFilename\"]\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "X_col = {'path': 'Filename'}\n",
    "y_col = {'illuminance': 'illuminance', 'adjusted_image_path': 'adjusted_image_path'}\n",
    "\n",
    "# Create an instance of CustomDataGen\n",
    "train_gen = CustomDataGen(train_df, X_col, y_col, batch_size=32, input_size=(224, 224, 3))\n",
    "\n",
    "eval_df = pd.read_csv(\"\") # path to eval_data csv\n",
    "eval_df[\"Filename\"] = \"./data/Evaluation/\" + eval_df[\"Filename\"]\n",
    "eval_df[\"RetFilename\"] = \"./data/RetEvaluation/\" + eval_df[\"RetFilename\"]\n",
    "\n",
    "# Define column indices or names for X and y\n",
    "eval_X_col = {'path': 'Filename'}\n",
    "eval_y_col = {'illuminance': 'illuminance','adjusted_image_path': 'adjusted_image_path'}\n",
    "\n",
    "val_gen = CustomDataGen(eval_df, eval_X_col, eval_y_col, batch_size=32, input_size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d01800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T09:37:10.104205Z",
     "start_time": "2023-11-25T09:37:10.069299Z"
    }
   },
   "outputs": [],
   "source": [
    "history = multi_task_model.fit(train_gen, epochs=50, validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fe86a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T10:42:44.317680Z",
     "start_time": "2023-11-27T10:42:44.057447Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===================== SAVE MODEL WEIGHTS =====================\n",
    "\n",
    "multi_task_model.save('IllumsRetinexModel.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
