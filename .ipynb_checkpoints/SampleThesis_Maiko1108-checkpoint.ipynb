{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69663c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:26.427070Z",
     "start_time": "2023-11-07T16:52:17.923732Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf89806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:32.246565Z",
     "start_time": "2023-11-07T16:52:32.238755Z"
    }
   },
   "outputs": [],
   "source": [
    "trainLandmarks = []\n",
    "trainLandmarksRet = []\n",
    "trainFileNames = []\n",
    "trainIllumsRaw = []\n",
    "trainIllumsRet = []\n",
    "\n",
    "evalLandmarks = []\n",
    "evalLandmarksRet = []\n",
    "evalFileNames = []\n",
    "evalIllumsRaw = []\n",
    "evalIllumsRet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096c8392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:34.739954Z",
     "start_time": "2023-11-07T16:52:34.686723Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def frame_capture(file): # (15 frames)\n",
    "    \n",
    "    cap = cv2.VideoCapture(file)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "            \n",
    "    current_frame = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "#         print(file)\n",
    "        if not ret:\n",
    "            current_frame = 0\n",
    "            break \n",
    "\n",
    "        if current_frame % 15 == 0:\n",
    "            \n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "            \n",
    "            parentDir = os.path.dirname(os.path.dirname(file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "            \n",
    "            childDir = os.path.dirname(file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "            \n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "            \n",
    "#             filename of txt document containing labels for current video\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                labelFile = labelFile.replace(\"nightno\", \"night_no\")\n",
    "            else:\n",
    "                scenario = \"\"\n",
    "                if \"sunglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                elif \"night_noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"night_noglasses\"    \n",
    "                elif \"noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"noglasses\"\n",
    "                elif \"night_glasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                else:\n",
    "                    scenario = \"glasses\"\n",
    "                \n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + scenario + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                if not os.path.exists(labelFile):                    \n",
    "                    labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + \"wh\" + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                \n",
    "                if not os.path.exists(labelFile): # if labels file is non-existent for the given video\n",
    "                    continue\n",
    "                \n",
    "            with open(labelFile) as f:\n",
    "                labels = f.readline()\n",
    "            try:\n",
    "                \n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                else:\n",
    "                    save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                \n",
    "#                 Creating..../data/Testing/037_sunglasses_mix/037_sunglasses_mix_7110_1.jpg\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "            print('Creating...' + file_name)\n",
    "            cv2.imwrite(file_name, frame)\n",
    "            \n",
    "            img_file = Path(file_name) # for Retinex images, use replace() to get path of same named images in order to get post-retinex illum\n",
    "            \n",
    "            if save_path == \"./data/Training/\":\n",
    "                trainFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                trainLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                trainIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetTraining/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                trainIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                trainLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "                \n",
    "                \n",
    "\n",
    "            elif save_path == \"./data/Evaluation/\":\n",
    "                evalFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                evalLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                evalIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetEvaluation/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                evalIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                evalLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "            \n",
    "            \n",
    "        current_frame += 1\n",
    "    \n",
    "#     cap.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb313c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T13:31:11.171528Z",
     "start_time": "2023-11-05T13:31:11.164774Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def frame_capture(file): # (per frame)\n",
    "    \n",
    "#     cap = cv2.VideoCapture(file)\n",
    "    \n",
    "#     try:\n",
    "#         if not os.path.exists('data'):\n",
    "#             os.makedirs('data')\n",
    "#     except OSError:\n",
    "#         print('Error: Creating directory of data')\n",
    "            \n",
    "#     current_frame = 0\n",
    "    \n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "# #         print(file)\n",
    "#         if not ret:\n",
    "#             current_frame = 0\n",
    "#             break \n",
    "            \n",
    "#         datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(file)))\n",
    "#         indexDataset = datasetDir.rfind('\\\\')\n",
    "#         datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "#         parentDir = os.path.dirname(os.path.dirname(file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "#         currDir = parentDir\n",
    "\n",
    "#         childDir = os.path.dirname(file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "#         indexParent = parentDir.rfind('\\\\')\n",
    "#         parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "#         indexChild = childDir.rfind('\\\\')\n",
    "#         childDir = childDir[indexChild:]\n",
    "\n",
    "# #             filename of txt document containing labels for current video\n",
    "#         if datasetDir[1:] == \"Training Dataset\":\n",
    "#             labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "#         elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "#             labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "#             labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "#             labelFile = labelFile.replace(\"nightno\", \"night_no\")\n",
    "#         else:\n",
    "#             scenario = \"\"\n",
    "#             if \"sunglasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"sunglasses\"\n",
    "#             elif \"night_noglasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"night_noglasses\"    \n",
    "#             elif \"noglasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"noglasses\"\n",
    "#             elif \"night_glasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"sunglasses\"\n",
    "#             else:\n",
    "#                 scenario = \"glasses\"\n",
    "\n",
    "#             labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + scenario + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "\n",
    "#             if not os.path.exists(labelFile):                    \n",
    "#                 labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + \"wh\" + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "\n",
    "#             labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "\n",
    "#         with open(labelFile) as f:\n",
    "#             labels = f.readline()\n",
    "#         try:\n",
    "\n",
    "#             if datasetDir[1:] == \"Training Dataset\":\n",
    "#                 save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "#                 file_name = save_path + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "#             elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "#                 save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "#                 file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "#             else:\n",
    "#                 save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "#                 file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "\n",
    "# #                 Creating..../data/Testing/037_sunglasses_mix/037_sunglasses_mix_7110_1.jpg\n",
    "\n",
    "#         except IndexError:\n",
    "#             continue\n",
    "\n",
    "#         print('Creating...' + file_name)\n",
    "#         cv2.imwrite(file_name, frame)\n",
    "\n",
    "#         img_file = Path(file_name) # for Retinex images, use replace() to get path of same named images in order to get post-retinex illum\n",
    "\n",
    "#         if save_path == \"./data/Training/\":\n",
    "#             trainFileNames.append(os.path.basename(img_file)[:-4])\n",
    "#             trainLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "#             trainIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "\n",
    "#             retSave_path = \"./data/RetTraining/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "#             retinexImplement(img_file, retSave_path)\n",
    "\n",
    "# #               post-retinex functions\n",
    "\n",
    "#             retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "#             trainIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "\n",
    "#             trainLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "\n",
    "\n",
    "\n",
    "#         elif save_path == \"./data/Evaluation/\":\n",
    "#             evalFileNames.append(os.path.basename(img_file)[:-4])\n",
    "#             evalLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "#             evalIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "\n",
    "#             retSave_path = \"./data/RetEvaluation/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "#             retinexImplement(img_file, retSave_path)\n",
    "\n",
    "# #               post-retinex functions\n",
    "\n",
    "#             retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "#             evalIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "\n",
    "#             evalLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "\n",
    "#         current_frame += 1\n",
    "    \n",
    "#     cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf88578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:36.758760Z",
     "start_time": "2023-11-07T16:52:36.746712Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Training Videos Path\n",
    "def trainingData_prep():\n",
    "    training_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Training Dataset\") #AVIs\n",
    "    training_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in training_videos.glob(\"*\"):\n",
    "        for scenario in driver.glob(\"*\"):\n",
    "            for videos_file in scenario.glob(\"*.avi\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "                datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "                indexDataset = datasetDir.rfind('\\\\')\n",
    "                datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "                parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "                currDir = parentDir\n",
    "\n",
    "                childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "                indexParent = parentDir.rfind('\\\\')\n",
    "                parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "                indexChild = childDir.rfind('\\\\')\n",
    "                childDir = childDir[indexChild:]\n",
    "\n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "                data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "                inputPath = save_path + folder_name\n",
    "\n",
    "                if not os.path.exists(inputPath):\n",
    "                    os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "                video_path = str(videos_file)\n",
    "                training_video_paths.append(video_path)\n",
    "                frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732f5fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:37.050991Z",
     "start_time": "2023-11-07T16:52:37.038199Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation Videos Path\n",
    "def evalData_prep():\n",
    "    evaluation_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset\") #AVIs\n",
    "    evaluation_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in evaluation_videos.glob(\"*\"):\n",
    "        for videos_file in driver.glob(\"*.mp4\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "            parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "\n",
    "            childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "            data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "            inputPath = save_path + folder_name\n",
    "\n",
    "            if not os.path.exists(inputPath):\n",
    "                os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "            video_path = str(videos_file)\n",
    "            evaluation_video_paths.append(video_path)\n",
    "            frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2243a300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:37.339372Z",
     "start_time": "2023-11-07T16:52:37.321478Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Testing Videos Path\n",
    "def testData_prep():\n",
    "    testing_videos = Path(r\"NTHU Dataset\\Testing_Dataset\") #MP4s\n",
    "    testing_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for videos_file in testing_videos.glob(\"*.mp4\"):\n",
    "        print(videos_file)\n",
    "\n",
    "#         note: videos_file refers to direct path of current video file\n",
    "\n",
    "        print(os.path.dirname(videos_file))\n",
    "\n",
    "        datasetDir = os.path.dirname(videos_file)\n",
    "        indexDataset = datasetDir.rfind('\\\\')\n",
    "        datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "        save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "        folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "        print(save_path + folder_name)\n",
    "\n",
    "        data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "        inputPath = save_path + folder_name\n",
    "\n",
    "        if not os.path.exists(inputPath):\n",
    "            os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "        video_path = str(videos_file)\n",
    "        testing_video_paths.append(video_path)\n",
    "        frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b6f26ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:39.113276Z",
     "start_time": "2023-11-07T16:52:39.101574Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generateLandmarks(img):\n",
    "    img = cv2.imread(img)\n",
    "    detector = MTCNN()\n",
    "    output = detector.detect_faces(img)\n",
    "#     print(output[0]['confidence'])\n",
    "    \n",
    "    return output[0]['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0936f309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:39.463615Z",
     "start_time": "2023-11-07T16:52:39.397210Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- ILLUM EST FUNCTIONS\n",
    "\"\"\"\n",
    "Module for hyper spectral image simulation\n",
    "==========================================\n",
    "\n",
    " :_HYPSPCIM_PATH: path to module\n",
    "\n",
    " :_HYPSPCIM_DEFAULT_IMAGE: path + filename to default image\n",
    " \n",
    " :_CSF_NIKON_D700: Nikon D700 camera sensitivity functions\n",
    " \n",
    " :_ROUNDING: rounding of input to xyz_to_rfl() search algorithm for improved speed\n",
    "\n",
    " :xyz_to_rfl(): approximate spectral reflectance of xyz based on k nearest \n",
    "                neighbour interpolation of samples from a standard reflectance \n",
    "                set.\n",
    "\n",
    " :render_image(): Render image under specified light source spd.\n",
    "\n",
    " :get_superresolution_hsi(): Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "\n",
    " :hsi_to_rgb(): Convert HyperSpectral Image to rgb\n",
    " \n",
    " :rfl_to_rgb(): Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "     \n",
    ".. codeauthor:: Kevin A.G. Smet (ksmet1977 at gmail.com)\n",
    "\"\"\"\n",
    "\n",
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "\n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "illum_out = 0\n",
    "\n",
    "__all__ =['_HYPSPCIM_PATH','_HYPSPCIM_DEFAULT_IMAGE','render_image','xyz_to_rfl',\n",
    "          'get_superresolution_hsi','hsi_to_rgb','rfl_to_rgb','_CSF_NIKON_D700']             \n",
    "\n",
    "_HYPSPCIM_PATH = _PKG_PATH + _SEP + 'hypspcim' + _SEP\n",
    "_HYPSPCIM_DEFAULT_IMAGE = _PKG_PATH + _SEP + 'toolboxes' + _SEP + 'hypspcim' +  _SEP + 'data' + _SEP + 'testimage1.jpg'\n",
    "\n",
    "\n",
    "_ROUNDING = 6 # to speed up xyz_to_rfl search algorithm, increase if kernel dies!!!\n",
    "\n",
    "# Nikon D700 camera sensitivity functions:\n",
    "_CSF_NIKON_D700 = np.vstack((np.arange(400,710,10),\n",
    "                             np.array([[0.005, 0.007, 0.012, 0.015, 0.023, 0.025, 0.030, 0.026, 0.024, 0.019, 0.010, 0.004, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  0.000,  0.000,  0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000], \n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.002, 0.003, 0.005, 0.007, 0.012, 0.013, 0.015, 0.016, 0.017, 0.020, 0.013, 0.011, 0.009, 0.005,  0.001,  0.001,  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.002, 0.002, 0.003],\n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.003, 0.010, 0.012,  0.013,  0.022,  0.020, 0.020, 0.018, 0.017, 0.016, 0.016, 0.014, 0.014, 0.013]])[::-1]))\n",
    "\n",
    "\n",
    "def xyz_to_rfl(xyz, CSF = None, rfl = None, out = 'rfl_est', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {},\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, verbosity = 0,\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Approximate spectral reflectance of xyz values based on nd-dimensional linear interpolation \n",
    "    or k nearest neighbour interpolation of samples from a standard reflectance set.\n",
    "    \n",
    "    Args:\n",
    "        :xyz: \n",
    "            | ndarray with xyz values of target points.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb (float) values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'rfl_est' or str, optional\n",
    "        :refspd: \n",
    "            | None, optional\n",
    "            | Refer ence spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65.\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set used for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | :rfl_est:\n",
    "            | ndarrays with estimated reflectance spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    \n",
    "    wlr = rfl[0]\n",
    "    \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "        \n",
    "    # Calculate rgb values of standard rfl set under refspd:\n",
    "    if CSF is None:\n",
    "        # Calculate lab coordinates:\n",
    "        xyz_rr, xyz_wr = spd_to_xyz(refspd, relative = True, rfl = rfl, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_rr = colortf(xyz_rr, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)[:,0,:]\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions\n",
    "        rgb_rr = rfl_to_rgb(rfl, spd = refspd, CSF = CSF, wl = None)   \n",
    "        lab_rr = rgb_rr\n",
    "        xyz = xyz\n",
    "        lab_rr = np.round(lab_rr,csf_based_rgb_rounding) # speed up search\n",
    "        \n",
    "        global illum_out\n",
    "        illum_out = np.mean(lab_rr)\n",
    "        print(\"Illuminance: \" + str(np.mean(lab_rr)))\n",
    "        \n",
    "    # Convert xyz to lab-type values under refspd:\n",
    "    if CSF is None:\n",
    "        lab = colortf(xyz, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)\n",
    "    else:\n",
    "        lab = xyz # xyz contained rgb values !!!\n",
    "        rgb = xyz\n",
    "        lab = np.round(lab,csf_based_rgb_rounding) # speed up search\n",
    "    \n",
    "    if interp_type == 'nearest':\n",
    "        # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "        # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "        # Construct cKDTree:\n",
    "        tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "        \n",
    "        # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "        d, inds = tree.query(lab, k = k_neighbours )\n",
    "        if k_neighbours  > 1:\n",
    "            d += _EPS\n",
    "            w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "            rfl_est = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "        else:\n",
    "            rfl_est = rfl[inds+1,:].copy()\n",
    "    elif interp_type == 'nd':\n",
    "\n",
    "        rfl_est = math.ndinterp1_scipy(lab_rr, rfl[1:], lab)\n",
    "            \n",
    "        _isnan = np.isnan(rfl_est[:,0]) \n",
    "\n",
    "        if (_isnan.any()): #do nearest neigbour method for those that fail using Delaunay (i.e. ndinterp1_scipy)\n",
    "\n",
    "            # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "            # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "            # Construct cKDTree:\n",
    "            tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "\n",
    "            # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "            d, inds = tree.query(lab[_isnan,...], k = k_neighbours )\n",
    "\n",
    "            if k_neighbours  > 1:\n",
    "                d += _EPS\n",
    "                w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "                rfl_est_isnan = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "            else:\n",
    "                rfl_est_isnan = rfl[inds+1,:].copy()\n",
    "            rfl_est[_isnan, :] = rfl_est_isnan\n",
    "\n",
    "    else:\n",
    "        raise Exception('xyz_to_rfl(): unsupported interp_type!')\n",
    "    \n",
    "    rfl_est[rfl_est<0] = 0 #can occur for points outside convexhull of standard rfl set.\n",
    "\n",
    "    rfl_est = np.vstack((rfl[0],rfl_est))\n",
    "        \n",
    "    if ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('lab_est' in out.split(',')) | ('DEi_ab' in out.split(',')) | ('DEa_ab' in out.split(','))) & (CSF is None):\n",
    "        xyz_est, _ = spd_to_xyz(refspd, rfl = rfl_est, relative = True, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_est = colortf(xyz_est, tf = cspace, fwtf = cspace_tf_copy)[:,0,:]\n",
    "        DEi_ab = np.sqrt(((lab_est[:,1:3]-lab[:,1:3])**2).sum(axis=1))\n",
    "        DEa_ab = DEi_ab.mean()\n",
    "    elif ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('rgb_est' in out.split(',')) | ('DEi_rgb' in out.split(',')) | ('DEa_rgb' in out.split(','))) & (CSF is not None):\n",
    "        rgb_est = rfl_to_rgb(rfl_est[1:], spd = refspd, CSF = CSF, wl = wlr) \n",
    "        xyz_est = rgb_est\n",
    "        DEi_rgb = np.sqrt(((rgb_est - rgb)**2).sum(axis=1))\n",
    "        DEa_rgb = DEi_rgb.mean()\n",
    "\n",
    "        \n",
    "    if verbosity > 0:\n",
    "        if CSF is None:\n",
    "            ax = plot_color_data(lab[...,1], lab[...,2], z = lab[...,0], \\\n",
    "                            show = False, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'ro', label = 'Original')\n",
    "            plot_color_data(lab_est[...,1], lab_est[...,2], z = lab_est[...,0], \\\n",
    "                            show = True, axh = ax, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'bd', label = 'Rendered')\n",
    "        else:\n",
    "            n = 100 #min(rfl.shape[0]-1,rfl_est.shape[0]-1)\n",
    "            s = np.random.permutation(rfl.shape[0]-1)[:min(n,rfl.shape[0]-1)]\n",
    "            st = np.random.permutation(rfl_est.shape[0]-1)[:min(n,rfl_est.shape[0]-1)]\n",
    "            fig = plt.figure()\n",
    "            ax = np.zeros((3,),dtype=np.object)\n",
    "            ax[0] = fig.add_subplot(131)\n",
    "            ax[1] = fig.add_subplot(132)\n",
    "            ax[2] = fig.add_subplot(133,projection='3d')\n",
    "            ax[0].plot(rfl[0],rfl[1:][s].T, linestyle = '-')\n",
    "            ax[0].set_title('Original RFL set (random selection of all)')\n",
    "            ax[0].set_ylim([0,1])\n",
    "            ax[1].plot(rfl_est[0],rfl_est[1:][st].T, linestyle = '--')\n",
    "            ax[0].set_title('Estimated RFL set (random selection of targets)')\n",
    "            ax[1].set_ylim([0,1])\n",
    "            ax[2].plot(rgb[st,0],rgb[st,1],rgb[st,2],'ro', label = 'Original')\n",
    "            ax[2].plot(rgb_est[st,0],rgb_est[st,1],rgb_est[st,2],'bd', label = 'Rendered')\n",
    "            ax[2].legend()\n",
    "    if out == 'rfl_est':\n",
    "        return rfl_est\n",
    "    elif out == 'rfl_est,xyz_est':\n",
    "        return rfl_est, xyz_est\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "\n",
    "def render_image(img = None, spd = None, rfl = None, out = 'img_hyp', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {}, CSF = None,\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, show = True,\n",
    "                 verbosity = 0, show_ref_img = True,\\\n",
    "                 stack_test_ref = 12,\\\n",
    "                 write_to_file = None,\\\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Render image under specified light source spd.\n",
    "    \n",
    "    Args:\n",
    "        :img: \n",
    "            | None or str or ndarray with float (max = 1) rgb image.\n",
    "            | None load a default image.\n",
    "        :spd: \n",
    "            | ndarray, optional\n",
    "            | Light source spectrum for rendering\n",
    "            | If None: use CIE illuminant F4\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'img_hyp' or str, optional\n",
    "            |  (other option: 'img_ren': rendered image under :spd:)\n",
    "        :refspd:\n",
    "            | None, optional\n",
    "            | Reference spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65 (srgb has a D65 white point)\n",
    "        :D: \n",
    "            | None, optional\n",
    "            | Degree of (von Kries) adaptation from spd to refspd. \n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :show: \n",
    "            | True, optional\n",
    "            |  Show images.\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "              rendered image pixels.\n",
    "        :show_ref_img:\n",
    "            | True, optional\n",
    "            | True: shows rendered image under reference spd. False: shows\n",
    "            |  original image.\n",
    "        :write_to_file:\n",
    "            | None, optional\n",
    "            | None: do nothing, else: write to filename(+path) in :write_to_file:\n",
    "        :stack_test_ref: \n",
    "            | 12, optional\n",
    "            |   - 12: left (test), right (ref) format for show and imwrite\n",
    "            |   - 21: top (test), bottom (ref)\n",
    "            |   - 1: only show/write test\n",
    "            |   - 2: only show/write ref\n",
    "            |   - 0: show both, write test\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | img_hyp, img_ren, \n",
    "            | ndarrays with float hyperspectral image and rendered images \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get image:\n",
    "    #imread = lambda x: plt.imread(x) #matplotlib.pyplot\n",
    "   \n",
    "    if img is not None:\n",
    "        if isinstance(img,str):\n",
    "            img = plt.imread(img).copy() # use matplotlib.pyplot's imread\n",
    "    else:\n",
    "        img = plt.imread(_HYPSPCIM_DEFAULT_IMAGE).copy()\n",
    "    \n",
    "    if img.dtype == np.uint8: \n",
    "        img = img/255\n",
    "    elif img.dtype == np.uint16:\n",
    "        img = img/(2**16-1)\n",
    "    elif (img.dtype == np.float64) | (img.dtype == np.float32):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    if img.max() > 1.0: raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    \n",
    "    \n",
    "    # Convert to 2D format:\n",
    "    rgb = img.reshape(img.shape[0]*img.shape[1],3) # *1.0: make float\n",
    "    rgb[rgb==0] = _EPS # avoid division by zero for pure blacks.\n",
    "\n",
    "    \n",
    "    # Get unique rgb values and positions:\n",
    "    rgb_u, rgb_indices = np.unique(rgb, return_inverse=True, axis = 0)\n",
    "\n",
    "    \n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    wlr = rfl[0] # spectral reflectance set determines wavelength range for estimation (xyz_to_rfl())\n",
    "        \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "\n",
    "\n",
    "    # Convert rgb_u to xyz and lab-type values under assumed refspd:\n",
    "    if CSF is None:\n",
    "        xyz_wr = spd_to_xyz(refspd, cieobs = cieobs, relative = True)\n",
    "        xyz_ur = colortf(rgb_u*255, tf = 'srgb>xyz')\n",
    "    else:\n",
    "        xyz_ur = rgb_u # for input in xyz_to_rfl (when CSF is not None: this functions assumes input is indeed rgb !!!)\n",
    "    \n",
    "    # Estimate rfl's for xyz_ur:\n",
    "    rfl_est, xyzri = xyz_to_rfl(xyz_ur, rfl = rfl, out = 'rfl_est,xyz_est', \\\n",
    "                 refspd = refspd, D = D, cieobs = cieobs, \\\n",
    "                 cspace = cspace, cspace_tf = cspace_tf, CSF = CSF,\\\n",
    "                 interp_type = interp_type, k_neighbours = k_neighbours, \n",
    "                 verbosity = verbosity,\n",
    "                 csf_based_rgb_rounding = csf_based_rgb_rounding)\n",
    "\n",
    "    # Get default test spd if none supplied:\n",
    "    if spd is None:\n",
    "        spd = _CIE_ILLUMINANTS['F4']\n",
    "        \n",
    "    if CSF is None:\n",
    "        # calculate xyz values under test spd:\n",
    "        xyzti, xyztw = spd_to_xyz(spd, rfl = rfl_est, cieobs = cieobs, out = 2)\n",
    "    \n",
    "        # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            xyzti = cat.apply(xyzti, xyzw1 = xyztw, xyzw2 = xyz_wr, D = D)\n",
    "    \n",
    "        # Convert xyzti under test spd to srgb:\n",
    "        rgbti = colortf(xyzti, tf = 'srgb')/255\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions under spd:\n",
    "        rgbti = rfl_to_rgb(rfl_est, spd = spd, CSF = CSF, wl = None) \n",
    "        \n",
    "         # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            white = np.ones_like(spd)\n",
    "            white[0] = spd[0]\n",
    "            rgbwr = rfl_to_rgb(white, spd = refspd, CSF = CSF, wl = None)\n",
    "            rgbwt = rfl_to_rgb(white, spd = spd, CSF = CSF, wl = None)\n",
    "            rgbti = cat.apply_vonkries2(rgbti,rgbwt,rgbwr,xyzw0=np.array([[1.0,1.0,1.0]]), in_type='rgb',out_type= 'rgb',D=1)\n",
    "        \n",
    "    \n",
    "    # Reconstruct original locations for rendered image rgbs:\n",
    "    img_ren = rgbti[rgb_indices]\n",
    "    img_ren.shape = img.shape # reshape back to 3D size of original\n",
    "    img_ren = img_ren\n",
    "    \n",
    "    # For output:\n",
    "    if show_ref_img == True:\n",
    "        rgb_ref = colortf(xyzri, tf = 'srgb')/255 if (CSF is None) else xyzri # if CSF not None: xyzri contains rgbri !!!\n",
    "        img_ref = rgb_ref[rgb_indices]\n",
    "        img_ref.shape = img.shape # reshape back to 3D size of original\n",
    "        img_str = 'Rendered (under ref. spd)'\n",
    "        img = img_ref\n",
    "    else:\n",
    "        img_str = 'Original'\n",
    "        img = img\n",
    "       \n",
    "    \n",
    "    if (stack_test_ref > 0) | show == True:\n",
    "        if stack_test_ref == 21:\n",
    "            img_original_rendered = np.vstack((img_ren,np.ones((4,img.shape[1],3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd)\\n ' + img_str \n",
    "        elif stack_test_ref == 12:\n",
    "            img_original_rendered = np.hstack((img_ren,np.ones((img.shape[0],4,3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd) | ' + img_str \n",
    "        elif stack_test_ref == 1:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str = 'Rendered (under test spd)' \n",
    "        elif stack_test_ref == 2:\n",
    "            img_original_rendered = img\n",
    "            img_original_rendered_str = img_str\n",
    "        elif stack_test_ref == 0:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str =  'Rendered (under test spd)' \n",
    "            \n",
    "    if write_to_file is not None:\n",
    "        # Convert from RGB to BGR formatand write:\n",
    "        #print('Writing rendering results to image file: {}'.format(write_to_file))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imsave(write_to_file, img_original_rendered)\n",
    "            \n",
    "    if show == True:\n",
    "        # show images using pyplot.show():\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.imshow(img_original_rendered)\n",
    "        plt.title(img_original_rendered_str)\n",
    "        plt.gca().get_xaxis().set_ticklabels([])\n",
    "        plt.gca().get_yaxis().set_ticklabels([])\n",
    "        \n",
    "        if stack_test_ref == 0:\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title(img_str)\n",
    "            plt.axis('off')\n",
    "      \n",
    "    if 'img_hyp' in out.split(','):\n",
    "        # Create hyper_spectral image:\n",
    "        rfl_image_2D = rfl_est[rgb_indices+1,:] # create array with all rfls required for each pixel\n",
    "        img_hyp = rfl_image_2D.reshape(img.shape[0],img.shape[1],rfl_image_2D.shape[1])\n",
    "\n",
    "\n",
    "    # Setup output:\n",
    "    if out == 'img_hyp':\n",
    "        return img_hyp\n",
    "    elif out == 'img_ren':\n",
    "        return img_ren\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "def rfl_to_rgb(rfl, spd = None, CSF = None, wl = None, normalize_to_white = True):\n",
    "    \"\"\" \n",
    "    Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "    \n",
    "    Args:\n",
    "        :rfl:\n",
    "            | ndarray with spectral reflectance functions (1st row is wavelengths if wl is None).\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True: white-balance output rgb to a perfect white diffuser.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb values for each spectral reflectance functions\n",
    "    \"\"\"\n",
    "    rfl_cp = rfl.copy()\n",
    "    if (wl is None): \n",
    "        wl = rfl_cp[0] \n",
    "        rfl_cp = rfl_cp[1:]\n",
    "    wlr = getwlr(wl)\n",
    "    if spd is not None:\n",
    "        spd = cie_interp(spd,wlr,kind='linear')[1:]\n",
    "    else:\n",
    "        spd = np.ones_like(wlr)\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    CSF = cie_interp(CSF,wlr,kind='linear')\n",
    "    CSF[1:] = CSF[1:]*spd\n",
    "    rgb = rfl_cp @ CSF[1:].T \n",
    "    if normalize_to_white:\n",
    "        white = np.ones_like(spd)\n",
    "        white = white/white.sum()*spd.sum()\n",
    "        rgbw = white @ CSF[1:].T  \n",
    "        rgb = rgb/rgbw.max(axis = 0,keepdims=True) \n",
    "    \n",
    "    return rgb\n",
    "\n",
    "    \n",
    "    \n",
    "def hsi_to_rgb(hsi, spd = None, cieobs = _CIEOBS, srgb = False, \n",
    "               linear_rgb = False, CSF = None, normalize_to_white = True, \n",
    "               wl = [380,780,1]):\n",
    "    \"\"\" \n",
    "    Convert HyperSpectral Image to rgb.\n",
    "    \n",
    "    Args:\n",
    "        :hsi:\n",
    "            | ndarray with hyperspectral image [M,N,L]\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set to convert spectral data to xyz tristimulus values.\n",
    "        :srgb:\n",
    "            | False, optional\n",
    "            | If False: Use xyz_to_srgb(spd_to_xyz(...)) to convert to srgb values\n",
    "            | If True: use camera sensitivity functions.\n",
    "        :linear_rgb:\n",
    "            | False, optional\n",
    "            | If False: use gamma = 2.4 in xyz_to_srgb, if False: use gamma = 1 and set :use_linear_part: to False.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True & CSF is not None: white-balance output rgb to a perfect white diffuser.\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb image [M,N,3]\n",
    "    \"\"\"\n",
    "    if spd is None:\n",
    "        spd = _CIE_E.copy()\n",
    "    wlr = getwlr(wl)\n",
    "    spd = cie_interp(spd,wl,kind='linear')\n",
    "    \n",
    "    hsi_2d = np.reshape(hsi,(hsi.shape[0]*hsi.shape[1],hsi.shape[2]))\n",
    "    if srgb:\n",
    "        xyz = spd_to_xyz(spd, cieobs = cieobs, relative = True, rfl = np.vstack((wlr,hsi_2d)))\n",
    "        gamma = 1 if linear_rgb else 2.4\n",
    "        rgb = xyz_to_srgb(xyz, gamma = gamma, use_linear_part = not linear_rgb)/255\n",
    "    else:\n",
    "        if CSF is None: CSF = _CSF_NIKON_D700\n",
    "        rgb = rfl_to_rgb(hsi_2d, spd = spd, CSF = CSF, wl = wl, normalize_to_white = normalize_to_white)        \n",
    "    return np.reshape(rgb,(hsi.shape[0],hsi.shape[1],3))\n",
    "\n",
    "       \n",
    "def get_superresolution_hsi(lrhsi, hrci, CSF, wl = [380,780,1], csf_based_rgb_rounding = _ROUNDING,\n",
    "                            interp_type = 'nd', k_neighbours = 4, verbosity = 0):\n",
    "    \"\"\" \n",
    "    Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "    \n",
    "    Args:\n",
    "        :lrhsi:\n",
    "            | ndarray with float (max = 1) LowResolution HSI [m,m,L].\n",
    "        :hrci:\n",
    "            | ndarray with float (max = 1) HighResolution HSI [M,N,3].\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | Verbosity level for sub-call to render_image().\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :hrhsi:\n",
    "            | ndarray with HighResolution HSI [M,N,L].\n",
    "        \n",
    "    Procedure:\n",
    "        | Call render_image(hrci, rfl = lrhsi_2, CSF = ...) to estimate a hyperspectral image\n",
    "        | from the high-resolution color image hrci with the reflectance spectra \n",
    "        | in the low-resolution hyper-spectral image as database for the estimation.\n",
    "        | Estimation is done in raw RGB space with the lrhsi converted using the\n",
    "        | camera sensitivity functions in CSF.\n",
    "    \"\"\"\n",
    "    wlr = getwlr(wl)\n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "    lrhsi_2d = np.vstack((wlr,np.reshape(lrhsi,(lrhsi.shape[0]*lrhsi.shape[1],lrhsi.shape[2])))) # create 2D rfl database\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    hrhsi = render_image(hrci, spd = eew,\n",
    "                         refspd = eew, rfl = lrhsi_2d, D = None,\n",
    "                         interp_type = interp_type, k_neighbours = k_neighbours,\n",
    "                         verbosity = verbosity, show = bool(verbosity),\n",
    "                         CSF = CSF, csf_based_rgb_rounding = csf_based_rgb_rounding) # render HR-hsi from HR-ci using LR-HSI rfls as database        \n",
    "    return hrhsi\n",
    "\n",
    "\n",
    "def illuminanceEstimation(input_img):\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for HSI simulation and rendering:\n",
    "    #--------------------------------------------------------------------------\n",
    "    # plt.close('all')\n",
    "    # from luxpy.toolboxes import spdbuild as spb\n",
    "    # S = spb.spd_builder(peakwl = [460,525,590],fwhm=[20,40,20],target=4000, tar_type = 'cct') \n",
    "    # img = _HYPSPCIM_DEFAULT_IMAGE\n",
    "    # img_hyp,img_ren = render_image(img = img, \n",
    "    #                                 cspace = 'Yuv',interp_type='nd',\n",
    "    #                                 spd = S, D=1, \n",
    "    #                                 show_ref_img = True,\n",
    "    #                                 stack_test_ref = 21,\n",
    "    #                                 out='img_hyp,img_ren',\n",
    "    #                                 write_to_file = 'test.jpg') \n",
    "    # raise Exception('')\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for super resolution:\n",
    "    #--------------------------------------------------------------------------\n",
    "    import time\n",
    "    import luxpy as lx\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage import transform\n",
    "    import imageio\n",
    "    from skimage.transform import rescale,resize\n",
    "    \n",
    "    np.random.seed(1)    \n",
    "    \n",
    "    # Set some default parameters:\n",
    "    #----------------------------\n",
    "    load_hsi = False # If True: load hrci and hrhsi from npy-file.\n",
    "    file = input_img\n",
    "\n",
    "    cieobs = '1931_2' # CIE CMF set\n",
    "    linear_rgb = 1 # only used when srgb in hsi_to_rgb == True !!!\n",
    "    verbosity = 0\n",
    "    \n",
    "    # Create HR-rgb image and HR-HSI for code testing: \n",
    "    #---------------------------------------------------\n",
    "    # get an image:\n",
    "    im = imageio.v2.imread(file)/255\n",
    "    \n",
    "    # rescale to n x dimensions of typical hyperspectral camera:\n",
    "    n = 2 # downscale factor\n",
    "    w, h = 1280, 960\n",
    "    cr,cc = np.array(im.shape[:2])//2\n",
    "    crop = lambda im,cr,cc,h,w:im[(cr-h//2):(cr+h//2),(cc-w//2):(cc+w//2),:].copy()\n",
    "    im = crop(im,cr,cc,h*n,w*n)\n",
    "#     print('New image shape:',im.shape)\n",
    "    \n",
    "    # simulate HR hyperspectral image:\n",
    "    hrhsi = render_image(im,show=False)\n",
    "    wlr = getwlr([380,780,1]) #  = wavelength range of default TM30 rfl set\n",
    "    wlr = wlr[20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "    hrhsi = hrhsi[...,20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "#     print('Simulated HR-HSI shape:',hrhsi.shape)\n",
    "    # np.save(file[:-4]+'.npy',{'hrhsi':hrhsi,'im':im, 'wlr':wlr})\n",
    "    \n",
    "    # Illumination spectrum of HSI:    \n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "        \n",
    "    # Create fig and axes for plots:\n",
    "    if verbosity > 0: fig, axs = plt.subplots(1,3)\n",
    "    \n",
    "    # convert HR hsi to HR rgb image:\n",
    "    hrci = hsi_to_rgb(hrhsi, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[0].imshow(hrci)\n",
    "    \n",
    "    # create LR hsi image for testing:\n",
    "    dl = n \n",
    "    lrhsi = hrhsi[::dl,::dl,:]\n",
    "#     print('Simulated LR-HSI shape:',lrhsi.shape)\n",
    "    \n",
    "    # convert LR hsi to LR rgb image:\n",
    "    lrci = hsi_to_rgb(lrhsi, spd = eew, cieobs = cieobs, wl = wlr,linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[1].imshow(lrci)\n",
    "    \n",
    "    # # Perform rgb guided super-resolution:\n",
    "    #hrci = lrci # for testing of estimation code\n",
    "    tic = time.time()\n",
    "    hrhsi_est = get_superresolution_hsi(lrhsi, hrci, CSF = _CSF_NIKON_D700, wl = wlr)\n",
    "#     print('Elapsed time (s): {:1.4f}'.format(time.time() - tic))\n",
    "    hrci_est = hsi_to_rgb(hrhsi_est, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "\n",
    "    if verbosity > 0:  axs[2].imshow(hrci_est)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Plot some rfl to visually evaluate estimation accuracy:\n",
    "    \n",
    "    hsi_rmse = np.linalg.norm(hrhsi-hrhsi_est)/np.array(hrhsi.shape[:2]).prod()**0.5\n",
    "#     print('RMSE(ground-truth,estimate): {:1.4f}'.format(hsi_rmse))\n",
    "    \n",
    "    global illum_out\n",
    "    return illum_out\n",
    "    \n",
    "#     fig, axs = plt.subplots(1,4, figsize=(22,5))\n",
    "    \n",
    "#     axs[0].imshow(transform.rescale(lrci,dl,order=0,multichannel=True),aspect='auto')\n",
    "#     axs[0].set_title('Color image of LR-HSI\\n(HR-to-LR scale factor = {:1.2f})'.format(1/dl))\n",
    "#     axs[0].axis('off')\n",
    "#     axs[1].imshow(hrci_est,aspect='auto')\n",
    "#     axs[1].set_title('Color image of estimated HR-HSI')\n",
    "#     axs[1].axis('off')\n",
    "    \n",
    "#     px_rmse = ((hrhsi_est-hrhsi)**2).sum(axis=-1)**0.5 # rmse per pixel\n",
    "#     axs[2].set_title('RMSE(ground-truth, estimated) HR-HSI\\nRMSE = {:1.4f}, max = {:1.4f}'.format((px_rmse**2).mean()**0.5,px_rmse.max()))\n",
    "#     im = axs[2].imshow(px_rmse, cmap = 'jet',aspect='auto') # rmse per pixel\n",
    "#     cbar = axs[2].figure.colorbar(im, ax=axs[2])\n",
    "#     cbar.ax.set_ylabel('RMSE', rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    \n",
    "#     psorted = np.unravel_index(np.argsort(px_rmse, axis=None), px_rmse.shape) # index of pixels sorted by px_rmse\n",
    "#     np.random.seed(1)\n",
    "#     pxs = np.random.permutation(min(hrhsi.shape[:2]))[:12].reshape(2,3,2)\n",
    "#     iis = np.hstack((pxs[...,0].ravel(),psorted[0][-3:]))\n",
    "#     jjs = np.hstack((pxs[...,1].ravel(),psorted[1][-3:]))\n",
    "#     colors = np.array(['m','b','c','g','y','r','k','lightgrey','grey'])\n",
    "#     for t in range(len(iis)):\n",
    "#         ii,jj = iis[t],jjs[t]\n",
    "#         axs[1].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[2].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[3].plot(wlr,hrhsi[ii,jj,:],color = colors[t], linestyle ='-',label='ground-truth (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#         axs[3].plot(wlr,hrhsi_est[ii,jj,:],color = colors[t], linestyle = '--',label='estimate (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#     axs[3].legend(bbox_to_anchor=(1.05, 1))   \n",
    "#     axs[3].set_xlabel('Wavelengths (nm)')\n",
    "#     axs[3].set_ylabel('Spectral Reflectance')\n",
    "#     plt.subplots_adjust(right=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9a8d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:42.333140Z",
     "start_time": "2023-11-07T16:52:39.647073Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import URetinexNet\n",
    "from URetinex_Net import *\n",
    "\n",
    "# Import Arch_network\n",
    "import sys\n",
    "sys.path.append(r\"URetinex_Net\")\n",
    "\n",
    "# testing of URetinex.Net\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from network.Math_Module import P, Q\n",
    "from network.decom import Decom\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "from utils import *\n",
    "\n",
    "def one2three(x):\n",
    "    return torch.cat([x, x, x], dim=1).to(x)\n",
    "\n",
    "class Inference(nn.Module):\n",
    "    #Class Inference Methods\n",
    "    def __init__(self, opts):\n",
    "        super().__init__()\n",
    "        self.opts = opts\n",
    "        # loading decomposition model \n",
    "        self.model_Decom_low = Decom()\n",
    "        self.model_Decom_low = load_initialize(self.model_Decom_low, self.opts.Decom_model_low_path)\n",
    "        # loading R; old_model_opts; and L model\n",
    "        self.unfolding_opts, self.model_R, self.model_L= load_unfolding(self.opts.unfolding_model_path)\n",
    "        # loading adjustment model\n",
    "        self.adjust_model = load_adjustment(self.opts.adjust_model_path)\n",
    "        self.P = P()\n",
    "        self.Q = Q()\n",
    "\n",
    "        transform = [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform)\n",
    "        print(self.model_Decom_low)\n",
    "        print(self.model_R)\n",
    "        print(self.model_L)\n",
    "        print(self.adjust_model)\n",
    "        #time.sleep(8)\n",
    "\n",
    "    def unfolding(self, input_low_img):\n",
    "        for t in range(self.unfolding_opts.round):      \n",
    "            if t == 0: # initialize R0, L0\n",
    "                P, Q = self.model_Decom_low(input_low_img)\n",
    "            else: # update P and Q\n",
    "                w_p = (self.unfolding_opts.gamma + self.unfolding_opts.Roffset * t)\n",
    "                w_q = (self.unfolding_opts.lamda + self.unfolding_opts.Loffset * t)\n",
    "                P = self.P(I=input_low_img, Q=Q, R=R, gamma=w_p)\n",
    "                Q = self.Q(I=input_low_img, P=P, L=L, lamda=w_q) \n",
    "            R = self.model_R(r=P, l=Q)\n",
    "            L = self.model_L(l=Q)\n",
    "        return R, L\n",
    "    \n",
    "    def lllumination_adjust(self, L, ratio):\n",
    "        ratio = torch.ones(L.shape) * self.opts.ratio\n",
    "        return self.adjust_model(l=L, alpha=ratio)\n",
    "    \n",
    "    def forward(self, input_low_img):\n",
    "        if torch.cuda.is_available():\n",
    "            input_low_img = input_low_img\n",
    "        with torch.no_grad():\n",
    "            start = time.time()  \n",
    "            R, L = self.unfolding(input_low_img)\n",
    "            High_L = self.lllumination_adjust(L, self.opts.ratio)\n",
    "            I_enhance = High_L * R\n",
    "            p_time = (time.time() - start)\n",
    "        return I_enhance, p_time\n",
    "\n",
    "    def run(self, low_img_path):\n",
    "        file_name = os.path.basename(self.opts.img_path)\n",
    "        name = file_name.split('.')[0]\n",
    "        low_img = self.transform(Image.open(low_img_path)).unsqueeze(0)\n",
    "        enhance, p_time = self.forward(input_low_img=low_img)\n",
    "        if not os.path.exists(self.opts.output):\n",
    "            os.makedirs(self.opts.output)\n",
    "        save_path = os.path.join(self.opts.output, file_name.replace(name, \"%s_URetinexNet\"%(name)))\n",
    "        np_save_TensorImg(enhance, save_path)  \n",
    "        print(\"================================= time for %s: %f============================\"%(file_name, p_time))\n",
    "\n",
    "#         add to own function for input of img path\n",
    "def retinexImplement(img, outPath):\n",
    "    parser = argparse.ArgumentParser(description='Configure')\n",
    "    \n",
    "    # specify your data path here!\n",
    "    parser.add_argument('--img_path', type=str, default=img)\n",
    "    parser.add_argument('--output', type=str, default=outPath)\n",
    "    # ratio are recommended to be 3-5, bigger ratio will lead to over-exposure \n",
    "    parser.add_argument('--ratio', type=int, default=2)\n",
    "    # model path\n",
    "    parser.add_argument('--Decom_model_low_path', type=str, default=\"./URetinex_Net/ckpt/init_low.pth\")\n",
    "    parser.add_argument('--unfolding_model_path', type=str, default=\"./URetinex_Net/ckpt/unfolding.pth\")\n",
    "    parser.add_argument('--adjust_model_path', type=str, default=\"./URetinex_Net/ckpt/L_adjust.pth\")\n",
    "    parser.add_argument('--gpu_id', type=int, default=0)\n",
    "    \n",
    "#     opts = parser.parse_args() change parse_args() to parse_known_args\n",
    "    opts, _ = parser.parse_known_args()\n",
    "    for k, v in vars(opts).items():\n",
    "        print(k, v)\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(opts.gpu_id)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = Inference(opts)\n",
    "        print(\"CUDA (GPU) is available\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Loading the model on CPU...\")\n",
    "        model = Inference(opts).to(torch.device('cpu'))\n",
    "    \n",
    "#    \n",
    "    model.run(opts.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab32b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:42.339638Z",
     "start_time": "2023-11-07T16:52:42.334152Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def prepData():\n",
    "    trainingData_prep()\n",
    "    evalData_prep()\n",
    "    testData_prep()\n",
    "    \n",
    "    train_data = \"train_data.csv\"\n",
    "\n",
    "    with open(train_data, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the column headers (optional)\n",
    "        writer.writerow(['Filename', 'LandmarksRaw', 'IlluminanceRaw', 'IlluminanceRet'])\n",
    "\n",
    "        # Combine the data from the three lists into rows and write them to the CSV file\n",
    "        for i in range(len(trainFileNames)):\n",
    "            row = [trainFileNames[i], trainLandmarks[i], trainIllumsRaw[i], trainIllumsRet[i]]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    eval_data = \"eval_data.csv\"\n",
    "\n",
    "    with open(eval_data, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the column headers (optional)\n",
    "        writer.writerow(['Filename', 'LandmarksRaw', 'IlluminanceRaw', 'IlluminanceRet'])\n",
    "\n",
    "        # Combine the data from the three lists into rows and write them to the CSV file\n",
    "        for i in range(len(evalFileNames)):\n",
    "            row = [evalFileNames[i], evalLandmarks[i], evalIllumsRaw[i], evalIllumsRet[i]]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "679d8739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T16:52:44.169500Z",
     "start_time": "2023-11-07T16:52:44.162402Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to setup entire dataset to be used for training, eval, and testing\n",
    "\n",
    "# prepData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e4da41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:00:23.586348Z",
     "start_time": "2023-11-07T16:58:38.478595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_0_0.jpg\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "Illuminance: 0.3028540202647569\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_0_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 004_glasses_mix_0_0.jpg: 3.324975============================\n",
      "Illuminance: 0.4703082178472223\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_15_0.jpg\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Illuminance: 0.30239957283854174\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_15_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 004_glasses_mix_15_0.jpg: 2.995040============================\n",
      "Illuminance: 0.4699447648307292\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_30_0.jpg\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Illuminance: 0.30281614687499997\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_30_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 004_glasses_mix_30_0.jpg: 3.136515============================\n",
      "Illuminance: 0.4702812100043403\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_45_0.jpg\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Illuminance: 0.3020892960677083\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_45_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 004_glasses_mix_45_0.jpg: 3.032499============================\n",
      "Illuminance: 0.4696774687977431\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_60_0.jpg\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Illuminance: 0.3013248533810764\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_60_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 004_glasses_mix_60_0.jpg: 3.056056============================\n",
      "Illuminance: 0.46925062346354157\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_75_0.jpg\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Illuminance: 0.301357504344618\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_75_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 004_glasses_mix_75_0.jpg: 3.064478============================\n",
      "Illuminance: 0.46926379809895835\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_90_0.jpg\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Illuminance: 0.3011281036848958\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_90_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 004_glasses_mix_90_0.jpg: 3.894520============================\n",
      "Illuminance: 0.4691539181944444\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_105_0.jpg\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Illuminance: 0.3012176109548611\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_105_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= time for 004_glasses_mix_105_0.jpg: 3.825720============================\n",
      "Illuminance: 0.46913210870225686\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_120_0.jpg\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Illuminance: 0.30233395059895835\n",
      "img_path data\\Evaluation\\004_glasses_mix\\004_glasses_mix_120_0.jpg\n",
      "output ./data/RetEvaluation/Evaluation Dataset_004_glasses_mix/\n",
      "ratio 2\n",
      "Decom_model_low_path ./URetinex_Net/ckpt/init_low.pth\n",
      "unfolding_model_path ./URetinex_Net/ckpt/unfolding.pth\n",
      "adjust_model_path ./URetinex_Net/ckpt/L_adjust.pth\n",
      "gpu_id 0\n",
      "CUDA (GPU) is not available. Loading the model on CPU...\n",
      " ===========>  loading pretrained Illumination Adjustment Model from: ./URetinex_Net/ckpt/L_adjust.pth \n",
      "Decom(\n",
      "  (decom): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      ")\n",
      "HalfDnCNNSE(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (se_layer): SELayer(\n",
      "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=4, out_features=64, bias=False)\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu6): ReLU(inplace=True)\n",
      "  (conv7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu7): ReLU(inplace=True)\n",
      "  (conv8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Illumination_Alone(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv5): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (leaky_relu_1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (leaky_relu_4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Adjust_naive(\n",
      "  (conv1): Conv2d(2, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "================================= time for 004_glasses_mix_120_0.jpg: 3.447101============================\n",
      "Illuminance: 0.46977477642361115\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Creating..../data/Evaluation/004_glasses_mix/004_glasses_mix_135_0.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evalData_prep()\n",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m, in \u001b[0;36mevalData_prep\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(videos_file)\n\u001b[0;32m     55\u001b[0m evaluation_video_paths\u001b[38;5;241m.\u001b[39mappend(video_path)\n\u001b[1;32m---> 56\u001b[0m frame_capture(video_path)\n",
      "Cell \u001b[1;32mIn[3], line 109\u001b[0m, in \u001b[0;36mframe_capture\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m save_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/Evaluation/\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m     evalFileNames\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_file)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m--> 109\u001b[0m     evalLandmarks\u001b[38;5;241m.\u001b[39mappend(generateLandmarks(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(img_file) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_file)))\n\u001b[0;32m    110\u001b[0m     evalIllumsRaw\u001b[38;5;241m.\u001b[39mappend(illuminanceEstimation(img_file))\n\u001b[0;32m    112\u001b[0m     retSave_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/RetEvaluation/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m parentDir[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mgenerateLandmarks\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      2\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img)\n\u001b[0;32m      3\u001b[0m     detector \u001b[38;5;241m=\u001b[39m MTCNN()\n\u001b[1;32m----> 4\u001b[0m     output \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect_faces(img)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#     print(output[0]['confidence'])\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mtcnn\\mtcnn.py:300\u001b[0m, in \u001b[0;36mMTCNN.detect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# We pipe here each of the stages\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m stages:\n\u001b[1;32m--> 300\u001b[0m     result \u001b[38;5;241m=\u001b[39m stage(img, result[\u001b[38;5;241m0\u001b[39m], result[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    302\u001b[0m [total_boxes, points] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    304\u001b[0m bounding_boxes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mtcnn\\mtcnn.py:342\u001b[0m, in \u001b[0;36mMTCNN.__stage1\u001b[1;34m(self, image, scales, stage_status)\u001b[0m\n\u001b[0;32m    339\u001b[0m img_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(scaled_image, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    340\u001b[0m img_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(img_x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m--> 342\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pnet\u001b[38;5;241m.\u001b[39mpredict(img_y)\n\u001b[0;32m    344\u001b[0m out0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(out[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m    345\u001b[0m out1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(out[\u001b[38;5;241m1\u001b[39m], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2550\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2548\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2549\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2552\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1331\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    706\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 710\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    746\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    747\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 749\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3451\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3450\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3451\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   3452\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[0;32m   3453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3454\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evalData_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e4c5e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:05:50.855763Z",
     "start_time": "2023-11-07T17:05:50.406603Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_109\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_110 (InputLayer)      [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)         1792      ['input_110[0][0]']           \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)         36928     ['block1_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)         0         ['block1_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)        73856     ['block1_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)        147584    ['block2_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)          0         ['block2_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)          295168    ['block2_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)          590080    ['block3_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)          590080    ['block3_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)          0         ['block3_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)          1180160   ['block3_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)          2359808   ['block4_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)          2359808   ['block4_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)          0         ['block4_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)          2359808   ['block4_pool[0][0]']         \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)          2359808   ['block5_conv1[0][0]']        \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)          2359808   ['block5_conv2[0][0]']        \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)            0         ['block5_conv3[0][0]']        \n",
      "                                                                                                  \n",
      " flattened_features (Flatte  (None, 25088)                0         ['block5_pool[0][0]']         \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 7, 7, 512)            0         ['flattened_features[0][0]']  \n",
      "                                                                                                  \n",
      " additional_dense1 (Dense)   (None, 64)                   1605696   ['flattened_features[0][0]']  \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 56, 56, 512)          0         ['reshape_1[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " additional_dense2 (Dense)   (None, 64)                   4160      ['additional_dense1[0][0]']   \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 224, 224, 512)        0         ['up_sampling2d_3[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " landmark_output (Dense)     (None, 10)                   650       ['additional_dense1[0][0]']   \n",
      "                                                                                                  \n",
      " previous_illuminance_outpu  (None, 1)                    65        ['additional_dense2[0][0]']   \n",
      " t (Dense)                                                                                        \n",
      "                                                                                                  \n",
      " image_retinex_output (Dens  (None, 224, 224, 3)          1539      ['up_sampling2d_4[0][0]']     \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16326798 (62.28 MB)\n",
      "Trainable params: 16326798 (62.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "additional_dense_layer1 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense1')(flattened_features)\n",
    "additional_dense_layer2 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense2')(additional_dense_layer1)\n",
    "# additional_dense_layer3 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense3')(flattened_features)\n",
    "\n",
    "landmarks = tf.keras.layers.Dense(10, activation='relu', name='landmark_output')(additional_dense_layer1)\n",
    "illum = tf.keras.layers.Dense(1, activation='relu', name='previous_illuminance_output')(additional_dense_layer2)\n",
    "\n",
    "# Reshape layer to the desired shape\n",
    "reshaped_features = tf.keras.layers.Reshape((7, 7, 512))(flattened_features)\n",
    "\n",
    "# Upsampling layers\n",
    "upsample1 = tf.keras.layers.UpSampling2D(size=(8, 8))(reshaped_features)\n",
    "upsample2 = tf.keras.layers.UpSampling2D(size=(4, 4))(upsample1)\n",
    "upsample3 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample2)\n",
    "\n",
    "retIllum = tf.keras.layers.Dense(3, activation='relu', name='image_retinex_output')(upsample2)\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = [landmarks, illum, retIllum]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'landmark_output': 'mean_squared_error',\n",
    "        'previous_illuminance_output': 'mean_squared_error',\n",
    "        'image_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'landmark_output': ['mse', \"accuracy\"],\n",
    "        'previous_illuminance_output': ['mse', \"accuracy\"],\n",
    "        'image_retinex_output': ['mse', \"accuracy\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d821b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:02:36.372027Z",
     "start_time": "2023-11-07T17:02:35.902838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(multi_task_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d29847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:02:42.093546Z",
     "start_time": "2023-11-07T17:02:42.086265Z"
    }
   },
   "outputs": [],
   "source": [
    "trainIllumsRawArray = np.array(trainIllumsRaw)\n",
    "trainIllumsRetArray = np.array(trainIllumsRet)\n",
    "\n",
    "evalIllumsRawArray = np.array(evalIllumsRaw)\n",
    "evalIllumsRetArray = np.array(evalIllumsRet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d888c6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:02:51.498431Z",
     "start_time": "2023-11-07T17:02:51.494962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train = np.vstack((trainLandmarks, trainIllumsRaw, trainIllumsRet)).T\n",
    "Y_val = np.vstack((evalLandmarks, evalIllumsRaw, evalIllumsRet)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eff25d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:03:31.197338Z",
     "start_time": "2023-11-07T17:03:31.189444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213 232 306 222 239 283 227 342 298 332]\n",
      " [215 230 307 222 238 285 228 339 299 333]\n",
      " [207 242 299 228 236 291 226 352 296 340]\n",
      " [218 240 313 232 245 291 231 352 304 345]\n",
      " [223 246 304 238 242 295 234 350 302 344]\n",
      " [214 237 306 233 241 295 227 352 298 348]\n",
      " [216 241 309 230 245 288 231 351 303 342]\n",
      " [225 235 317 232 249 291 235 346 305 343]]\n",
      "[[279 202 366 200 295 247 280 305 352 304]\n",
      " [276 200 367 199 298 246 278 306 353 304]\n",
      " [277 202 365 200 295 247 280 306 352 304]\n",
      " [277 202 365 200 296 247 280 306 352 305]\n",
      " [276 202 365 200 296 247 280 306 352 305]\n",
      " [276 202 364 200 295 247 281 307 352 305]\n",
      " [278 201 369 200 299 246 280 306 354 304]\n",
      " [275 202 367 199 297 249 279 307 353 305]]\n"
     ]
    }
   ],
   "source": [
    "# Sample 2D NumPy array\n",
    "data = Y_train\n",
    "\n",
    "# Extract numerical values from the dictionaries\n",
    "numerical_values = []\n",
    "\n",
    "for row in data:\n",
    "    row_values = []\n",
    "    for element in row:\n",
    "        if isinstance(element, dict):\n",
    "            # Extract numerical values from the dictionary\n",
    "            dict_values = [val for key, val in element.items() if isinstance(val, tuple)]\n",
    "            for tpl in dict_values:\n",
    "                for value in tpl:\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        row_values.append(value)\n",
    "    numerical_values.append(row_values)\n",
    "\n",
    "numerical_values = np.array(numerical_values)\n",
    "print(numerical_values)\n",
    "\n",
    "data = Y_val\n",
    "\n",
    "# Extract numerical values from the dictionaries\n",
    "valNumerical_values = []\n",
    "\n",
    "for row in data:\n",
    "    row_values = []\n",
    "    for element in row:\n",
    "        if isinstance(element, dict):\n",
    "            # Extract numerical values from the dictionary\n",
    "            dict_values = [val for key, val in element.items() if isinstance(val, tuple)]\n",
    "            for tpl in dict_values:\n",
    "                for value in tpl:\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        row_values.append(value)\n",
    "    valNumerical_values.append(row_values)\n",
    "\n",
    "valNumerical_values = np.array(valNumerical_values)\n",
    "print(valNumerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a40ff52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:04.567565Z",
     "start_time": "2023-11-07T17:04:04.337548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n",
      "Found 8 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'data\\Training', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=100, \n",
    "                                                    class_mode='input')\n",
    "\n",
    "for batch in train_generator:\n",
    "    images, labels = batch\n",
    "    break\n",
    "    \n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'data\\RetTraining', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='input')\n",
    "\n",
    "for batch in train_generator:\n",
    "    retImages, labels = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52fe5f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:06.374144Z",
     "start_time": "2023-11-07T17:04:06.259380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n",
      "Found 8 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(r'data\\Evaluation', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=100, \n",
    "                                                    class_mode='input')\n",
    "\n",
    "for batch in val_generator:\n",
    "    valImages, labels = batch\n",
    "    break\n",
    "    \n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(r'data\\RetEvaluation', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=100,\n",
    "                                                    class_mode='input')\n",
    "\n",
    "for batch in val_generator:\n",
    "    valRetImages, labels = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "badf21bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:11.289492Z",
     "start_time": "2023-11-07T17:04:11.273906Z"
    }
   },
   "outputs": [],
   "source": [
    "imageTensor = tf.convert_to_tensor(images)\n",
    "landmarkTensor = tf.convert_to_tensor(numerical_values)\n",
    "illuminanceTensor = tf.convert_to_tensor(trainIllumsRawArray)\n",
    "illumsRetTensor = tf.convert_to_tensor(trainIllumsRetArray)\n",
    "imageRetTensor = tf.convert_to_tensor(retImages)\n",
    "\n",
    "valImageTensor = tf.convert_to_tensor(valImages)\n",
    "valLandmarkTensor = tf.convert_to_tensor(valNumerical_values)\n",
    "valIlluminanceTensor = tf.convert_to_tensor(trainIllumsRawArray)\n",
    "valIllumsRetTensor = tf.convert_to_tensor(trainIllumsRetArray)\n",
    "valImageRetTensor = tf.convert_to_tensor(valRetImages)\n",
    "\n",
    "validation_data = (valImageTensor, {\n",
    "    'landmark_output': valLandmarkTensor,\n",
    "    'previous_illuminance_output': valIlluminanceTensor,\n",
    "    'image_retinex_output': valImageRetTensor\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00e8ac7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:04:14.527659Z",
     "start_time": "2023-11-07T17:04:14.517861Z"
    }
   },
   "outputs": [],
   "source": [
    "class InputOutputShapeCallback(Callback):\n",
    "    def __init__(self, input_data, task_names):\n",
    "        super().__init__()\n",
    "        self.input_data = input_data\n",
    "        self.task_names = task_names\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Get the model's first layer (input layer) and last layer (output layer)\n",
    "        input_layer = self.model.layers[0]\n",
    "        output_layers = self.model.layers[1:]  # Exclude the input layer\n",
    "\n",
    "        # Print the shapes of the input and output tensors of the model\n",
    "        print(f\"Input Data Shape: {self.input_data.shape}\")\n",
    "        print(f\"Input Layer Shape: {input_layer.input_shape}\")\n",
    "\n",
    "        # Print the shapes of the output tensors for each task\n",
    "        for task_name, output_layer in zip(self.task_names, output_layers):\n",
    "            print(f\"Output Layer Shape for {task_name}: {output_layer.output_shape}\")\n",
    "\n",
    "# List of task names\n",
    "task_names = ['landmark_output', 'previous_illuminance_output', 'image_retinex_output']\n",
    "\n",
    "# Create an instance of the callback with input data and task names\n",
    "shape_callback = InputOutputShapeCallback(input_data=imageTensor, task_names=task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec3d61ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:06:40.994417Z",
     "start_time": "2023-11-07T17:05:54.498842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 77295.5859 - landmark_output_loss: 77295.2969 - previous_illuminance_output_loss: 0.0019 - image_retinex_output_loss: 0.2842 - landmark_output_mse: 77295.2969 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.0019 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 0.2842 - image_retinex_output_accuracy: 0.4943 - val_loss: 74281.7656 - val_landmark_output_loss: 74182.4766 - val_previous_illuminance_output_loss: 97.5440 - val_image_retinex_output_loss: 1.7453 - val_landmark_output_mse: 74182.4766 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 97.5440 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 1.7453 - val_image_retinex_output_accuracy: 0.1539\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 68635.9531 - landmark_output_loss: 68541.3125 - previous_illuminance_output_loss: 92.8007 - image_retinex_output_loss: 1.8429 - landmark_output_mse: 68541.3125 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 92.8007 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 1.8429 - image_retinex_output_accuracy: 0.1450 - val_loss: 246639984.0000 - val_landmark_output_loss: 235426032.0000 - val_previous_illuminance_output_loss: 11209498.0000 - val_image_retinex_output_loss: 4455.3857 - val_landmark_output_mse: 235426032.0000 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 11209498.0000 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 4455.3857 - val_image_retinex_output_accuracy: 0.1306\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 242227120.0000 - landmark_output_loss: 231277600.0000 - previous_illuminance_output_loss: 10945783.0000 - image_retinex_output_loss: 3751.1750 - landmark_output_mse: 231277600.0000 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 10945783.0000 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 3751.1750 - image_retinex_output_accuracy: 0.1754 - val_loss: 80772.0312 - val_landmark_output_loss: 80771.5000 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 0.4425 - val_landmark_output_mse: 80771.5000 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 0.4425 - val_image_retinex_output_accuracy: 0.2451\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 75162.3281 - landmark_output_loss: 75161.7031 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 0.4145 - landmark_output_mse: 75161.7031 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 0.4145 - image_retinex_output_accuracy: 0.3280 - val_loss: 82327.6250 - val_landmark_output_loss: 82327.2031 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 0.3364 - val_landmark_output_mse: 82327.2031 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 0.3364 - val_image_retinex_output_accuracy: 0.6278\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 76850.5938 - landmark_output_loss: 76850.0547 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 0.3280 - landmark_output_mse: 76850.0547 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 0.3280 - image_retinex_output_accuracy: 0.4921 - val_loss: 81520.8750 - val_landmark_output_loss: 81520.4375 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 0.3521 - val_landmark_output_mse: 81520.4375 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 0.3521 - val_image_retinex_output_accuracy: 0.1610\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 76040.8750 - landmark_output_loss: 76040.3438 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 0.3214 - landmark_output_mse: 76040.3438 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 0.3214 - image_retinex_output_accuracy: 0.1243 - val_loss: 79422.1016 - val_landmark_output_loss: 79421.6562 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 0.3557 - val_landmark_output_mse: 79421.6562 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 0.3557 - val_image_retinex_output_accuracy: 0.1277\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 74063.8672 - landmark_output_loss: 74063.3281 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 0.3300 - landmark_output_mse: 74063.3281 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 0.3300 - image_retinex_output_accuracy: 0.1037 - val_loss: 70596.6719 - val_landmark_output_loss: 70596.1484 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 0.4374 - val_landmark_output_mse: 70596.1484 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 0.4374 - val_image_retinex_output_accuracy: 0.1277\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 65932.9219 - landmark_output_loss: 65932.3203 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 0.3887 - landmark_output_mse: 65932.3203 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 0.3887 - image_retinex_output_accuracy: 0.1037 - val_loss: 44979.1211 - val_landmark_output_loss: 44972.8438 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 6.1872 - val_landmark_output_mse: 44972.8438 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 6.1872 - val_image_retinex_output_accuracy: 0.1355\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40765.4336 - landmark_output_loss: 40760.0156 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 5.2053 - landmark_output_mse: 40760.0156 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 5.2053 - image_retinex_output_accuracy: 0.1260 - val_loss: 609479.1875 - val_landmark_output_loss: 609345.0000 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 134.0952 - val_landmark_output_mse: 609345.0000 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 134.0952 - val_image_retinex_output_accuracy: 0.1328\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 523943.5312 - landmark_output_loss: 523824.9375 - previous_illuminance_output_loss: 0.2096 - image_retinex_output_loss: 118.3904 - landmark_output_mse: 523824.9375 - landmark_output_accuracy: 0.0000e+00 - previous_illuminance_output_mse: 0.2096 - previous_illuminance_output_accuracy: 0.0000e+00 - image_retinex_output_mse: 118.3904 - image_retinex_output_accuracy: 0.1889 - val_loss: 41027.2656 - val_landmark_output_loss: 41022.4492 - val_previous_illuminance_output_loss: 0.0881 - val_image_retinex_output_loss: 4.7247 - val_landmark_output_mse: 41022.4492 - val_landmark_output_accuracy: 0.0000e+00 - val_previous_illuminance_output_mse: 0.0881 - val_previous_illuminance_output_accuracy: 0.0000e+00 - val_image_retinex_output_mse: 4.7247 - val_image_retinex_output_accuracy: 0.1277\n"
     ]
    }
   ],
   "source": [
    "history = multi_task_model.fit(x=imageTensor,\n",
    "                              y=[landmarkTensor, illumsRetTensor, imageRetTensor],\n",
    "                              epochs=10, validation_data=validation_data,\n",
    "                              batch_size=13)\n",
    "\n",
    "\n",
    "# history = multi_task_model.fit(x=imageTensor,\n",
    "#                                y={'landmark_output': landmarkTensor, \n",
    "#                                 'previous_illuminance_output': illuminanceTensor, \n",
    "#                                 'illuminance_retinex_output': illumsRetTensor},\n",
    "#                                epochs=10,\n",
    "#                                batch_size=4,\n",
    "#                                callbacks=[shape_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52600a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T17:06:48.506710Z",
     "start_time": "2023-11-07T17:06:48.495032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [77295.5859375,\n",
       "  68635.953125,\n",
       "  242227120.0,\n",
       "  75162.328125,\n",
       "  76850.59375,\n",
       "  76040.875,\n",
       "  74063.8671875,\n",
       "  65932.921875,\n",
       "  40765.43359375,\n",
       "  523943.53125],\n",
       " 'landmark_output_loss': [77295.296875,\n",
       "  68541.3125,\n",
       "  231277600.0,\n",
       "  75161.703125,\n",
       "  76850.0546875,\n",
       "  76040.34375,\n",
       "  74063.328125,\n",
       "  65932.3203125,\n",
       "  40760.015625,\n",
       "  523824.9375],\n",
       " 'previous_illuminance_output_loss': [0.0018656505271792412,\n",
       "  92.80068969726562,\n",
       "  10945783.0,\n",
       "  0.2095586061477661,\n",
       "  0.2095586061477661,\n",
       "  0.20955859124660492,\n",
       "  0.20955859124660492,\n",
       "  0.2095586061477661,\n",
       "  0.2095586061477661,\n",
       "  0.20955859124660492],\n",
       " 'image_retinex_output_loss': [0.28419917821884155,\n",
       "  1.842873454093933,\n",
       "  3751.175048828125,\n",
       "  0.41454723477363586,\n",
       "  0.3280377984046936,\n",
       "  0.3214341700077057,\n",
       "  0.3299652338027954,\n",
       "  0.3886816203594208,\n",
       "  5.2053422927856445,\n",
       "  118.39044189453125],\n",
       " 'landmark_output_mse': [77295.296875,\n",
       "  68541.3125,\n",
       "  231277600.0,\n",
       "  75161.703125,\n",
       "  76850.0546875,\n",
       "  76040.34375,\n",
       "  74063.328125,\n",
       "  65932.3203125,\n",
       "  40760.015625,\n",
       "  523824.9375],\n",
       " 'landmark_output_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'previous_illuminance_output_mse': [0.0018656505271792412,\n",
       "  92.80068969726562,\n",
       "  10945783.0,\n",
       "  0.2095586061477661,\n",
       "  0.2095586061477661,\n",
       "  0.20955859124660492,\n",
       "  0.20955859124660492,\n",
       "  0.2095586061477661,\n",
       "  0.2095586061477661,\n",
       "  0.20955859124660492],\n",
       " 'previous_illuminance_output_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'image_retinex_output_mse': [0.28419917821884155,\n",
       "  1.842873454093933,\n",
       "  3751.175048828125,\n",
       "  0.41454723477363586,\n",
       "  0.3280377984046936,\n",
       "  0.3214341700077057,\n",
       "  0.3299652338027954,\n",
       "  0.3886816203594208,\n",
       "  5.2053422927856445,\n",
       "  118.39044189453125],\n",
       " 'image_retinex_output_accuracy': [0.4942975640296936,\n",
       "  0.1449672132730484,\n",
       "  0.17544244229793549,\n",
       "  0.3280104100704193,\n",
       "  0.49213019013404846,\n",
       "  0.12426259368658066,\n",
       "  0.10365264117717743,\n",
       "  0.10365264117717743,\n",
       "  0.12600645422935486,\n",
       "  0.18889009952545166],\n",
       " 'val_loss': [74281.765625,\n",
       "  246639984.0,\n",
       "  80772.03125,\n",
       "  82327.625,\n",
       "  81520.875,\n",
       "  79422.1015625,\n",
       "  70596.671875,\n",
       "  44979.12109375,\n",
       "  609479.1875,\n",
       "  41027.265625],\n",
       " 'val_landmark_output_loss': [74182.4765625,\n",
       "  235426032.0,\n",
       "  80771.5,\n",
       "  82327.203125,\n",
       "  81520.4375,\n",
       "  79421.65625,\n",
       "  70596.1484375,\n",
       "  44972.84375,\n",
       "  609345.0,\n",
       "  41022.44921875],\n",
       " 'val_previous_illuminance_output_loss': [97.54403686523438,\n",
       "  11209498.0,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896],\n",
       " 'val_image_retinex_output_loss': [1.7452853918075562,\n",
       "  4455.3857421875,\n",
       "  0.44252344965934753,\n",
       "  0.3363800346851349,\n",
       "  0.3521002531051636,\n",
       "  0.35573866963386536,\n",
       "  0.43735525012016296,\n",
       "  6.187186241149902,\n",
       "  134.0951690673828,\n",
       "  4.724693298339844],\n",
       " 'val_landmark_output_mse': [74182.4765625,\n",
       "  235426032.0,\n",
       "  80771.5,\n",
       "  82327.203125,\n",
       "  81520.4375,\n",
       "  79421.65625,\n",
       "  70596.1484375,\n",
       "  44972.84375,\n",
       "  609345.0,\n",
       "  41022.44921875],\n",
       " 'val_landmark_output_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_previous_illuminance_output_mse': [97.54403686523438,\n",
       "  11209498.0,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896,\n",
       "  0.0881303921341896],\n",
       " 'val_previous_illuminance_output_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_image_retinex_output_mse': [1.7452853918075562,\n",
       "  4455.3857421875,\n",
       "  0.44252344965934753,\n",
       "  0.3363800346851349,\n",
       "  0.3521002531051636,\n",
       "  0.35573866963386536,\n",
       "  0.43735525012016296,\n",
       "  6.187186241149902,\n",
       "  134.0951690673828,\n",
       "  4.724693298339844],\n",
       " 'val_image_retinex_output_accuracy': [0.1539132297039032,\n",
       "  0.1305629163980484,\n",
       "  0.24511221051216125,\n",
       "  0.6277727484703064,\n",
       "  0.16095095872879028,\n",
       "  0.12774533033370972,\n",
       "  0.12774533033370972,\n",
       "  0.13550053536891937,\n",
       "  0.13275021314620972,\n",
       "  0.12774533033370972]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af155719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
