{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e555e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T19:35:30.462305Z",
     "start_time": "2023-11-30T19:35:25.429608Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\miniconda3\\envs\\torch\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\michael\\miniconda3\\envs\\torch\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===================== IMPORTS/LIBRARIES =====================\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff3e63",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== TRAINING HISTORY FUNCTIONS =====================\n",
    "def historyToCsv():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Convert the datetime object to a string\n",
    "    filename_friendly_datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # save to csv: \n",
    "    hist_csv_file = 'history' + filename_friendly_datetime_string + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "def csvToHistory(csv_filename):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    hist_df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    history_dict = hist_df.to_dict(orient='list')\n",
    "\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a5ec0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T19:35:52.831466Z",
     "start_time": "2023-11-30T19:35:49.393077Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flattened_features (Flatten)   (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " embedding (Dense)              (None, 512)          12845568    ['flattened_features[0][0]']     \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 16, 16, 2)    0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 2)    6           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 16, 16, 2)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 2)    0           ['reshape[0][0]',                \n",
      "                                                                  'softmax[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2)           0           ['multiply[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " drowsiness_output (Dense)      (None, 1)            3           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,560,265\n",
      "Trainable params: 27,560,265\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ===================== DROWSINESS MODEL =====================\n",
    "\n",
    "# import multi-task model keras file (rename accordingly depending on what multitask model was trained)\n",
    "multi_task_model = tf.keras.models.load_model('multiTaskModel.keras')\n",
    "\n",
    "# retain weights and remove top layer\n",
    "output_layer = multi_task_model.get_layer('embedding').output\n",
    "\n",
    "drowsiness_model = Model(inputs=multi_task_model.input, outputs=output_layer)\n",
    "\n",
    "# drowsiness_model.summary()\n",
    "# tf.keras.utils.plot_model(drowsiness_model)\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# plot_model(drowsiness_model, to_file='drowsinessModel_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "existing_output = drowsiness_model.output\n",
    "\n",
    "reshaped_output = tf.keras.layers.Reshape((16, 16, 2))(existing_output)\n",
    "\n",
    "spatial_attention = tf.keras.layers.Conv2D(2, (1, 1), activation='sigmoid', padding='same')(reshaped_output)\n",
    "spatial_attention = tf.keras.layers.Softmax()(spatial_attention)\n",
    "output_tensor = tf.keras.layers.Multiply()([reshaped_output, spatial_attention])\n",
    "\n",
    "# Add Global Average Pooling layer\n",
    "output_tensor = tf.keras.layers.GlobalAveragePooling2D()(output_tensor)\n",
    "\n",
    "# Add output layer with two classes and softmax activation\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid', name='drowsiness_output')(output_tensor)\n",
    "\n",
    "# Create the new model with the modified top layers\n",
    "drowsiness_model = Model(inputs=drowsiness_model.input, outputs=predictions)\n",
    "\n",
    "drowsiness_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss={\n",
    "        'drowsiness_output': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'drowsiness_output': [tf.keras.metrics.Accuracy(name='accuracy'), \n",
    "                            tf.keras.metrics.Precision(name='precision'),\n",
    "                            tf.keras.metrics.Recall(name='recall'),\n",
    "                            tfa.metrics.F1Score(num_classes=1, threshold=0.5)]\n",
    "    }\n",
    ")\n",
    "\n",
    "drowsiness_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4748c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T06:40:11.300276Z",
     "start_time": "2023-11-28T06:40:11.281296Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== ORIGINAL DATA GEN CLASS =====================\n",
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True,\n",
    "                 random_seed=None):  # Add a new parameter for random seed\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed  # Store the random seed\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "#         self.n_coords = 2  # Assuming landmark coordinates are 2-dimensional\n",
    "        self.n_drowsiness = 1  # Assuming a single illuminance value\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1, random_state=self.random_seed).reset_index(drop=True)  # Use the random seed\n",
    "    \n",
    "    def __get_input(self, path, target_size):\n",
    "    \n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = tf.image.resize(image_arr, (target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr / 255.\n",
    "    \n",
    "    def __get_output(self, label, output_type):\n",
    "        # Assuming output_type is 'coordinates', 'illuminance', or 'adjusted_image_path'\n",
    "#         if output_type == 'coordinates':\n",
    "#             # Assuming label is a string containing a dictionary-like structure\n",
    "#             # Safely evaluate the string as a literal dictionary using ast.literal_eval\n",
    "#             coordinates_dict = ast.literal_eval(label)\n",
    "            \n",
    "#             # Extract x and y coordinates for each landmark\n",
    "#             landmarks = ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']\n",
    "#             coordinates_list = [coordinates_dict[landmark] for landmark in landmarks]\n",
    "            \n",
    "#             # Flatten the list and convert to numpy array\n",
    "#             coordinates_array = np.array([coord for landmark_coords in coordinates_list for coord in landmark_coords])\n",
    "            \n",
    "# #             print(\"Shape of landmarks_array:\", coordinates_array.shape)\n",
    "            \n",
    "#             # If there are exactly 10 values, return the array, otherwise raise an error\n",
    "#             if len(coordinates_array) == 10:\n",
    "#                 return coordinates_array\n",
    "#             else:\n",
    "#                 raise ValueError(\"Expected 10 coordinates, but found {}\".format(len(coordinates_array)))\n",
    "#         elif output_type == 'illuminance':\n",
    "#             # Convert the illuminance value to a float\n",
    "#             return float(label)\n",
    "#         elif output_type == 'adjusted_image_path':\n",
    "#             # Assuming label is the path to the adjusted image\n",
    "#             return self.__get_input(label, self.input_size)\n",
    "        if output_type == 'drowsiness':\n",
    "            # Convert the illuminance value to a float\n",
    "            return float(label)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        \n",
    "#         coords_batch = batches[self.y_col['coordinates']]\n",
    "        illuminance_batch = batches[self.y_col['drowsiness']]\n",
    "#         adjusted_image_path_batch = batches[self.y_col['adjusted_image_path']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
    "\n",
    "#         y0_batch = np.asarray([self.__get_output(y, 'coordinates') for y in coords_batch])\n",
    "        y0_batch = np.asarray([self.__get_output(y, 'drowsiness') for y in illuminance_batch])\n",
    "#         y2_batch = np.asarray([self.__get_output(y, 'adjusted_image_path') for y in adjusted_image_path_batch])\n",
    "\n",
    "        return X_batch, [y0_batch]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "\n",
    "        # Print a few examples of the data\n",
    "#         print(\"Sample X:\", tf.shape(X[0]))  # Print the first example in the batch\n",
    "#         print(\"Sample y[0] (landmarks):\", tf.shape(y[0][0]))  # Print the first example in the landmarks output\n",
    "#         print(\"Sample y[1] (illum):\", tf.shape(y[1][0]))  # Print the first example in the illum output\n",
    "#         print(\"Sample y[2] (adjusted_image_path):\", tf.shape(y[2][0]))  # Print the first example in the adjusted_image_path output\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b8a51a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T06:40:11.343911Z",
     "start_time": "2023-11-28T06:40:11.302314Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== DATA GEN SETUP (DROWSINESS TASK) =====================\n",
    "\n",
    "test_df = pd.read_csv(\"illuminance_results.csv\") # path to test_data csv\n",
    "test_df[\"Filename\"] = \"./data/Training/\" + test_df[\"Filename\"] + \".jpg\"\n",
    "test_df[\"Drowsiness\"] = test_df[\"Drowsiness\"].astype(int)\n",
    "\n",
    "X_col = {'path': 'Filename'}\n",
    "y_col = {'drowsiness': 'Drowsiness'}\n",
    "\n",
    "test_gen = CustomDataGen(test_df, X_col, y_col, batch_size=32, input_size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56856d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T06:40:50.294759Z",
     "start_time": "2023-11-28T06:40:13.424269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_result = drowsiness_model.fit(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efeb2657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T18:27:10.131668Z",
     "start_time": "2023-11-28T18:27:10.103457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.0010000000474974513\n"
     ]
    }
   ],
   "source": [
    "optimizer = drowsiness_model.optimizer\n",
    "learning_rate = optimizer.learning_rate.numpy()\n",
    "print(f\"Learning Rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b7aeef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T03:05:57.783239Z",
     "start_time": "2023-11-30T03:05:57.776255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49836848656103877\n"
     ]
    }
   ],
   "source": [
    "tp = 9048 \n",
    "fp = 5670\n",
    "fn = 9242\n",
    "tn = 5767\n",
    "\n",
    "top = tp+tn+fp+fn\n",
    "bottom = tp+tn\n",
    "\n",
    "accuracy = bottom/top\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
