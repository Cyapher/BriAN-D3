{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e555e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:46:02.268333Z",
     "start_time": "2023-12-04T02:45:51.826597Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\miniconda3\\envs\\torch\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\michael\\miniconda3\\envs\\torch\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===================== IMPORTS/LIBRARIES =====================\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import ast\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eff3e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:03:15.224230Z",
     "start_time": "2023-12-01T13:03:15.207193Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== TRAINING HISTORY FUNCTIONS =====================\n",
    "def historyToCsv():\n",
    "    # convert the history.history dict to a pandas DataFrame:     \n",
    "    hist_df = pd.DataFrame(history.history) \n",
    "    \n",
    "    current_datetime = datetime.now()\n",
    "\n",
    "    # Convert the datetime object to a string\n",
    "    filename_friendly_datetime_string = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    # save to csv: \n",
    "    hist_csv_file = 'history' + filename_friendly_datetime_string + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "\n",
    "def csvToHistory(csv_filename):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    hist_df = pd.read_csv(csv_filename, index_col=0)\n",
    "\n",
    "    # Convert the DataFrame to a dictionary\n",
    "    history_dict = hist_df.to_dict(orient='list')\n",
    "\n",
    "    return history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a5ec0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:46:46.610032Z",
     "start_time": "2023-12-04T02:46:40.515808Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: input_1, Trainable: True\n",
      "Layer 1: block1_conv1, Trainable: True\n",
      "Layer 2: block1_conv2, Trainable: True\n",
      "Layer 3: block1_pool, Trainable: True\n",
      "Layer 4: block2_conv1, Trainable: True\n",
      "Layer 5: block2_conv2, Trainable: True\n",
      "Layer 6: block2_pool, Trainable: True\n",
      "Layer 7: block3_conv1, Trainable: True\n",
      "Layer 8: block3_conv2, Trainable: True\n",
      "Layer 9: block3_conv3, Trainable: True\n",
      "Layer 10: block3_pool, Trainable: True\n",
      "Layer 11: block4_conv1, Trainable: True\n",
      "Layer 12: block4_conv2, Trainable: True\n",
      "Layer 13: block4_conv3, Trainable: True\n",
      "Layer 14: block4_pool, Trainable: True\n",
      "Layer 15: block5_conv1, Trainable: True\n",
      "Layer 16: block5_conv2, Trainable: True\n",
      "Layer 17: block5_conv3, Trainable: True\n",
      "Layer 18: block5_pool, Trainable: True\n",
      "Layer 19: flattened_features, Trainable: True\n",
      "Layer 20: embedding, Trainable: True\n",
      "Layer 21: additional_dense1, Trainable: True\n",
      "Layer 22: additional_dense3, Trainable: True\n",
      "Layer 23: additional_dense2, Trainable: True\n",
      "Layer 24: additional_dense4, Trainable: True\n",
      "Layer 25: landmark_output, Trainable: True\n",
      "Layer 26: previous_illuminance_output, Trainable: True\n"
     ]
    }
   ],
   "source": [
    "# ===================== DROWSINESS MODEL =====================\n",
    "\n",
    "# import multi-task model keras file (rename accordingly depending on what multitask model was trained)\n",
    "multi_task_model = tf.keras.models.load_model('LandmarksIlluminanceModel.keras')\n",
    "\n",
    "# Unfreeze specific layers in the range\n",
    "# for layer in multi_task_model.layers[0:20]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# Display information about the layers and their trainability\n",
    "for i, layer in enumerate(multi_task_model.layers):\n",
    "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")\n",
    "    \n",
    "# retain weights and remove top layer\n",
    "output_layer = multi_task_model.get_layer('embedding').output\n",
    "\n",
    "drowsiness_model = Model(inputs=multi_task_model.input, outputs=output_layer)\n",
    "\n",
    "# drowsiness_model.summary()\n",
    "# tf.keras.utils.plot_model(drowsiness_model)\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# plot_model(drowsiness_model, to_file='drowsinessModel_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "existing_output = drowsiness_model.output\n",
    "\n",
    "reshaped_output = tf.keras.layers.Reshape((16, 16, 2))(existing_output)\n",
    "\n",
    "\n",
    "spatial_attention = tf.keras.layers.Conv2D(2, (1, 1), activation='sigmoid', padding='same')(reshaped_output)\n",
    "\n",
    "dropout_layer1 = tf.keras.layers.Dropout(rate=0.2, name=\"dropout_layer1\")(spatial_attention)\n",
    "\n",
    "spatial_attention = tf.keras.layers.Softmax()(spatial_attention)\n",
    "output_tensor = tf.keras.layers.Multiply()([reshaped_output, spatial_attention])\n",
    "\n",
    "# Add Global Average Pooling layer\n",
    "output_tensor = tf.keras.layers.GlobalAveragePooling2D()(output_tensor)\n",
    "\n",
    "# Add output layer with two classes and softmax activation\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid', name='drowsiness_output')(output_tensor)\n",
    "\n",
    "# Create the new model with the modified top layers\n",
    "drowsiness_model = Model(inputs=drowsiness_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "371806a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:46:52.330603Z",
     "start_time": "2023-12-04T02:46:52.219522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " flattened_features (Flatten)   (None, 25088)        0           ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " embedding (Dense)              (None, 512)          12845568    ['flattened_features[0][0]']     \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 16, 16, 2)    0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 2)    6           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 16, 16, 2)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 16, 16, 2)    0           ['reshape[0][0]',                \n",
      "                                                                  'softmax[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2)           0           ['multiply[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " drowsiness_output (Dense)      (None, 1)            3           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,560,265\n",
      "Trainable params: 27,560,265\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drowsiness_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00001),\n",
    "    loss={\n",
    "        'drowsiness_output': 'binary_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'drowsiness_output': [\n",
    "                             tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                             tf.keras.metrics.Precision(name='precision'),\n",
    "                             tf.keras.metrics.Recall(name='recall'),\n",
    "                             tfa.metrics.F1Score(num_classes=1, threshold=0.5)]\n",
    "    }\n",
    ")\n",
    "\n",
    "drowsiness_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c925e391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T13:03:18.749353Z",
     "start_time": "2023-12-01T13:03:18.739729Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer input_3: Trainable - True\n",
      "Layer block1_conv1: Trainable - True\n",
      "Layer block1_conv2: Trainable - True\n",
      "Layer block1_pool: Trainable - True\n",
      "Layer block2_conv1: Trainable - True\n",
      "Layer block2_conv2: Trainable - True\n",
      "Layer block2_pool: Trainable - True\n",
      "Layer block3_conv1: Trainable - True\n",
      "Layer block3_conv2: Trainable - True\n",
      "Layer block3_conv3: Trainable - True\n",
      "Layer block3_pool: Trainable - True\n",
      "Layer block4_conv1: Trainable - True\n",
      "Layer block4_conv2: Trainable - True\n",
      "Layer block4_conv3: Trainable - True\n",
      "Layer block4_pool: Trainable - True\n",
      "Layer block5_conv1: Trainable - True\n",
      "Layer block5_conv2: Trainable - True\n",
      "Layer block5_conv3: Trainable - True\n",
      "Layer block5_pool: Trainable - True\n",
      "Layer flattened_features: Trainable - True\n",
      "Layer embedding: Trainable - True\n",
      "Layer reshape_2: Trainable - True\n",
      "Layer conv2d_2: Trainable - True\n",
      "Layer softmax_2: Trainable - True\n",
      "Layer multiply_2: Trainable - True\n",
      "Layer global_average_pooling2d_2: Trainable - True\n",
      "Layer drowsiness_output: Trainable - True\n"
     ]
    }
   ],
   "source": [
    "for layer in drowsiness_model.layers:\n",
    "    print(f\"Layer {layer.name}: Trainable - {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4748c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:47:03.408069Z",
     "start_time": "2023-12-04T02:47:03.381141Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ===================== ORIGINAL DATA GEN CLASS =====================\n",
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 shuffle=True,\n",
    "                 random_seed=None):  # Add a new parameter for random seed\n",
    "        \n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.random_seed = random_seed  # Store the random seed\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "#         self.n_coords = 2  # Assuming landmark coordinates are 2-dimensional\n",
    "        self.n_drowsiness = 1  # Assuming a single illuminance value\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1, random_state=self.random_seed).reset_index(drop=True)  # Use the random seed\n",
    "    \n",
    "    def __get_input(self, path, target_size):\n",
    "    \n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "        image_arr = tf.image.resize(image_arr, (target_size[0], target_size[1])).numpy()\n",
    "\n",
    "        return image_arr / 255.\n",
    "    \n",
    "    def __get_output(self, label, output_type):\n",
    "        # Assuming output_type is 'coordinates', 'illuminance', or 'adjusted_image_path'\n",
    "#         if output_type == 'coordinates':\n",
    "#             # Assuming label is a string containing a dictionary-like structure\n",
    "#             # Safely evaluate the string as a literal dictionary using ast.literal_eval\n",
    "#             coordinates_dict = ast.literal_eval(label)\n",
    "            \n",
    "#             # Extract x and y coordinates for each landmark\n",
    "#             landmarks = ['left_eye', 'right_eye', 'nose', 'mouth_left', 'mouth_right']\n",
    "#             coordinates_list = [coordinates_dict[landmark] for landmark in landmarks]\n",
    "            \n",
    "#             # Flatten the list and convert to numpy array\n",
    "#             coordinates_array = np.array([coord for landmark_coords in coordinates_list for coord in landmark_coords])\n",
    "            \n",
    "# #             print(\"Shape of landmarks_array:\", coordinates_array.shape)\n",
    "            \n",
    "#             # If there are exactly 10 values, return the array, otherwise raise an error\n",
    "#             if len(coordinates_array) == 10:\n",
    "#                 return coordinates_array\n",
    "#             else:\n",
    "#                 raise ValueError(\"Expected 10 coordinates, but found {}\".format(len(coordinates_array)))\n",
    "#         elif output_type == 'illuminance':\n",
    "#             # Convert the illuminance value to a float\n",
    "#             return float(label)\n",
    "#         elif output_type == 'adjusted_image_path':\n",
    "#             # Assuming label is the path to the adjusted image\n",
    "#             return self.__get_input(label, self.input_size)\n",
    "        if output_type == 'drowsiness':\n",
    "            # Convert the illuminance value to a float\n",
    "            return int(label)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col['path']]\n",
    "        \n",
    "#         coords_batch = batches[self.y_col['coordinates']]\n",
    "        illuminance_batch = batches[self.y_col['drowsiness']]\n",
    "#         adjusted_image_path_batch = batches[self.y_col['adjusted_image_path']]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.input_size) for x in path_batch])\n",
    "\n",
    "#         y0_batch = np.asarray([self.__get_output(y, 'coordinates') for y in coords_batch])\n",
    "        y0_batch = np.asarray([self.__get_output(y, 'drowsiness') for y in illuminance_batch])\n",
    "#         y2_batch = np.asarray([self.__get_output(y, 'adjusted_image_path') for y in adjusted_image_path_batch])\n",
    "\n",
    "        return X_batch, [y0_batch]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)\n",
    "\n",
    "        # Print a few examples of the data\n",
    "#         print(\"Sample X:\", tf.shape(X[0]))  # Print the first example in the batch\n",
    "#         print(\"Sample y[0] (landmarks):\", tf.shape(y[0][0]))  # Print the first example in the landmarks output\n",
    "#         print(\"Sample y[1] (illum):\", tf.shape(y[1][0]))  # Print the first example in the illum output\n",
    "#         print(\"Sample y[2] (adjusted_image_path):\", tf.shape(y[2][0]))  # Print the first example in the adjusted_image_path output\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b8a51a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:47:04.313893Z",
     "start_time": "2023-12-04T02:47:04.098429Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ===================== DATA GEN SETUP (DROWSINESS TASK) =====================\n",
    "\n",
    "test_df = pd.read_csv(\"./data/illuminance_results.csv\") # path to test_data csv\n",
    "test_df[\"Filename\"] = \"./data/Training/\" + test_df[\"Filename\"]\n",
    "\n",
    "def getDrowsiness(filename):\n",
    "    index = filename.rfind('.')\n",
    "    return filename[index - 1] if index >= 1 else None\n",
    "\n",
    "test_df[\"Drowsiness\"] = test_df[\"Filename\"].apply(getDrowsiness).astype(int)\n",
    "\n",
    "\n",
    "eval_df = pd.read_csv(\"./data/illuminance_results_eval.csv\") # path to test_data csv\n",
    "eval_df[\"Filename\"] = \"./data/Evaluation/Evaluation/\" + eval_df[\"Filename\"]\n",
    "\n",
    "def getDrowsiness(filename):\n",
    "    index = filename.rfind('.')\n",
    "    return filename[index - 1] if index >= 1 else None\n",
    "\n",
    "eval_df[\"Drowsiness\"] = eval_df[\"Filename\"].apply(getDrowsiness).astype(int)\n",
    "\n",
    "\n",
    "test_gen = CustomDataGen(df=test_df, X_col={'path': 'Filename'}, y_col={'drowsiness': 'Drowsiness'}, batch_size=32, input_size=(224, 224, 3), random_seed=438)\n",
    "eval_gen = CustomDataGen(df=eval_df, X_col={'path': 'Filename'}, y_col={'drowsiness': 'Drowsiness'}, batch_size=32, input_size=(224, 224, 3), random_seed=438)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f64e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:47:06.877384Z",
     "start_time": "2023-12-04T02:47:06.862424Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DynamicLearningRateScheduler(Callback):\n",
    "    def __init__(self, monitor_metric='val_loss', patience=3, factor=0.5, min_lr=1e-6):\n",
    "        super(DynamicLearningRateScheduler, self).__init__()\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.patience = patience\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.wait = 0\n",
    "        self.best_metric = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_metric = logs.get(self.monitor_metric)\n",
    "\n",
    "        if current_metric is None:\n",
    "            raise ValueError(f\"Metric {self.monitor_metric} not found in training logs.\")\n",
    "\n",
    "        if current_metric < self.best_metric:\n",
    "            self.best_metric = current_metric\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                new_lr = max(self.model.optimizer.lr * self.factor, self.min_lr)\n",
    "                self.model.optimizer.lr = new_lr\n",
    "                print(f\"\\nLearning rate reduced to {new_lr}.\")\n",
    "                self.wait = 0\n",
    "\n",
    "dynamicLearningCallback = DynamicLearningRateScheduler(monitor_metric='val_loss', patience=3, factor=0.5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56856d95",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-04T02:47:10.438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "940/940 [==============================] - 1196s 1s/step - loss: 0.6855 - accuracy: 0.5789 - precision: 0.5789 - recall: 1.0000 - f1_score: 0.7333 - val_loss: 0.7001 - val_accuracy: 0.5084 - val_precision: 0.5084 - val_recall: 1.0000 - val_f1_score: 0.6741\n",
      "Epoch 2/10\n",
      "940/940 [==============================] - 981s 1s/step - loss: 0.6808 - accuracy: 0.5787 - precision: 0.5787 - recall: 1.0000 - f1_score: 0.7331 - val_loss: 0.7034 - val_accuracy: 0.5084 - val_precision: 0.5084 - val_recall: 1.0000 - val_f1_score: 0.6741\n",
      "Epoch 3/10\n",
      "940/940 [==============================] - 1023s 1s/step - loss: 0.6808 - accuracy: 0.5787 - precision: 0.5787 - recall: 1.0000 - f1_score: 0.7331 - val_loss: 0.7035 - val_accuracy: 0.5084 - val_precision: 0.5084 - val_recall: 1.0000 - val_f1_score: 0.6741\n",
      "Epoch 4/10\n",
      " 98/940 [==>...........................] - ETA: 10:34 - loss: 0.6797 - accuracy: 0.5823 - precision: 0.5823 - recall: 1.0000 - f1_score: 0.7360"
     ]
    }
   ],
   "source": [
    "evaluation_result = drowsiness_model.fit(test_gen, epochs=10, validation_data=eval_gen, callbacks=[dynamicLearningCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1514eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T15:01:53.329052Z",
     "start_time": "2023-12-01T15:01:48.551992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DrowsinessModel_IllumsOnly\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DrowsinessModel_IllumsOnly\\assets\n"
     ]
    }
   ],
   "source": [
    "drowsiness_model.save(\"DrowsinessModel_IllumsOnly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e53f316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T15:57:12.033896Z",
     "start_time": "2023-12-01T15:50:37.432497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29727 images belonging to 2 classes.\n",
      "num_batches: 929\n",
      "929/929 [==============================] - 115s 123ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "main_directory = './Testing/Testing/'\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Create a data generator\n",
    "X_test = data_generator.flow_from_directory(\n",
    "    main_directory,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  # Set to 'binary' since you have two classes\n",
    "    shuffle=False  # Set to True for training, False for prediction\n",
    ")\n",
    "\n",
    "# Obtain the mapping between filenames and labels\n",
    "filename_label_mapping = X_test.class_indices\n",
    "\n",
    "# print(filename_label_mapping)\n",
    "\n",
    "# Iterate over the generator to load all labels\n",
    "all_labels = []\n",
    "num_batches = len(X_test)\n",
    "for i in range(num_batches):\n",
    "    _, labels = X_test[i]\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "print(f'num_batches: { num_batches}')\n",
    "# Convert labels to a NumPy array\n",
    "labels_array = np.array(all_labels)\n",
    "\n",
    "# Convert numerical labels to class labels without periods\n",
    "class_names = list(filename_label_mapping.keys())\n",
    "y_true = [class_names[int(label)] for label in labels_array]\n",
    "y_true = np.array(y_true, dtype=int)\n",
    "\n",
    "y_pred = drowsiness_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int) # prediction\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47fb80a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T15:57:20.172705Z",
     "start_time": "2023-12-01T15:57:19.798895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.23%\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['True Negative', 'True Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79735be0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:10:11.489150Z",
     "start_time": "2023-12-01T16:10:11.458698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6872913241386414,\n",
       "  0.6630070209503174,\n",
       "  0.6078982353210449,\n",
       "  0.5629286766052246,\n",
       "  0.520764172077179,\n",
       "  0.4979870021343231,\n",
       "  0.4851733446121216,\n",
       "  0.4662149250507355,\n",
       "  0.4595789909362793,\n",
       "  0.4534068703651428],\n",
       " 'accuracy': [0.5788564085960388,\n",
       "  0.6013298034667969,\n",
       "  0.6609042286872864,\n",
       "  0.7028923034667969,\n",
       "  0.7442486882209778,\n",
       "  0.7661236524581909,\n",
       "  0.7780252695083618,\n",
       "  0.7894946932792664,\n",
       "  0.7967420220375061,\n",
       "  0.7983044981956482],\n",
       " 'precision': [0.5788564085960388,\n",
       "  0.5976203083992004,\n",
       "  0.6556371450424194,\n",
       "  0.6886435747146606,\n",
       "  0.7236805558204651,\n",
       "  0.7448083758354187,\n",
       "  0.7578917145729065,\n",
       "  0.7669430375099182,\n",
       "  0.775222897529602,\n",
       "  0.7772563099861145],\n",
       " 'recall': [1.0,\n",
       "  0.9522031545639038,\n",
       "  0.8719981908798218,\n",
       "  0.8884102702140808,\n",
       "  0.9027402997016907,\n",
       "  0.9064851403236389,\n",
       "  0.9059269428253174,\n",
       "  0.9140050411224365,\n",
       "  0.9138574600219727,\n",
       "  0.9132058024406433],\n",
       " 'f1_score': [array([0.73326033], dtype=float32),\n",
       "  array([0.7343493], dtype=float32),\n",
       "  array([0.74849594], dtype=float32),\n",
       "  array([0.7758747], dtype=float32),\n",
       "  array([0.80335367], dtype=float32),\n",
       "  array([0.8177319], dtype=float32),\n",
       "  array([0.8253238], dtype=float32),\n",
       "  array([0.834041], dtype=float32),\n",
       "  array([0.8388508], dtype=float32),\n",
       "  array([0.8397645], dtype=float32)],\n",
       " 'val_loss': [0.6969746947288513,\n",
       "  0.7520362734794617,\n",
       "  0.8596950173377991,\n",
       "  0.9429405927658081,\n",
       "  1.030731439590454,\n",
       "  1.070959210395813,\n",
       "  1.091631531715393,\n",
       "  1.1538492441177368,\n",
       "  1.173750877380371,\n",
       "  1.208624243736267],\n",
       " 'val_accuracy': [0.5084302425384521,\n",
       "  0.4659883677959442,\n",
       "  0.47441861033439636,\n",
       "  0.466133713722229,\n",
       "  0.47369185090065,\n",
       "  0.4597383737564087,\n",
       "  0.45915699005126953,\n",
       "  0.4569767415523529,\n",
       "  0.4677325487136841,\n",
       "  0.4700581431388855],\n",
       " 'val_precision': [0.5084302425384521,\n",
       "  0.4673832356929779,\n",
       "  0.4811621904373169,\n",
       "  0.46355685591697693,\n",
       "  0.47205814719200134,\n",
       "  0.42958199977874756,\n",
       "  0.4427911639213562,\n",
       "  0.4210875332355499,\n",
       "  0.4515366554260254,\n",
       "  0.45150721073150635],\n",
       " 'val_recall': [1.0,\n",
       "  0.36049172282218933,\n",
       "  0.4308176040649414,\n",
       "  0.3181818127632141,\n",
       "  0.2970268726348877,\n",
       "  0.19096626341342926,\n",
       "  0.24671240150928497,\n",
       "  0.18153230845928192,\n",
       "  0.21841052174568176,\n",
       "  0.19696970283985138],\n",
       " 'val_f1_score': [array([0.67411834], dtype=float32),\n",
       "  array([0.4070368], dtype=float32),\n",
       "  array([0.45460027], dtype=float32),\n",
       "  array([0.3773521], dtype=float32),\n",
       "  array([0.36462533], dtype=float32),\n",
       "  array([0.26439738], dtype=float32),\n",
       "  array([0.31687167], dtype=float32),\n",
       "  array([0.25369558], dtype=float32),\n",
       "  array([0.29441234], dtype=float32),\n",
       "  array([0.27428347], dtype=float32)]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
