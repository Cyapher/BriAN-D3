{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69663c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:38:31.311939Z",
     "start_time": "2023-11-05T14:38:19.967258Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de120e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:40:07.967782Z",
     "start_time": "2023-11-05T14:40:03.637354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- ---------------\n",
      "absl-py                           2.0.0\n",
      "aiobotocore                       2.4.2\n",
      "aiofiles                          22.1.0\n",
      "aiohttp                           3.8.3\n",
      "aioitertools                      0.7.1\n",
      "aiosignal                         1.2.0\n",
      "aiosqlite                         0.18.0\n",
      "alabaster                         0.7.12\n",
      "anaconda-catalogs                 0.2.0\n",
      "anaconda-client                   1.12.0\n",
      "anaconda-navigator                2.4.2\n",
      "anaconda-project                  0.11.1\n",
      "annotated-types                   0.6.0\n",
      "anyio                             3.5.0\n",
      "appdirs                           1.4.4\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "arrow                             1.2.3\n",
      "astroid                           2.14.2\n",
      "astropy                           5.1\n",
      "asttokens                         2.0.5\n",
      "astunparse                        1.6.3\n",
      "async-timeout                     4.0.2\n",
      "atomicwrites                      1.4.0\n",
      "attrs                             22.1.0\n",
      "Automat                           20.2.0\n",
      "autopep8                          1.6.0\n",
      "Babel                             2.11.0\n",
      "backcall                          0.2.0\n",
      "backports.functools-lru-cache     1.6.4\n",
      "backports.tempfile                1.0\n",
      "backports.weakref                 1.0.post1\n",
      "bcrypt                            3.2.0\n",
      "beautifulsoup4                    4.12.2\n",
      "binaryornot                       0.4.4\n",
      "black                             0.0\n",
      "bleach                            4.1.0\n",
      "blis                              0.7.11\n",
      "bokeh                             3.2.1\n",
      "boltons                           23.0.0\n",
      "boto3                             1.24.28\n",
      "botocore                          1.27.59\n",
      "Bottleneck                        1.3.5\n",
      "brotlipy                          0.7.0\n",
      "cachetools                        5.3.1\n",
      "calamanCy                         0.1.1\n",
      "catalogue                         2.0.10\n",
      "certifi                           2023.7.22\n",
      "cffi                              1.15.1\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                2.0.4\n",
      "click                             8.0.4\n",
      "cloudpathlib                      0.16.0\n",
      "cloudpickle                       2.2.1\n",
      "clyent                            1.2.2\n",
      "colorama                          0.4.6\n",
      "colorcet                          3.0.1\n",
      "comm                              0.1.2\n",
      "conda                             23.7.2\n",
      "conda-build                       3.26.0\n",
      "conda-content-trust               0.2.0\n",
      "conda_index                       0.2.3\n",
      "conda-libmamba-solver             23.5.0\n",
      "conda-pack                        0.6.0\n",
      "conda-package-handling            2.2.0\n",
      "conda_package_streaming           0.9.0\n",
      "conda-repo-cli                    1.0.41\n",
      "conda-token                       0.4.0\n",
      "conda-verify                      3.4.2\n",
      "confection                        0.1.3\n",
      "constantly                        15.1.0\n",
      "contourpy                         1.0.5\n",
      "cookiecutter                      1.7.3\n",
      "cryptography                      41.0.2\n",
      "cssselect                         1.1.0\n",
      "cycler                            0.11.0\n",
      "cymem                             2.0.6\n",
      "cytoolz                           0.12.0\n",
      "daal4py                           2023.1.1\n",
      "dask                              2023.6.0\n",
      "dataclasses                       0.8\n",
      "datasets                          2.12.0\n",
      "datashader                        0.15.1\n",
      "datashape                         0.5.4\n",
      "debugpy                           1.6.7\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "diff-match-patch                  20200713\n",
      "dill                              0.3.6\n",
      "distributed                       2023.6.0\n",
      "docstring-to-markdown             0.11\n",
      "docutils                          0.18.1\n",
      "en-core-web-sm                    3.7.0\n",
      "entrypoints                       0.4\n",
      "et-xmlfile                        1.1.0\n",
      "executing                         0.8.3\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.9.0\n",
      "flake8                            6.0.0\n",
      "Flask                             2.2.2\n",
      "flatbuffers                       23.5.26\n",
      "fonttools                         4.25.0\n",
      "frozenlist                        1.3.3\n",
      "fsspec                            2023.3.0\n",
      "future                            0.18.3\n",
      "gast                              0.4.0\n",
      "gensim                            4.3.0\n",
      "glob2                             0.7\n",
      "google-auth                       2.23.0\n",
      "google-auth-oauthlib              1.0.0\n",
      "google-pasta                      0.2.0\n",
      "graphviz                          0.20.1\n",
      "greenlet                          2.0.1\n",
      "grpcio                            1.58.0\n",
      "h5py                              3.7.0\n",
      "HeapDict                          1.0.1\n",
      "holoviews                         1.17.0\n",
      "huggingface-hub                   0.17.3\n",
      "hvplot                            0.8.4\n",
      "hyperlink                         21.0.0\n",
      "idna                              3.4\n",
      "imagecodecs                       2021.8.26\n",
      "imageio                           2.26.0\n",
      "imagesize                         1.4.1\n",
      "imbalanced-learn                  0.10.1\n",
      "importlib-metadata                6.0.0\n",
      "incremental                       21.3.0\n",
      "inflection                        0.5.1\n",
      "iniconfig                         1.1.1\n",
      "intake                            0.6.8\n",
      "intervaltree                      3.1.0\n",
      "ipykernel                         6.19.2\n",
      "ipython                           8.12.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        8.0.4\n",
      "isort                             5.9.3\n",
      "itemadapter                       0.3.0\n",
      "itemloaders                       1.0.4\n",
      "itsdangerous                      2.0.1\n",
      "jaraco.classes                    3.2.1\n",
      "jedi                              0.18.1\n",
      "jellyfish                         0.9.0\n",
      "Jinja2                            3.1.2\n",
      "jinja2-time                       0.2.0\n",
      "jmespath                          0.10.0\n",
      "joblib                            1.2.0\n",
      "json5                             0.9.6\n",
      "jsonpatch                         1.32\n",
      "jsonpointer                       2.1\n",
      "jsonschema                        4.17.3\n",
      "jupyter                           1.0.0\n",
      "jupyter_client                    7.4.9\n",
      "jupyter-console                   6.6.3\n",
      "jupyter-contrib-core              0.4.2\n",
      "jupyter-contrib-nbextensions      0.7.0\n",
      "jupyter_core                      5.3.0\n",
      "jupyter-events                    0.6.3\n",
      "jupyter-highlight-selected-word   0.2.0\n",
      "jupyter-nbextensions-configurator 0.6.3\n",
      "jupyter-server                    1.23.4\n",
      "jupyter_server_fileid             0.9.0\n",
      "jupyter_server_ydoc               0.8.0\n",
      "jupyter-ydoc                      0.2.4\n",
      "jupyterlab                        3.6.3\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab_server                 2.22.0\n",
      "jupyterlab-widgets                3.0.5\n",
      "keras                             2.13.1\n",
      "keyring                           23.13.1\n",
      "kiwisolver                        1.4.4\n",
      "langcodes                         3.3.0\n",
      "lazy_loader                       0.2\n",
      "lazy-object-proxy                 1.6.0\n",
      "libarchive-c                      2.9\n",
      "libclang                          16.0.6\n",
      "libmambapy                        1.4.1\n",
      "linkify-it-py                     2.0.0\n",
      "llvmlite                          0.40.0\n",
      "lmdb                              1.4.1\n",
      "locket                            1.0.0\n",
      "luxpy                             1.9.8\n",
      "lxml                              4.9.2\n",
      "lz4                               4.3.2\n",
      "Markdown                          3.4.1\n",
      "markdown-it-py                    2.2.0\n",
      "MarkupSafe                        2.1.1\n",
      "matplotlib                        3.7.1\n",
      "matplotlib-inline                 0.1.6\n",
      "mccabe                            0.7.0\n",
      "mdit-py-plugins                   0.3.0\n",
      "mdurl                             0.1.0\n",
      "menuinst                          1.4.19\n",
      "mistune                           0.8.4\n",
      "mkl-fft                           1.3.6\n",
      "mkl-random                        1.2.2\n",
      "mkl-service                       2.4.0\n",
      "more-itertools                    8.12.0\n",
      "mpmath                            1.3.0\n",
      "msgpack                           1.0.3\n",
      "mtcnn                             0.1.1\n",
      "multidict                         6.0.2\n",
      "multipledispatch                  0.6.0\n",
      "multiprocess                      0.70.14\n",
      "munkres                           1.1.4\n",
      "murmurhash                        1.0.10\n",
      "mypy-extensions                   0.4.3\n",
      "navigator-updater                 0.4.0\n",
      "nbclassic                         0.5.5\n",
      "nbclient                          0.5.13\n",
      "nbconvert                         6.5.4\n",
      "nbformat                          5.7.0\n",
      "nest-asyncio                      1.5.6\n",
      "networkx                          3.1\n",
      "nltk                              3.8.1\n",
      "notebook                          6.5.4\n",
      "notebook_shim                     0.2.2\n",
      "numba                             0.57.0\n",
      "numexpr                           2.8.4\n",
      "numpy                             1.24.3\n",
      "numpydoc                          1.5.0\n",
      "oauthlib                          3.2.2\n",
      "opencv-python                     4.8.0.76\n",
      "openpyxl                          3.0.10\n",
      "opt-einsum                        3.3.0\n",
      "packaging                         23.0\n",
      "pandas                            1.5.3\n",
      "pandocfilters                     1.5.0\n",
      "panel                             1.2.1\n",
      "param                             1.13.0\n",
      "paramiko                          2.8.1\n",
      "parsel                            1.6.0\n",
      "parso                             0.8.3\n",
      "partd                             1.2.0\n",
      "pathlib                           1.0.1\n",
      "pathspec                          0.10.3\n",
      "pathy                             0.10.2\n",
      "patsy                             0.5.3\n",
      "pep8                              1.7.1\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "Pillow                            9.4.0\n",
      "pip                               23.2.1\n",
      "pkginfo                           1.9.6\n",
      "platformdirs                      2.5.2\n",
      "plotly                            5.9.0\n",
      "pluggy                            1.0.0\n",
      "ply                               3.11\n",
      "pooch                             1.4.0\n",
      "poyo                              0.5.0\n",
      "preshed                           3.0.6\n",
      "prometheus-client                 0.14.1\n",
      "prompt-toolkit                    3.0.36\n",
      "Protego                           0.1.16\n",
      "protobuf                          4.24.3\n",
      "psutil                            5.9.0\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "py-cpuinfo                        8.0.0\n",
      "pyarrow                           11.0.0\n",
      "pyasn1                            0.4.8\n",
      "pyasn1-modules                    0.2.8\n",
      "pycodestyle                       2.10.0\n",
      "pycosat                           0.6.4\n",
      "pycparser                         2.21\n",
      "pyct                              0.5.0\n",
      "pycurl                            7.45.2\n",
      "pydantic                          1.10.12\n",
      "pydantic_core                     2.10.1\n",
      "PyDispatcher                      2.0.5\n",
      "pydocstyle                        6.3.0\n",
      "pydot                             1.4.2\n",
      "pydotplus                         2.0.2\n",
      "pyerfa                            2.0.0\n",
      "pyflakes                          3.0.1\n",
      "Pygments                          2.15.1\n",
      "PyJWT                             2.4.0\n",
      "pylint                            2.16.2\n",
      "pylint-venv                       2.3.0\n",
      "pyls-spyder                       0.4.0\n",
      "PyNaCl                            1.5.0\n",
      "pyodbc                            4.0.34\n",
      "pyOpenSSL                         23.2.0\n",
      "pyparsing                         3.0.9\n",
      "PyQt5                             5.15.7\n",
      "PyQt5-sip                         12.11.0\n",
      "PyQtWebEngine                     5.15.4\n",
      "pyrsistent                        0.18.0\n",
      "PySocks                           1.7.1\n",
      "pytest                            7.4.0\n",
      "python-dateutil                   2.8.2\n",
      "python-json-logger                2.0.7\n",
      "python-lsp-black                  1.2.1\n",
      "python-lsp-jsonrpc                1.0.0\n",
      "python-lsp-server                 1.7.2\n",
      "python-slugify                    5.0.2\n",
      "python-snappy                     0.6.1\n",
      "pytoolconfig                      1.2.5\n",
      "pytz                              2022.7\n",
      "pyviz-comms                       2.3.0\n",
      "PyWavelets                        1.4.1\n",
      "pywin32                           305.1\n",
      "pywin32-ctypes                    0.2.0\n",
      "pywinpty                          2.0.10\n",
      "PyYAML                            6.0\n",
      "pyzmq                             23.2.0\n",
      "QDarkStyle                        3.0.2\n",
      "qstylizer                         0.2.2\n",
      "QtAwesome                         1.2.2\n",
      "qtconsole                         5.4.2\n",
      "QtPy                              2.2.0\n",
      "queuelib                          1.5.0\n",
      "regex                             2022.7.9\n",
      "requests                          2.31.0\n",
      "requests-file                     1.5.1\n",
      "requests-oauthlib                 1.3.1\n",
      "requests-toolbelt                 1.0.0\n",
      "responses                         0.13.3\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rope                              1.7.0\n",
      "rsa                               4.9\n",
      "Rtree                             1.0.1\n",
      "ruamel.yaml                       0.17.21\n",
      "ruamel-yaml-conda                 0.17.21\n",
      "s3fs                              2023.3.0\n",
      "s3transfer                        0.6.0\n",
      "sacremoses                        0.0.43\n",
      "safetensors                       0.3.3\n",
      "scikit-image                      0.20.0\n",
      "scikit-learn                      1.3.0\n",
      "scikit-learn-intelex              20230426.121932\n",
      "scipy                             1.10.1\n",
      "Scrapy                            2.8.0\n",
      "seaborn                           0.12.2\n",
      "Send2Trash                        1.8.0\n",
      "sentence-transformers             2.2.2\n",
      "sentencepiece                     0.1.99\n",
      "service-identity                  18.1.0\n",
      "setuptools                        68.0.0\n",
      "shellingham                       1.5.3\n",
      "sip                               6.6.2\n",
      "six                               1.16.0\n",
      "smart-open                        5.2.1\n",
      "sniffio                           1.2.0\n",
      "snowballstemmer                   2.2.0\n",
      "sortedcontainers                  2.4.0\n",
      "soupsieve                         2.4\n",
      "spacy                             3.7.2\n",
      "spacy-legacy                      3.0.12\n",
      "spacy-loggers                     1.0.5\n",
      "Sphinx                            5.0.2\n",
      "sphinxcontrib-applehelp           1.0.2\n",
      "sphinxcontrib-devhelp             1.0.2\n",
      "sphinxcontrib-htmlhelp            2.0.0\n",
      "sphinxcontrib-jsmath              1.0.1\n",
      "sphinxcontrib-qthelp              1.0.3\n",
      "sphinxcontrib-serializinghtml     1.1.5\n",
      "spyder                            5.4.3\n",
      "spyder-kernels                    2.4.3\n",
      "SQLAlchemy                        1.4.39\n",
      "srsly                             2.4.6\n",
      "stack-data                        0.2.0\n",
      "statsmodels                       0.14.0\n",
      "sympy                             1.11.1\n",
      "tables                            3.8.0\n",
      "tabulate                          0.8.10\n",
      "TBB                               0.2\n",
      "tblib                             1.7.0\n",
      "tenacity                          8.2.2\n",
      "tensorboard                       2.13.0\n",
      "tensorboard-data-server           0.7.1\n",
      "tensorflow                        2.13.0\n",
      "tensorflow-estimator              2.13.0\n",
      "tensorflow-intel                  2.13.0\n",
      "tensorflow-io-gcs-filesystem      0.31.0\n",
      "termcolor                         2.3.0\n",
      "terminado                         0.17.1\n",
      "text-unidecode                    1.3\n",
      "textdistance                      4.2.1\n",
      "thinc                             8.1.10\n",
      "threadpoolctl                     2.2.0\n",
      "three-merge                       0.1.1\n",
      "tifffile                          2021.7.2\n",
      "tinycss2                          1.2.1\n",
      "tl-calamancy-md                   0.1.0\n",
      "tldextract                        3.2.0\n",
      "tokenizers                        0.13.3\n",
      "toml                              0.10.2\n",
      "tomlkit                           0.11.1\n",
      "toolz                             0.12.0\n",
      "torch                             2.0.1\n",
      "torchvision                       0.15.2\n",
      "tornado                           6.3.2\n",
      "tqdm                              4.65.0\n",
      "traitlets                         5.7.1\n",
      "transformers                      4.32.1\n",
      "Twisted                           22.10.0\n",
      "twisted-iocpsupport               1.0.2\n",
      "typer                             0.4.2\n",
      "typing_extensions                 4.7.1\n",
      "uc-micro-py                       1.0.1\n",
      "ujson                             5.4.0\n",
      "Unidecode                         1.2.0\n",
      "urllib3                           1.26.16\n",
      "w3lib                             1.21.0\n",
      "wasabi                            1.1.2\n",
      "watchdog                          2.1.6\n",
      "wcwidth                           0.2.5\n",
      "weasel                            0.3.3\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  0.58.0\n",
      "Werkzeug                          2.2.3\n",
      "whatthepatch                      1.0.2\n",
      "wheel                             0.38.4\n",
      "widgetsnbextension                4.0.5\n",
      "win-inet-pton                     1.1.0\n",
      "wrapt                             1.14.1\n",
      "xarray                            2023.6.0\n",
      "xlwings                           0.29.1\n",
      "xxhash                            2.0.2\n",
      "xyzservices                       2022.9.0\n",
      "y-py                              0.5.9\n",
      "yapf                              0.31.0\n",
      "yarl                              1.8.1\n",
      "ypy-websocket                     0.8.2\n",
      "zict                              2.2.0\n",
      "zipp                              3.11.0\n",
      "zope.interface                    5.4.0\n",
      "zstandard                         0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf89806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:38:33.754759Z",
     "start_time": "2023-11-05T14:38:33.749991Z"
    }
   },
   "outputs": [],
   "source": [
    "trainLandmarks = []\n",
    "trainLandmarksRet = []\n",
    "trainFileNames = []\n",
    "trainIllumsRaw = []\n",
    "trainIllumsRet = []\n",
    "\n",
    "evalLandmarks = []\n",
    "evalLandmarksRet = []\n",
    "evalFileNames = []\n",
    "evalIllumsRaw = []\n",
    "evalIllumsRet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096c8392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:38:35.819771Z",
     "start_time": "2023-11-05T14:38:35.794829Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def frame_capture(file): # (15 frames)\n",
    "    \n",
    "    cap = cv2.VideoCapture(file)\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "            os.makedirs('data')\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "            \n",
    "    current_frame = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "#         print(file)\n",
    "        if not ret:\n",
    "            current_frame = 0\n",
    "            break \n",
    "\n",
    "        if current_frame % 15 == 0:\n",
    "            \n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "            \n",
    "            parentDir = os.path.dirname(os.path.dirname(file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "            \n",
    "            childDir = os.path.dirname(file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "            \n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "            \n",
    "#             filename of txt document containing labels for current video\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                labelFile = labelFile.replace(\"nightno\", \"night_no\")\n",
    "            else:\n",
    "                scenario = \"\"\n",
    "                if \"sunglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                elif \"night_noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"night_noglasses\"    \n",
    "                elif \"noglasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"noglasses\"\n",
    "                elif \"night_glasses\" in os.path.basename(file)[:-4]:\n",
    "                    scenario = \"sunglasses\"\n",
    "                else:\n",
    "                    scenario = \"glasses\"\n",
    "                \n",
    "                labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + scenario + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                if not os.path.exists(labelFile):                    \n",
    "                    labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + \"wh\" + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "                \n",
    "                labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "                \n",
    "                if not os.path.exists(labelFile): # if labels file is non-existent for the given video\n",
    "                    continue\n",
    "                \n",
    "            with open(labelFile) as f:\n",
    "                labels = f.readline()\n",
    "            try:\n",
    "                \n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                else:\n",
    "                    save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "                    file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "                \n",
    "#                 Creating..../data/Testing/037_sunglasses_mix/037_sunglasses_mix_7110_1.jpg\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "            print('Creating...' + file_name)\n",
    "            cv2.imwrite(file_name, frame)\n",
    "            \n",
    "            img_file = Path(file_name) # for Retinex images, use replace() to get path of same named images in order to get post-retinex illum\n",
    "            \n",
    "            if save_path == \"./data/Training/\":\n",
    "                trainFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                trainLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                trainIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetTraining/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                trainIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                trainLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "                \n",
    "                \n",
    "\n",
    "            elif save_path == \"./data/Evaluation/\":\n",
    "                evalFileNames.append(os.path.basename(img_file)[:-4])\n",
    "                evalLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "                evalIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "                \n",
    "                retSave_path = \"./data/RetEvaluation/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "                retinexImplement(img_file, retSave_path)\n",
    "                \n",
    "#               post-retinex functions\n",
    "                \n",
    "                retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "                evalIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "            \n",
    "                evalLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "            \n",
    "            \n",
    "        current_frame += 1\n",
    "    \n",
    "#     cap.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb313c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T13:31:11.171528Z",
     "start_time": "2023-11-05T13:31:11.164774Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def frame_capture(file): # (per frame)\n",
    "    \n",
    "#     cap = cv2.VideoCapture(file)\n",
    "    \n",
    "#     try:\n",
    "#         if not os.path.exists('data'):\n",
    "#             os.makedirs('data')\n",
    "#     except OSError:\n",
    "#         print('Error: Creating directory of data')\n",
    "            \n",
    "#     current_frame = 0\n",
    "    \n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "# #         print(file)\n",
    "#         if not ret:\n",
    "#             current_frame = 0\n",
    "#             break \n",
    "            \n",
    "#         datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(file)))\n",
    "#         indexDataset = datasetDir.rfind('\\\\')\n",
    "#         datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "#         parentDir = os.path.dirname(os.path.dirname(file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "#         currDir = parentDir\n",
    "\n",
    "#         childDir = os.path.dirname(file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "#         indexParent = parentDir.rfind('\\\\')\n",
    "#         parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "#         indexChild = childDir.rfind('\\\\')\n",
    "#         childDir = childDir[indexChild:]\n",
    "\n",
    "# #             filename of txt document containing labels for current video\n",
    "#         if datasetDir[1:] == \"Training Dataset\":\n",
    "#             labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "#         elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "#             labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "#             labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "#             labelFile = labelFile.replace(\"nightno\", \"night_no\")\n",
    "#         else:\n",
    "#             scenario = \"\"\n",
    "#             if \"sunglasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"sunglasses\"\n",
    "#             elif \"night_noglasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"night_noglasses\"    \n",
    "#             elif \"noglasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"noglasses\"\n",
    "#             elif \"night_glasses\" in os.path.basename(file)[:-4]:\n",
    "#                 scenario = \"sunglasses\"\n",
    "#             else:\n",
    "#                 scenario = \"glasses\"\n",
    "\n",
    "#             labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + scenario + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "\n",
    "#             if not os.path.exists(labelFile):                    \n",
    "#                 labelFile = currDir + \"\\\\\" + childDir[1:] + \"\\\\\" + \"test_label_txt\\\\\" + \"wh\" + \"\\\\\" + os.path.basename(file)[:-4] + \"_drowsiness\" + '.txt'\n",
    "\n",
    "#             labelFile = labelFile.replace(\"mix\", \"mixing\")\n",
    "\n",
    "#         with open(labelFile) as f:\n",
    "#             labels = f.readline()\n",
    "#         try:\n",
    "\n",
    "#             if datasetDir[1:] == \"Training Dataset\":\n",
    "#                 save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "#                 file_name = save_path + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "#             elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "#                 save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "#                 file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "#             else:\n",
    "#                 save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "#                 file_name = save_path + os.path.basename(file)[:-4] + \"/\" + os.path.basename(file)[:-4] + \"_\" + str(current_frame) + \"_\" + labels[current_frame] + '.jpg'\n",
    "\n",
    "# #                 Creating..../data/Testing/037_sunglasses_mix/037_sunglasses_mix_7110_1.jpg\n",
    "\n",
    "#         except IndexError:\n",
    "#             continue\n",
    "\n",
    "#         print('Creating...' + file_name)\n",
    "#         cv2.imwrite(file_name, frame)\n",
    "\n",
    "#         img_file = Path(file_name) # for Retinex images, use replace() to get path of same named images in order to get post-retinex illum\n",
    "\n",
    "#         if save_path == \"./data/Training/\":\n",
    "#             trainFileNames.append(os.path.basename(img_file)[:-4])\n",
    "#             trainLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "#             trainIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "\n",
    "#             retSave_path = \"./data/RetTraining/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "#             retinexImplement(img_file, retSave_path)\n",
    "\n",
    "# #               post-retinex functions\n",
    "\n",
    "#             retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "#             trainIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "\n",
    "#             trainLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "\n",
    "\n",
    "\n",
    "#         elif save_path == \"./data/Evaluation/\":\n",
    "#             evalFileNames.append(os.path.basename(img_file)[:-4])\n",
    "#             evalLandmarks.append(generateLandmarks(os.path.dirname(img_file) + \"\\\\\" + os.path.basename(img_file)))\n",
    "#             evalIllumsRaw.append(illuminanceEstimation(img_file))\n",
    "\n",
    "#             retSave_path = \"./data/RetEvaluation/\" + parentDir[1:] + \"_\" + os.path.basename(file)[:-4] + \"/\"\n",
    "#             retinexImplement(img_file, retSave_path)\n",
    "\n",
    "# #               post-retinex functions\n",
    "\n",
    "#             retSave_path = retSave_path + os.path.basename(img_file)[:-4] + \"_URetinexNet.jpg\"\n",
    "#             evalIllumsRet.append(illuminanceEstimation(retSave_path))\n",
    "\n",
    "#             evalLandmarksRet.append(generateLandmarks(retSave_path))\n",
    "\n",
    "#         current_frame += 1\n",
    "    \n",
    "#     cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf88578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:41.985937Z",
     "start_time": "2023-11-05T14:00:41.974526Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Training Videos Path\n",
    "def trainingData_prep():\n",
    "    training_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Training Dataset\") #AVIs\n",
    "    training_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in training_videos.glob(\"*\"):\n",
    "        for scenario in driver.glob(\"*\"):\n",
    "            for videos_file in scenario.glob(\"*.avi\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "                datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "                indexDataset = datasetDir.rfind('\\\\')\n",
    "                datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "                parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "                currDir = parentDir\n",
    "\n",
    "                childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "                indexParent = parentDir.rfind('\\\\')\n",
    "                parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "                indexChild = childDir.rfind('\\\\')\n",
    "                childDir = childDir[indexChild:]\n",
    "\n",
    "                if datasetDir[1:] == \"Training Dataset\":\n",
    "                    save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "                elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                    save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                    folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "                data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "                inputPath = save_path + folder_name\n",
    "\n",
    "                if not os.path.exists(inputPath):\n",
    "                    os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "                video_path = str(videos_file)\n",
    "                training_video_paths.append(video_path)\n",
    "                frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f5fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:42.001039Z",
     "start_time": "2023-11-05T14:00:41.988428Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation Videos Path\n",
    "def evalData_prep():\n",
    "    evaluation_videos = Path(r\"NTHU Dataset\\Training_Evaluation_Dataset\\Evaluation Dataset\") #AVIs\n",
    "    evaluation_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for driver in evaluation_videos.glob(\"*\"):\n",
    "        for videos_file in driver.glob(\"*.mp4\"):\n",
    "\n",
    "    #         note: videos_file refers to direct path of current video file\n",
    "\n",
    "            datasetDir = os.path.dirname(os.path.dirname(os.path.dirname(videos_file)))\n",
    "            indexDataset = datasetDir.rfind('\\\\')\n",
    "            datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "            parentDir = os.path.dirname(os.path.dirname(videos_file)) # refers to <driver_num> e.g. \"001, 002\"\n",
    "            currDir = parentDir\n",
    "\n",
    "            childDir = os.path.dirname(videos_file) # refers to where the current video file is <scenario> e.g. noglasses, glasses, etc.\n",
    "            indexParent = parentDir.rfind('\\\\')\n",
    "            parentDir = parentDir[indexParent:] # refers to <scenario> only\n",
    "\n",
    "            indexChild = childDir.rfind('\\\\')\n",
    "            childDir = childDir[indexChild:]\n",
    "\n",
    "            if datasetDir[1:] == \"Training Dataset\":\n",
    "                save_path = \"./data/Training/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = parentDir[1:] + \"_\" + os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "            elif parentDir[1:] == \"Evaluation Dataset\":\n",
    "                save_path = \"./data/Evaluation/\" # specify where (in relation to root path to place new folder)\n",
    "                folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "            data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "            inputPath = save_path + folder_name\n",
    "\n",
    "            if not os.path.exists(inputPath):\n",
    "                os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "            video_path = str(videos_file)\n",
    "            evaluation_video_paths.append(video_path)\n",
    "            frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243a300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:42.014002Z",
     "start_time": "2023-11-05T14:00:42.003530Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Testing Videos Path\n",
    "def testData_prep():\n",
    "    testing_videos = Path(r\"NTHU Dataset\\Testing_Dataset\") #MP4s\n",
    "    testing_video_paths = []\n",
    "\n",
    "    # create data folder\n",
    "    try:\n",
    "        if not os.path.exists('data'):\n",
    "                os.makedirs('data')\n",
    "                os.mkdir(os.path.join('./data/', 'Training'))\n",
    "                os.mkdir(os.path.join('./data/', 'Evaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'Testing'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTraining'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetEvaluation'))\n",
    "                os.mkdir(os.path.join('./data/', 'RetTesting'))\n",
    "    except OSError:\n",
    "        print('Error: Creating directory of data')\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for videos_file in testing_videos.glob(\"*.mp4\"):\n",
    "        print(videos_file)\n",
    "\n",
    "#         note: videos_file refers to direct path of current video file\n",
    "\n",
    "        print(os.path.dirname(videos_file))\n",
    "\n",
    "        datasetDir = os.path.dirname(videos_file)\n",
    "        indexDataset = datasetDir.rfind('\\\\')\n",
    "        datasetDir = datasetDir[indexDataset:]\n",
    "\n",
    "        save_path = \"./data/Testing/\" # specify where (in relation to root path to place new folder)\n",
    "        folder_name = os.path.basename(videos_file)[:-4] # specify name of new folder\n",
    "\n",
    "        print(save_path + folder_name)\n",
    "\n",
    "        data_path = os.path.join(save_path, folder_name) # set path and folder name as input for os.path.join()\n",
    "\n",
    "        inputPath = save_path + folder_name\n",
    "\n",
    "        if not os.path.exists(inputPath):\n",
    "            os.mkdir(data_path) # create new folder based on data_path\n",
    "\n",
    "        video_path = str(videos_file)\n",
    "        testing_video_paths.append(video_path)\n",
    "        frame_capture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f26ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:44.014689Z",
     "start_time": "2023-11-05T14:00:44.010208Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generateLandmarks(img):\n",
    "    img = cv2.imread(img)\n",
    "    detector = MTCNN()\n",
    "    output = detector.detect_faces(img)\n",
    "#     print(output[0]['confidence'])\n",
    "    \n",
    "    return output[0]['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936f309",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:43.081593Z",
     "start_time": "2023-11-05T14:00:42.995810Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- ILLUM EST FUNCTIONS\n",
    "\"\"\"\n",
    "Module for hyper spectral image simulation\n",
    "==========================================\n",
    "\n",
    " :_HYPSPCIM_PATH: path to module\n",
    "\n",
    " :_HYPSPCIM_DEFAULT_IMAGE: path + filename to default image\n",
    " \n",
    " :_CSF_NIKON_D700: Nikon D700 camera sensitivity functions\n",
    " \n",
    " :_ROUNDING: rounding of input to xyz_to_rfl() search algorithm for improved speed\n",
    "\n",
    " :xyz_to_rfl(): approximate spectral reflectance of xyz based on k nearest \n",
    "                neighbour interpolation of samples from a standard reflectance \n",
    "                set.\n",
    "\n",
    " :render_image(): Render image under specified light source spd.\n",
    "\n",
    " :get_superresolution_hsi(): Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "\n",
    " :hsi_to_rgb(): Convert HyperSpectral Image to rgb\n",
    " \n",
    " :rfl_to_rgb(): Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "     \n",
    ".. codeauthor:: Kevin A.G. Smet (ksmet1977 at gmail.com)\n",
    "\"\"\"\n",
    "\n",
    "from luxpy import (cat, colortf, _CIEOBS, _CIE_ILLUMINANTS, _CRI_RFL, _CIE_D65,_CIE_E,\n",
    "                   spd_to_xyz, plot_color_data, math, cie_interp, getwlr, xyz_to_srgb)\n",
    "from luxpy.utils import np, plt, sp, _PKG_PATH, _SEP, _EPS \n",
    "\n",
    "import warnings\n",
    "from imageio import imsave\n",
    "\n",
    "illum_out = 0\n",
    "\n",
    "__all__ =['_HYPSPCIM_PATH','_HYPSPCIM_DEFAULT_IMAGE','render_image','xyz_to_rfl',\n",
    "          'get_superresolution_hsi','hsi_to_rgb','rfl_to_rgb','_CSF_NIKON_D700']             \n",
    "\n",
    "_HYPSPCIM_PATH = _PKG_PATH + _SEP + 'hypspcim' + _SEP\n",
    "_HYPSPCIM_DEFAULT_IMAGE = _PKG_PATH + _SEP + 'toolboxes' + _SEP + 'hypspcim' +  _SEP + 'data' + _SEP + 'testimage1.jpg'\n",
    "\n",
    "\n",
    "_ROUNDING = 6 # to speed up xyz_to_rfl search algorithm, increase if kernel dies!!!\n",
    "\n",
    "# Nikon D700 camera sensitivity functions:\n",
    "_CSF_NIKON_D700 = np.vstack((np.arange(400,710,10),\n",
    "                             np.array([[0.005, 0.007, 0.012, 0.015, 0.023, 0.025, 0.030, 0.026, 0.024, 0.019, 0.010, 0.004, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000,  0.000,  0.000,  0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000], \n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.002, 0.003, 0.005, 0.007, 0.012, 0.013, 0.015, 0.016, 0.017, 0.020, 0.013, 0.011, 0.009, 0.005,  0.001,  0.001,  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.002, 0.002, 0.003],\n",
    "                                       [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.003, 0.010, 0.012,  0.013,  0.022,  0.020, 0.020, 0.018, 0.017, 0.016, 0.016, 0.014, 0.014, 0.013]])[::-1]))\n",
    "\n",
    "\n",
    "def xyz_to_rfl(xyz, CSF = None, rfl = None, out = 'rfl_est', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {},\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, verbosity = 0,\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Approximate spectral reflectance of xyz values based on nd-dimensional linear interpolation \n",
    "    or k nearest neighbour interpolation of samples from a standard reflectance set.\n",
    "    \n",
    "    Args:\n",
    "        :xyz: \n",
    "            | ndarray with xyz values of target points.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb (float) values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'rfl_est' or str, optional\n",
    "        :refspd: \n",
    "            | None, optional\n",
    "            | Refer ence spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65.\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set used for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | :rfl_est:\n",
    "            | ndarrays with estimated reflectance spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    \n",
    "    wlr = rfl[0]\n",
    "    \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "        \n",
    "    # Calculate rgb values of standard rfl set under refspd:\n",
    "    if CSF is None:\n",
    "        # Calculate lab coordinates:\n",
    "        xyz_rr, xyz_wr = spd_to_xyz(refspd, relative = True, rfl = rfl, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_rr = colortf(xyz_rr, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)[:,0,:]\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions\n",
    "        rgb_rr = rfl_to_rgb(rfl, spd = refspd, CSF = CSF, wl = None)   \n",
    "        lab_rr = rgb_rr\n",
    "        xyz = xyz\n",
    "        lab_rr = np.round(lab_rr,csf_based_rgb_rounding) # speed up search\n",
    "        \n",
    "        global illum_out\n",
    "        illum_out = np.mean(lab_rr)\n",
    "        print(\"Illuminance: \" + str(np.mean(lab_rr)))\n",
    "        \n",
    "    # Convert xyz to lab-type values under refspd:\n",
    "    if CSF is None:\n",
    "        lab = colortf(xyz, tf = cspace, fwtf = cspace_tf_copy, bwtf = cspace_tf_copy)\n",
    "    else:\n",
    "        lab = xyz # xyz contained rgb values !!!\n",
    "        rgb = xyz\n",
    "        lab = np.round(lab,csf_based_rgb_rounding) # speed up search\n",
    "    \n",
    "    if interp_type == 'nearest':\n",
    "        # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "        # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "        # Construct cKDTree:\n",
    "        tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "        \n",
    "        # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "        d, inds = tree.query(lab, k = k_neighbours )\n",
    "        if k_neighbours  > 1:\n",
    "            d += _EPS\n",
    "            w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "            rfl_est = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "        else:\n",
    "            rfl_est = rfl[inds+1,:].copy()\n",
    "    elif interp_type == 'nd':\n",
    "\n",
    "        rfl_est = math.ndinterp1_scipy(lab_rr, rfl[1:], lab)\n",
    "            \n",
    "        _isnan = np.isnan(rfl_est[:,0]) \n",
    "\n",
    "        if (_isnan.any()): #do nearest neigbour method for those that fail using Delaunay (i.e. ndinterp1_scipy)\n",
    "\n",
    "            # Find rfl (cfr. lab_rr) from rfl set that results in 'near' metameric \n",
    "            # color coordinates for each value in lab_ur (i.e. smallest DE):\n",
    "            # Construct cKDTree:\n",
    "            tree = sp.spatial.cKDTree(lab_rr, copy_data = True)\n",
    "\n",
    "            # Interpolate rfls using k nearest neightbours and inverse distance weigthing:\n",
    "            d, inds = tree.query(lab[_isnan,...], k = k_neighbours )\n",
    "\n",
    "            if k_neighbours  > 1:\n",
    "                d += _EPS\n",
    "                w = (1.0 / d**2)[:,:,None] # inverse distance weigthing\n",
    "                rfl_est_isnan = np.sum(w * rfl[inds+1,:], axis=1) / np.sum(w, axis=1)\n",
    "            else:\n",
    "                rfl_est_isnan = rfl[inds+1,:].copy()\n",
    "            rfl_est[_isnan, :] = rfl_est_isnan\n",
    "\n",
    "    else:\n",
    "        raise Exception('xyz_to_rfl(): unsupported interp_type!')\n",
    "    \n",
    "    rfl_est[rfl_est<0] = 0 #can occur for points outside convexhull of standard rfl set.\n",
    "\n",
    "    rfl_est = np.vstack((rfl[0],rfl_est))\n",
    "        \n",
    "    if ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('lab_est' in out.split(',')) | ('DEi_ab' in out.split(',')) | ('DEa_ab' in out.split(','))) & (CSF is None):\n",
    "        xyz_est, _ = spd_to_xyz(refspd, rfl = rfl_est, relative = True, cieobs = cieobs, out = 2)\n",
    "        cspace_tf_copy = cspace_tf.copy()\n",
    "        cspace_tf_copy['xyzw'] = xyz_wr # put correct white point in param. dict\n",
    "        lab_est = colortf(xyz_est, tf = cspace, fwtf = cspace_tf_copy)[:,0,:]\n",
    "        DEi_ab = np.sqrt(((lab_est[:,1:3]-lab[:,1:3])**2).sum(axis=1))\n",
    "        DEa_ab = DEi_ab.mean()\n",
    "    elif ((verbosity > 0) | ('xyz_est' in out.split(',')) | ('rgb_est' in out.split(',')) | ('DEi_rgb' in out.split(',')) | ('DEa_rgb' in out.split(','))) & (CSF is not None):\n",
    "        rgb_est = rfl_to_rgb(rfl_est[1:], spd = refspd, CSF = CSF, wl = wlr) \n",
    "        xyz_est = rgb_est\n",
    "        DEi_rgb = np.sqrt(((rgb_est - rgb)**2).sum(axis=1))\n",
    "        DEa_rgb = DEi_rgb.mean()\n",
    "\n",
    "        \n",
    "    if verbosity > 0:\n",
    "        if CSF is None:\n",
    "            ax = plot_color_data(lab[...,1], lab[...,2], z = lab[...,0], \\\n",
    "                            show = False, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'ro', label = 'Original')\n",
    "            plot_color_data(lab_est[...,1], lab_est[...,2], z = lab_est[...,0], \\\n",
    "                            show = True, axh = ax, cieobs = cieobs, cspace = cspace, \\\n",
    "                            formatstr = 'bd', label = 'Rendered')\n",
    "        else:\n",
    "            n = 100 #min(rfl.shape[0]-1,rfl_est.shape[0]-1)\n",
    "            s = np.random.permutation(rfl.shape[0]-1)[:min(n,rfl.shape[0]-1)]\n",
    "            st = np.random.permutation(rfl_est.shape[0]-1)[:min(n,rfl_est.shape[0]-1)]\n",
    "            fig = plt.figure()\n",
    "            ax = np.zeros((3,),dtype=np.object)\n",
    "            ax[0] = fig.add_subplot(131)\n",
    "            ax[1] = fig.add_subplot(132)\n",
    "            ax[2] = fig.add_subplot(133,projection='3d')\n",
    "            ax[0].plot(rfl[0],rfl[1:][s].T, linestyle = '-')\n",
    "            ax[0].set_title('Original RFL set (random selection of all)')\n",
    "            ax[0].set_ylim([0,1])\n",
    "            ax[1].plot(rfl_est[0],rfl_est[1:][st].T, linestyle = '--')\n",
    "            ax[0].set_title('Estimated RFL set (random selection of targets)')\n",
    "            ax[1].set_ylim([0,1])\n",
    "            ax[2].plot(rgb[st,0],rgb[st,1],rgb[st,2],'ro', label = 'Original')\n",
    "            ax[2].plot(rgb_est[st,0],rgb_est[st,1],rgb_est[st,2],'bd', label = 'Rendered')\n",
    "            ax[2].legend()\n",
    "    if out == 'rfl_est':\n",
    "        return rfl_est\n",
    "    elif out == 'rfl_est,xyz_est':\n",
    "        return rfl_est, xyz_est\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "\n",
    "def render_image(img = None, spd = None, rfl = None, out = 'img_hyp', \\\n",
    "                 refspd = None, D = None, cieobs = _CIEOBS, \\\n",
    "                 cspace = 'xyz', cspace_tf = {}, CSF = None,\\\n",
    "                 interp_type = 'nd', k_neighbours = 4, show = True,\n",
    "                 verbosity = 0, show_ref_img = True,\\\n",
    "                 stack_test_ref = 12,\\\n",
    "                 write_to_file = None,\\\n",
    "                 csf_based_rgb_rounding = _ROUNDING):\n",
    "    \"\"\"\n",
    "    Render image under specified light source spd.\n",
    "    \n",
    "    Args:\n",
    "        :img: \n",
    "            | None or str or ndarray with float (max = 1) rgb image.\n",
    "            | None load a default image.\n",
    "        :spd: \n",
    "            | ndarray, optional\n",
    "            | Light source spectrum for rendering\n",
    "            | If None: use CIE illuminant F4\n",
    "        :rfl: \n",
    "            | ndarray, optional\n",
    "            | Reflectance set for color coordinate to rfl mapping.\n",
    "        :out: \n",
    "            | 'img_hyp' or str, optional\n",
    "            |  (other option: 'img_ren': rendered image under :spd:)\n",
    "        :refspd:\n",
    "            | None, optional\n",
    "            | Reference spectrum for color coordinate to rfl mapping.\n",
    "            | None defaults to D65 (srgb has a D65 white point)\n",
    "        :D: \n",
    "            | None, optional\n",
    "            | Degree of (von Kries) adaptation from spd to refspd. \n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set for calculation of xyz from spectral data.\n",
    "        :cspace:\n",
    "            | 'xyz',  optional\n",
    "            | Color space for color coordinate to rfl mapping.\n",
    "            | Tip: Use linear space (e.g. 'xyz', 'Yuv',...) for (interp_type == 'nd'),\n",
    "            |      and perceptually uniform space (e.g. 'ipt') for (interp_type == 'nearest')\n",
    "        :cspace_tf:\n",
    "            | {}, optional\n",
    "            | Dict with parameters for xyz_to_cspace and cspace_to_xyz transform.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | RGB camera response functions.\n",
    "            | If None: input :xyz: contains raw rgb values. Override :cspace:\n",
    "            | argument and perform estimation directly in raw rgb space!!!\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :show: \n",
    "            | True, optional\n",
    "            |  Show images.\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "              rendered image pixels.\n",
    "        :show_ref_img:\n",
    "            | True, optional\n",
    "            | True: shows rendered image under reference spd. False: shows\n",
    "            |  original image.\n",
    "        :write_to_file:\n",
    "            | None, optional\n",
    "            | None: do nothing, else: write to filename(+path) in :write_to_file:\n",
    "        :stack_test_ref: \n",
    "            | 12, optional\n",
    "            |   - 12: left (test), right (ref) format for show and imwrite\n",
    "            |   - 21: top (test), bottom (ref)\n",
    "            |   - 1: only show/write test\n",
    "            |   - 2: only show/write ref\n",
    "            |   - 0: show both, write test\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        :returns: \n",
    "            | img_hyp, img_ren, \n",
    "            | ndarrays with float hyperspectral image and rendered images \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get image:\n",
    "    #imread = lambda x: plt.imread(x) #matplotlib.pyplot\n",
    "   \n",
    "    if img is not None:\n",
    "        if isinstance(img,str):\n",
    "            img = plt.imread(img).copy() # use matplotlib.pyplot's imread\n",
    "    else:\n",
    "        img = plt.imread(_HYPSPCIM_DEFAULT_IMAGE).copy()\n",
    "    \n",
    "    if img.dtype == np.uint8: \n",
    "        img = img/255\n",
    "    elif img.dtype == np.uint16:\n",
    "        img = img/(2**16-1)\n",
    "    elif (img.dtype == np.float64) | (img.dtype == np.float32):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    if img.max() > 1.0: raise Exception('img input must be None, string or ndarray of (max = 1) float32 or float64 !')\n",
    "    \n",
    "    \n",
    "    # Convert to 2D format:\n",
    "    rgb = img.reshape(img.shape[0]*img.shape[1],3) # *1.0: make float\n",
    "    rgb[rgb==0] = _EPS # avoid division by zero for pure blacks.\n",
    "\n",
    "    \n",
    "    # Get unique rgb values and positions:\n",
    "    rgb_u, rgb_indices = np.unique(rgb, return_inverse=True, axis = 0)\n",
    "\n",
    "    \n",
    "    # get rfl set:\n",
    "    if rfl is None: # use IESTM30['4880'] set \n",
    "        rfl = _CRI_RFL['ies-tm30']['4880']['5nm']\n",
    "    wlr = rfl[0] # spectral reflectance set determines wavelength range for estimation (xyz_to_rfl())\n",
    "        \n",
    "    # get Ref spd:\n",
    "    if refspd is None:\n",
    "        refspd = _CIE_ILLUMINANTS['D65'].copy()\n",
    "    refspd = cie_interp(refspd, wlr, kind = 'linear') # force spd to same wavelength range as rfl\n",
    "\n",
    "\n",
    "    # Convert rgb_u to xyz and lab-type values under assumed refspd:\n",
    "    if CSF is None:\n",
    "        xyz_wr = spd_to_xyz(refspd, cieobs = cieobs, relative = True)\n",
    "        xyz_ur = colortf(rgb_u*255, tf = 'srgb>xyz')\n",
    "    else:\n",
    "        xyz_ur = rgb_u # for input in xyz_to_rfl (when CSF is not None: this functions assumes input is indeed rgb !!!)\n",
    "    \n",
    "    # Estimate rfl's for xyz_ur:\n",
    "    rfl_est, xyzri = xyz_to_rfl(xyz_ur, rfl = rfl, out = 'rfl_est,xyz_est', \\\n",
    "                 refspd = refspd, D = D, cieobs = cieobs, \\\n",
    "                 cspace = cspace, cspace_tf = cspace_tf, CSF = CSF,\\\n",
    "                 interp_type = interp_type, k_neighbours = k_neighbours, \n",
    "                 verbosity = verbosity,\n",
    "                 csf_based_rgb_rounding = csf_based_rgb_rounding)\n",
    "\n",
    "    # Get default test spd if none supplied:\n",
    "    if spd is None:\n",
    "        spd = _CIE_ILLUMINANTS['F4']\n",
    "        \n",
    "    if CSF is None:\n",
    "        # calculate xyz values under test spd:\n",
    "        xyzti, xyztw = spd_to_xyz(spd, rfl = rfl_est, cieobs = cieobs, out = 2)\n",
    "    \n",
    "        # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            xyzti = cat.apply(xyzti, xyzw1 = xyztw, xyzw2 = xyz_wr, D = D)\n",
    "    \n",
    "        # Convert xyzti under test spd to srgb:\n",
    "        rgbti = colortf(xyzti, tf = 'srgb')/255\n",
    "    else:\n",
    "        # Calculate rgb coordinates from camera sensitivity functions under spd:\n",
    "        rgbti = rfl_to_rgb(rfl_est, spd = spd, CSF = CSF, wl = None) \n",
    "        \n",
    "         # Chromatic adaptation from test spd to refspd:\n",
    "        if D is not None:\n",
    "            white = np.ones_like(spd)\n",
    "            white[0] = spd[0]\n",
    "            rgbwr = rfl_to_rgb(white, spd = refspd, CSF = CSF, wl = None)\n",
    "            rgbwt = rfl_to_rgb(white, spd = spd, CSF = CSF, wl = None)\n",
    "            rgbti = cat.apply_vonkries2(rgbti,rgbwt,rgbwr,xyzw0=np.array([[1.0,1.0,1.0]]), in_type='rgb',out_type= 'rgb',D=1)\n",
    "        \n",
    "    \n",
    "    # Reconstruct original locations for rendered image rgbs:\n",
    "    img_ren = rgbti[rgb_indices]\n",
    "    img_ren.shape = img.shape # reshape back to 3D size of original\n",
    "    img_ren = img_ren\n",
    "    \n",
    "    # For output:\n",
    "    if show_ref_img == True:\n",
    "        rgb_ref = colortf(xyzri, tf = 'srgb')/255 if (CSF is None) else xyzri # if CSF not None: xyzri contains rgbri !!!\n",
    "        img_ref = rgb_ref[rgb_indices]\n",
    "        img_ref.shape = img.shape # reshape back to 3D size of original\n",
    "        img_str = 'Rendered (under ref. spd)'\n",
    "        img = img_ref\n",
    "    else:\n",
    "        img_str = 'Original'\n",
    "        img = img\n",
    "       \n",
    "    \n",
    "    if (stack_test_ref > 0) | show == True:\n",
    "        if stack_test_ref == 21:\n",
    "            img_original_rendered = np.vstack((img_ren,np.ones((4,img.shape[1],3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd)\\n ' + img_str \n",
    "        elif stack_test_ref == 12:\n",
    "            img_original_rendered = np.hstack((img_ren,np.ones((img.shape[0],4,3)),img))\n",
    "            img_original_rendered_str = 'Rendered (under test spd) | ' + img_str \n",
    "        elif stack_test_ref == 1:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str = 'Rendered (under test spd)' \n",
    "        elif stack_test_ref == 2:\n",
    "            img_original_rendered = img\n",
    "            img_original_rendered_str = img_str\n",
    "        elif stack_test_ref == 0:\n",
    "            img_original_rendered = img_ren\n",
    "            img_original_rendered_str =  'Rendered (under test spd)' \n",
    "            \n",
    "    if write_to_file is not None:\n",
    "        # Convert from RGB to BGR formatand write:\n",
    "        #print('Writing rendering results to image file: {}'.format(write_to_file))\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imsave(write_to_file, img_original_rendered)\n",
    "            \n",
    "    if show == True:\n",
    "        # show images using pyplot.show():\n",
    "        plt.figure()\n",
    "        \n",
    "        plt.imshow(img_original_rendered)\n",
    "        plt.title(img_original_rendered_str)\n",
    "        plt.gca().get_xaxis().set_ticklabels([])\n",
    "        plt.gca().get_yaxis().set_ticklabels([])\n",
    "        \n",
    "        if stack_test_ref == 0:\n",
    "            plt.figure()\n",
    "            plt.imshow(img)\n",
    "            plt.title(img_str)\n",
    "            plt.axis('off')\n",
    "      \n",
    "    if 'img_hyp' in out.split(','):\n",
    "        # Create hyper_spectral image:\n",
    "        rfl_image_2D = rfl_est[rgb_indices+1,:] # create array with all rfls required for each pixel\n",
    "        img_hyp = rfl_image_2D.reshape(img.shape[0],img.shape[1],rfl_image_2D.shape[1])\n",
    "\n",
    "\n",
    "    # Setup output:\n",
    "    if out == 'img_hyp':\n",
    "        return img_hyp\n",
    "    elif out == 'img_ren':\n",
    "        return img_ren\n",
    "    else:\n",
    "        return eval(out)\n",
    "\n",
    "\n",
    "def rfl_to_rgb(rfl, spd = None, CSF = None, wl = None, normalize_to_white = True):\n",
    "    \"\"\" \n",
    "    Convert spectral reflectance functions (illuminated by spd) to Camera Sensitivity Functions.\n",
    "    \n",
    "    Args:\n",
    "        :rfl:\n",
    "            | ndarray with spectral reflectance functions (1st row is wavelengths if wl is None).\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True: white-balance output rgb to a perfect white diffuser.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb values for each spectral reflectance functions\n",
    "    \"\"\"\n",
    "    rfl_cp = rfl.copy()\n",
    "    if (wl is None): \n",
    "        wl = rfl_cp[0] \n",
    "        rfl_cp = rfl_cp[1:]\n",
    "    wlr = getwlr(wl)\n",
    "    if spd is not None:\n",
    "        spd = cie_interp(spd,wlr,kind='linear')[1:]\n",
    "    else:\n",
    "        spd = np.ones_like(wlr)\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    CSF = cie_interp(CSF,wlr,kind='linear')\n",
    "    CSF[1:] = CSF[1:]*spd\n",
    "    rgb = rfl_cp @ CSF[1:].T \n",
    "    if normalize_to_white:\n",
    "        white = np.ones_like(spd)\n",
    "        white = white/white.sum()*spd.sum()\n",
    "        rgbw = white @ CSF[1:].T  \n",
    "        rgb = rgb/rgbw.max(axis = 0,keepdims=True) \n",
    "    \n",
    "    return rgb\n",
    "\n",
    "    \n",
    "    \n",
    "def hsi_to_rgb(hsi, spd = None, cieobs = _CIEOBS, srgb = False, \n",
    "               linear_rgb = False, CSF = None, normalize_to_white = True, \n",
    "               wl = [380,780,1]):\n",
    "    \"\"\" \n",
    "    Convert HyperSpectral Image to rgb.\n",
    "    \n",
    "    Args:\n",
    "        :hsi:\n",
    "            | ndarray with hyperspectral image [M,N,L]\n",
    "        :spd:\n",
    "            | None, optional\n",
    "            | ndarray with illumination spectrum\n",
    "        :cieobs:\n",
    "            | _CIEOBS, optional\n",
    "            | CMF set to convert spectral data to xyz tristimulus values.\n",
    "        :srgb:\n",
    "            | False, optional\n",
    "            | If False: Use xyz_to_srgb(spd_to_xyz(...)) to convert to srgb values\n",
    "            | If True: use camera sensitivity functions.\n",
    "        :linear_rgb:\n",
    "            | False, optional\n",
    "            | If False: use gamma = 2.4 in xyz_to_srgb, if False: use gamma = 1 and set :use_linear_part: to False.\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :normalize_to_white:\n",
    "            | True, optional\n",
    "            | If True & CSF is not None: white-balance output rgb to a perfect white diffuser.\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "    \n",
    "    Returns:\n",
    "        :rgb:\n",
    "            | ndarray with rgb image [M,N,3]\n",
    "    \"\"\"\n",
    "    if spd is None:\n",
    "        spd = _CIE_E.copy()\n",
    "    wlr = getwlr(wl)\n",
    "    spd = cie_interp(spd,wl,kind='linear')\n",
    "    \n",
    "    hsi_2d = np.reshape(hsi,(hsi.shape[0]*hsi.shape[1],hsi.shape[2]))\n",
    "    if srgb:\n",
    "        xyz = spd_to_xyz(spd, cieobs = cieobs, relative = True, rfl = np.vstack((wlr,hsi_2d)))\n",
    "        gamma = 1 if linear_rgb else 2.4\n",
    "        rgb = xyz_to_srgb(xyz, gamma = gamma, use_linear_part = not linear_rgb)/255\n",
    "    else:\n",
    "        if CSF is None: CSF = _CSF_NIKON_D700\n",
    "        rgb = rfl_to_rgb(hsi_2d, spd = spd, CSF = CSF, wl = wl, normalize_to_white = normalize_to_white)        \n",
    "    return np.reshape(rgb,(hsi.shape[0],hsi.shape[1],3))\n",
    "\n",
    "       \n",
    "def get_superresolution_hsi(lrhsi, hrci, CSF, wl = [380,780,1], csf_based_rgb_rounding = _ROUNDING,\n",
    "                            interp_type = 'nd', k_neighbours = 4, verbosity = 0):\n",
    "    \"\"\" \n",
    "    Get a HighResolution HyperSpectral Image (super-resolution HSI) based on a LowResolution HSI and a HighResolution Color Image.\n",
    "    \n",
    "    Args:\n",
    "        :lrhsi:\n",
    "            | ndarray with float (max = 1) LowResolution HSI [m,m,L].\n",
    "        :hrci:\n",
    "            | ndarray with float (max = 1) HighResolution HSI [M,N,3].\n",
    "        :CSF:\n",
    "            | None, optional\n",
    "            | ndarray with camera sensitivity functions \n",
    "            | If None: use Nikon D700\n",
    "        :wl:\n",
    "            | [380,780,1], optional\n",
    "            | Wavelength range and spacing or ndarray with wavelengths of HSI image.\n",
    "        :interp_type:\n",
    "            | 'nd', optional\n",
    "            | Options:\n",
    "            | - 'nd': perform n-dimensional linear interpolation using Delaunay triangulation.\n",
    "            | - 'nearest': perform nearest neighbour interpolation. \n",
    "        :k_neighbours:\n",
    "            | 4 or int, optional\n",
    "            | Number of nearest neighbours for reflectance spectrum interpolation.\n",
    "            | Neighbours are found using scipy.spatial.cKDTree\n",
    "        :verbosity:\n",
    "            | 0, optional\n",
    "            | Verbosity level for sub-call to render_image().\n",
    "            | If > 0: make a plot of the color coordinates of original and \n",
    "            | rendered image pixels.\n",
    "        :csf_based_rgb_rounding:\n",
    "            | _ROUNDING, optional\n",
    "            | Int representing the number of decimals to round the RGB values (obtained from not-None CSF input) to before applying the search algorithm.\n",
    "            | Smaller values increase the search speed, but could cause fatal error that causes python kernel to die. If this happens increase the rounding int value.\n",
    "\n",
    "    Returns:\n",
    "        :hrhsi:\n",
    "            | ndarray with HighResolution HSI [M,N,L].\n",
    "        \n",
    "    Procedure:\n",
    "        | Call render_image(hrci, rfl = lrhsi_2, CSF = ...) to estimate a hyperspectral image\n",
    "        | from the high-resolution color image hrci with the reflectance spectra \n",
    "        | in the low-resolution hyper-spectral image as database for the estimation.\n",
    "        | Estimation is done in raw RGB space with the lrhsi converted using the\n",
    "        | camera sensitivity functions in CSF.\n",
    "    \"\"\"\n",
    "    wlr = getwlr(wl)\n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "    lrhsi_2d = np.vstack((wlr,np.reshape(lrhsi,(lrhsi.shape[0]*lrhsi.shape[1],lrhsi.shape[2])))) # create 2D rfl database\n",
    "    if CSF is None: CSF = _CSF_NIKON_D700\n",
    "    hrhsi = render_image(hrci, spd = eew,\n",
    "                         refspd = eew, rfl = lrhsi_2d, D = None,\n",
    "                         interp_type = interp_type, k_neighbours = k_neighbours,\n",
    "                         verbosity = verbosity, show = bool(verbosity),\n",
    "                         CSF = CSF, csf_based_rgb_rounding = csf_based_rgb_rounding) # render HR-hsi from HR-ci using LR-HSI rfls as database        \n",
    "    return hrhsi\n",
    "\n",
    "\n",
    "def illuminanceEstimation(input_img):\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for HSI simulation and rendering:\n",
    "    #--------------------------------------------------------------------------\n",
    "    # plt.close('all')\n",
    "    # from luxpy.toolboxes import spdbuild as spb\n",
    "    # S = spb.spd_builder(peakwl = [460,525,590],fwhm=[20,40,20],target=4000, tar_type = 'cct') \n",
    "    # img = _HYPSPCIM_DEFAULT_IMAGE\n",
    "    # img_hyp,img_ren = render_image(img = img, \n",
    "    #                                 cspace = 'Yuv',interp_type='nd',\n",
    "    #                                 spd = S, D=1, \n",
    "    #                                 show_ref_img = True,\n",
    "    #                                 stack_test_ref = 21,\n",
    "    #                                 out='img_hyp,img_ren',\n",
    "    #                                 write_to_file = 'test.jpg') \n",
    "    # raise Exception('')\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Example / test code for super resolution:\n",
    "    #--------------------------------------------------------------------------\n",
    "    import time\n",
    "    import luxpy as lx\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage import transform\n",
    "    import imageio\n",
    "    from skimage.transform import rescale,resize\n",
    "    \n",
    "    np.random.seed(1)    \n",
    "    \n",
    "    # Set some default parameters:\n",
    "    #----------------------------\n",
    "    load_hsi = False # If True: load hrci and hrhsi from npy-file.\n",
    "    file = input_img\n",
    "\n",
    "    cieobs = '1931_2' # CIE CMF set\n",
    "    linear_rgb = 1 # only used when srgb in hsi_to_rgb == True !!!\n",
    "    verbosity = 0\n",
    "    \n",
    "    # Create HR-rgb image and HR-HSI for code testing: \n",
    "    #---------------------------------------------------\n",
    "    # get an image:\n",
    "    im = imageio.v2.imread(file)/255\n",
    "    \n",
    "    # rescale to n x dimensions of typical hyperspectral camera:\n",
    "    n = 2 # downscale factor\n",
    "    w, h = 1280, 960\n",
    "    cr,cc = np.array(im.shape[:2])//2\n",
    "    crop = lambda im,cr,cc,h,w:im[(cr-h//2):(cr+h//2),(cc-w//2):(cc+w//2),:].copy()\n",
    "    im = crop(im,cr,cc,h*n,w*n)\n",
    "#     print('New image shape:',im.shape)\n",
    "    \n",
    "    # simulate HR hyperspectral image:\n",
    "    hrhsi = render_image(im,show=False)\n",
    "    wlr = getwlr([380,780,1]) #  = wavelength range of default TM30 rfl set\n",
    "    wlr = wlr[20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "    hrhsi = hrhsi[...,20:-80:10] # wavelength range from 400nm-700nm every 10 nm\n",
    "#     print('Simulated HR-HSI shape:',hrhsi.shape)\n",
    "    # np.save(file[:-4]+'.npy',{'hrhsi':hrhsi,'im':im, 'wlr':wlr})\n",
    "    \n",
    "    # Illumination spectrum of HSI:    \n",
    "    eew = np.vstack((wlr,np.ones_like(wlr)))\n",
    "        \n",
    "    # Create fig and axes for plots:\n",
    "    if verbosity > 0: fig, axs = plt.subplots(1,3)\n",
    "    \n",
    "    # convert HR hsi to HR rgb image:\n",
    "    hrci = hsi_to_rgb(hrhsi, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[0].imshow(hrci)\n",
    "    \n",
    "    # create LR hsi image for testing:\n",
    "    dl = n \n",
    "    lrhsi = hrhsi[::dl,::dl,:]\n",
    "#     print('Simulated LR-HSI shape:',lrhsi.shape)\n",
    "    \n",
    "    # convert LR hsi to LR rgb image:\n",
    "    lrci = hsi_to_rgb(lrhsi, spd = eew, cieobs = cieobs, wl = wlr,linear_rgb = linear_rgb)\n",
    "    if verbosity > 0:  axs[1].imshow(lrci)\n",
    "    \n",
    "    # # Perform rgb guided super-resolution:\n",
    "    #hrci = lrci # for testing of estimation code\n",
    "    tic = time.time()\n",
    "    hrhsi_est = get_superresolution_hsi(lrhsi, hrci, CSF = _CSF_NIKON_D700, wl = wlr)\n",
    "#     print('Elapsed time (s): {:1.4f}'.format(time.time() - tic))\n",
    "    hrci_est = hsi_to_rgb(hrhsi_est, spd = eew, cieobs = cieobs, wl = wlr, linear_rgb = linear_rgb)\n",
    "\n",
    "    if verbosity > 0:  axs[2].imshow(hrci_est)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    # Plot some rfl to visually evaluate estimation accuracy:\n",
    "    \n",
    "    hsi_rmse = np.linalg.norm(hrhsi-hrhsi_est)/np.array(hrhsi.shape[:2]).prod()**0.5\n",
    "#     print('RMSE(ground-truth,estimate): {:1.4f}'.format(hsi_rmse))\n",
    "    \n",
    "    global illum_out\n",
    "    return illum_out\n",
    "    \n",
    "#     fig, axs = plt.subplots(1,4, figsize=(22,5))\n",
    "    \n",
    "#     axs[0].imshow(transform.rescale(lrci,dl,order=0,multichannel=True),aspect='auto')\n",
    "#     axs[0].set_title('Color image of LR-HSI\\n(HR-to-LR scale factor = {:1.2f})'.format(1/dl))\n",
    "#     axs[0].axis('off')\n",
    "#     axs[1].imshow(hrci_est,aspect='auto')\n",
    "#     axs[1].set_title('Color image of estimated HR-HSI')\n",
    "#     axs[1].axis('off')\n",
    "    \n",
    "#     px_rmse = ((hrhsi_est-hrhsi)**2).sum(axis=-1)**0.5 # rmse per pixel\n",
    "#     axs[2].set_title('RMSE(ground-truth, estimated) HR-HSI\\nRMSE = {:1.4f}, max = {:1.4f}'.format((px_rmse**2).mean()**0.5,px_rmse.max()))\n",
    "#     im = axs[2].imshow(px_rmse, cmap = 'jet',aspect='auto') # rmse per pixel\n",
    "#     cbar = axs[2].figure.colorbar(im, ax=axs[2])\n",
    "#     cbar.ax.set_ylabel('RMSE', rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    \n",
    "#     psorted = np.unravel_index(np.argsort(px_rmse, axis=None), px_rmse.shape) # index of pixels sorted by px_rmse\n",
    "#     np.random.seed(1)\n",
    "#     pxs = np.random.permutation(min(hrhsi.shape[:2]))[:12].reshape(2,3,2)\n",
    "#     iis = np.hstack((pxs[...,0].ravel(),psorted[0][-3:]))\n",
    "#     jjs = np.hstack((pxs[...,1].ravel(),psorted[1][-3:]))\n",
    "#     colors = np.array(['m','b','c','g','y','r','k','lightgrey','grey'])\n",
    "#     for t in range(len(iis)):\n",
    "#         ii,jj = iis[t],jjs[t]\n",
    "#         axs[1].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[2].plot(jj,ii,color = 'none', marker = 'o', mec = colors[t])\n",
    "#         axs[3].plot(wlr,hrhsi[ii,jj,:],color = colors[t], linestyle ='-',label='ground-truth (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#         axs[3].plot(wlr,hrhsi_est[ii,jj,:],color = colors[t], linestyle = '--',label='estimate (r{:1.0f},c{:1.0f})'.format(ii,jj))\n",
    "#     axs[3].legend(bbox_to_anchor=(1.05, 1))   \n",
    "#     axs[3].set_xlabel('Wavelengths (nm)')\n",
    "#     axs[3].set_ylabel('Spectral Reflectance')\n",
    "#     plt.subplots_adjust(right=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a8d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:47.912066Z",
     "start_time": "2023-11-05T14:00:44.674312Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import URetinexNet\n",
    "from URetinex_Net import *\n",
    "\n",
    "# Import Arch_network\n",
    "import sys\n",
    "sys.path.append(r\"URetinex_Net\")\n",
    "\n",
    "# testing of URetinex.Net\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from network.Math_Module import P, Q\n",
    "from network.decom import Decom\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "from utils import *\n",
    "\n",
    "def one2three(x):\n",
    "    return torch.cat([x, x, x], dim=1).to(x)\n",
    "\n",
    "class Inference(nn.Module):\n",
    "    #Class Inference Methods\n",
    "    def __init__(self, opts):\n",
    "        super().__init__()\n",
    "        self.opts = opts\n",
    "        # loading decomposition model \n",
    "        self.model_Decom_low = Decom()\n",
    "        self.model_Decom_low = load_initialize(self.model_Decom_low, self.opts.Decom_model_low_path)\n",
    "        # loading R; old_model_opts; and L model\n",
    "        self.unfolding_opts, self.model_R, self.model_L= load_unfolding(self.opts.unfolding_model_path)\n",
    "        # loading adjustment model\n",
    "        self.adjust_model = load_adjustment(self.opts.adjust_model_path)\n",
    "        self.P = P()\n",
    "        self.Q = Q()\n",
    "\n",
    "        transform = [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "        self.transform = transforms.Compose(transform)\n",
    "        print(self.model_Decom_low)\n",
    "        print(self.model_R)\n",
    "        print(self.model_L)\n",
    "        print(self.adjust_model)\n",
    "        #time.sleep(8)\n",
    "\n",
    "    def unfolding(self, input_low_img):\n",
    "        for t in range(self.unfolding_opts.round):      \n",
    "            if t == 0: # initialize R0, L0\n",
    "                P, Q = self.model_Decom_low(input_low_img)\n",
    "            else: # update P and Q\n",
    "                w_p = (self.unfolding_opts.gamma + self.unfolding_opts.Roffset * t)\n",
    "                w_q = (self.unfolding_opts.lamda + self.unfolding_opts.Loffset * t)\n",
    "                P = self.P(I=input_low_img, Q=Q, R=R, gamma=w_p)\n",
    "                Q = self.Q(I=input_low_img, P=P, L=L, lamda=w_q) \n",
    "            R = self.model_R(r=P, l=Q)\n",
    "            L = self.model_L(l=Q)\n",
    "        return R, L\n",
    "    \n",
    "    def lllumination_adjust(self, L, ratio):\n",
    "        ratio = torch.ones(L.shape) * self.opts.ratio\n",
    "        return self.adjust_model(l=L, alpha=ratio)\n",
    "    \n",
    "    def forward(self, input_low_img):\n",
    "        if torch.cuda.is_available():\n",
    "            input_low_img = input_low_img\n",
    "        with torch.no_grad():\n",
    "            start = time.time()  \n",
    "            R, L = self.unfolding(input_low_img)\n",
    "            High_L = self.lllumination_adjust(L, self.opts.ratio)\n",
    "            I_enhance = High_L * R\n",
    "            p_time = (time.time() - start)\n",
    "        return I_enhance, p_time\n",
    "\n",
    "    def run(self, low_img_path):\n",
    "        file_name = os.path.basename(self.opts.img_path)\n",
    "        name = file_name.split('.')[0]\n",
    "        low_img = self.transform(Image.open(low_img_path)).unsqueeze(0)\n",
    "        enhance, p_time = self.forward(input_low_img=low_img)\n",
    "        if not os.path.exists(self.opts.output):\n",
    "            os.makedirs(self.opts.output)\n",
    "        save_path = os.path.join(self.opts.output, file_name.replace(name, \"%s_URetinexNet\"%(name)))\n",
    "        np_save_TensorImg(enhance, save_path)  \n",
    "        print(\"================================= time for %s: %f============================\"%(file_name, p_time))\n",
    "\n",
    "#         add to own function for input of img path\n",
    "def retinexImplement(img, outPath):\n",
    "    parser = argparse.ArgumentParser(description='Configure')\n",
    "    \n",
    "    # specify your data path here!\n",
    "    parser.add_argument('--img_path', type=str, default=img)\n",
    "    parser.add_argument('--output', type=str, default=outPath)\n",
    "    # ratio are recommended to be 3-5, bigger ratio will lead to over-exposure \n",
    "    parser.add_argument('--ratio', type=int, default=2)\n",
    "    # model path\n",
    "    parser.add_argument('--Decom_model_low_path', type=str, default=\"./URetinex_Net/ckpt/init_low.pth\")\n",
    "    parser.add_argument('--unfolding_model_path', type=str, default=\"./URetinex_Net/ckpt/unfolding.pth\")\n",
    "    parser.add_argument('--adjust_model_path', type=str, default=\"./URetinex_Net/ckpt/L_adjust.pth\")\n",
    "    parser.add_argument('--gpu_id', type=int, default=0)\n",
    "    \n",
    "#     opts = parser.parse_args() change parse_args() to parse_known_args\n",
    "    opts, _ = parser.parse_known_args()\n",
    "    for k, v in vars(opts).items():\n",
    "        print(k, v)\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(opts.gpu_id)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = Inference(opts)\n",
    "        print(\"CUDA (GPU) is available\")\n",
    "    else:\n",
    "        print(\"CUDA (GPU) is not available. Loading the model on CPU...\")\n",
    "        model = Inference(opts).to(torch.device('cpu'))\n",
    "    \n",
    "#    \n",
    "    model.run(opts.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab32b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:47.925122Z",
     "start_time": "2023-11-05T14:00:47.915082Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def prepData():\n",
    "    trainingData_prep()\n",
    "    evalData_prep()\n",
    "    testData_prep()\n",
    "    \n",
    "    train_data = \"train_data.csv\"\n",
    "\n",
    "    with open(train_data, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the column headers (optional)\n",
    "        writer.writerow(['Filename', 'LandmarksRaw', 'IlluminanceRaw', 'IlluminanceRet'])\n",
    "\n",
    "        # Combine the data from the three lists into rows and write them to the CSV file\n",
    "        for i in range(len(trainFileNames)):\n",
    "            row = [trainFileNames[i], trainLandmarks[i], trainIllumsRaw[i], trainIllumsRet[i]]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    eval_data = \"eval_data.csv\"\n",
    "\n",
    "    with open(eval_data, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the column headers (optional)\n",
    "        writer.writerow(['Filename', 'LandmarksRaw', 'IlluminanceRaw', 'IlluminanceRet'])\n",
    "\n",
    "        # Combine the data from the three lists into rows and write them to the CSV file\n",
    "        for i in range(len(evalFileNames)):\n",
    "            row = [evalFileNames[i], evalLandmarks[i], evalIllumsRaw[i], evalIllumsRet[i]]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d8739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:00:52.093108Z",
     "start_time": "2023-11-05T14:00:52.090237Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to setup entire dataset to be used for training, eval, and testing\n",
    "\n",
    "# prepData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4da41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:01:34.074067Z",
     "start_time": "2023-11-05T14:00:53.290222Z"
    }
   },
   "outputs": [],
   "source": [
    "testData_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c5e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:08:34.631969Z",
     "start_time": "2023-11-05T14:08:33.754708Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "flattened_features = tf.keras.layers.Flatten(name='flattened_features')(base_model.output)\n",
    "\n",
    "additional_dense_layer1 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense1')(flattened_features)\n",
    "additional_dense_layer2 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense2')(additional_dense_layer1)\n",
    "# additional_dense_layer3 = tf.keras.layers.Dense(64, activation='relu', name='additional_dense3')(flattened_features)\n",
    "\n",
    "landmarks = tf.keras.layers.Dense(10, activation='relu', name='landmark_output')(additional_dense_layer1)\n",
    "illum = tf.keras.layers.Dense(1, activation='relu', name='previous_illuminance_output')(additional_dense_layer2)\n",
    "\n",
    "# Reshape layer to the desired shape\n",
    "reshaped_features = tf.keras.layers.Reshape((7, 7, 512))(flattened_features)\n",
    "\n",
    "# Upsampling layers\n",
    "upsample1 = tf.keras.layers.UpSampling2D(size=(8, 8))(reshaped_features)\n",
    "upsample2 = tf.keras.layers.UpSampling2D(size=(4, 4))(upsample1)\n",
    "upsample3 = tf.keras.layers.UpSampling2D(size=(2, 2))(upsample2)\n",
    "\n",
    "retIllum = tf.keras.layers.Dense(3, activation='relu', name='image_retinex_output')(upsample2)\n",
    "\n",
    "task_outputs = None\n",
    "\n",
    "task_outputs = [landmarks, illum, retIllum]\n",
    "\n",
    "multi_task_model = tf.keras.Model(inputs=base_model.input, outputs=task_outputs)\n",
    "\n",
    "# Compile the model with specific loss functions and metrics for each task\n",
    "multi_task_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'landmark_output': 'mean_squared_error',\n",
    "        'previous_illuminance_output': 'mean_squared_error',\n",
    "        'illuminance_retinex_output': 'mean_squared_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'landmark_output': ['mse', \"accuracy\"],\n",
    "        'previous_illuminance_output': ['mse', \"accuracy\"],\n",
    "        'image_retinex_output': ['mse', \"accuracy\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Summary of the multi-task model\n",
    "multi_task_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d821b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T13:41:12.862469Z",
     "start_time": "2023-11-05T13:41:12.167751Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(multi_task_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972d9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T13:41:17.572709Z",
     "start_time": "2023-11-05T13:41:17.568254Z"
    }
   },
   "outputs": [],
   "source": [
    "first_layer = multi_task_model.layers[0]  # Get the first layer\n",
    "input_shape = first_layer.input_shape\n",
    "print(\"Input shape of the first layer:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f2d1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:08:54.417206Z",
     "start_time": "2023-11-05T14:08:54.412665Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(trainLandmarks))\n",
    "print(len(trainIllumsRaw))\n",
    "print(len(trainIllumsRet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d29847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T13:42:59.302898Z",
     "start_time": "2023-11-05T13:42:59.298575Z"
    }
   },
   "outputs": [],
   "source": [
    "# multi_task_model.fit()\n",
    "# trainLandmarks = trainLandmarks[:-1]\n",
    "trainIllumsRaw = trainIllumsRaw[:-2]\n",
    "# print(trainLandmarks)\n",
    "# print(trainIllumsRaw)\n",
    "# print(trainIllumsRet)\n",
    "\n",
    "trainIllumsRawArray = np.array(trainIllumsRaw)\n",
    "trainIllumsRetArray = np.array(trainIllumsRet)\n",
    "\n",
    "# print(trainIllumsRawArray)\n",
    "# print(trainIllumsRetArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888c6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:09:07.229260Z",
     "start_time": "2023-11-05T14:09:07.224820Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train = np.vstack((trainLandmarks, trainIllumsRaw, trainIllumsRet)).T\n",
    "print(Y_train)\n",
    "\n",
    "# Sample 2D NumPy array\n",
    "data = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff25d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:09:11.563740Z",
     "start_time": "2023-11-05T14:09:11.557277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample 2D NumPy array\n",
    "data = Y_train\n",
    "\n",
    "# Extract numerical values from the dictionaries\n",
    "numerical_values = []\n",
    "\n",
    "for row in data:\n",
    "    row_values = []\n",
    "    for element in row:\n",
    "        if isinstance(element, dict):\n",
    "            # Extract numerical values from the dictionary\n",
    "            dict_values = [val for key, val in element.items() if isinstance(val, tuple)]\n",
    "            for tpl in dict_values:\n",
    "                for value in tpl:\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        row_values.append(value)\n",
    "    numerical_values.append(row_values)\n",
    "\n",
    "# Print the numerical values\n",
    "# for row in numerical_values:\n",
    "#     print(row)\n",
    "\n",
    "numerical_values = np.array(numerical_values)\n",
    "print(numerical_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40ff52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:10:05.380140Z",
     "start_time": "2023-11-05T14:10:05.225268Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'data\\Training', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=22, \n",
    "                                                    class_mode='input')\n",
    "\n",
    "for batch in train_generator:\n",
    "    images, labels = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe5f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T09:03:51.551192Z",
     "start_time": "2023-10-31T09:03:51.533969Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'data\\RetTraining', \n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=22,\n",
    "                                                    class_mode='input')\n",
    "\n",
    "for batch in train_generator:\n",
    "    retImages, labels = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf21bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:10:08.809510Z",
     "start_time": "2023-11-05T14:10:08.576764Z"
    }
   },
   "outputs": [],
   "source": [
    "imageTensor = tf.convert_to_tensor(images)\n",
    "landmarkTensor = tf.convert_to_tensor(numerical_values)\n",
    "illuminanceTensor = tf.convert_to_tensor(trainIllumsRawArray)\n",
    "illumsRetTensor = tf.convert_to_tensor(trainIllumsRetArray)\n",
    "imageRetTensor = tf.convert_to_tensor(retImages)\n",
    "\n",
    "print(tf.shape(imageTensor))\n",
    "print(tf.shape(illuminanceTensor))\n",
    "print(tf.shape(landmarkTensor))\n",
    "print(tf.shape(illumsRetTensor))\n",
    "print(tf.shape(retImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8ac7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:10:32.943689Z",
     "start_time": "2023-11-05T14:10:32.937226Z"
    }
   },
   "outputs": [],
   "source": [
    "class InputOutputShapeCallback(Callback):\n",
    "    def __init__(self, input_data, task_names):\n",
    "        super().__init__()\n",
    "        self.input_data = input_data\n",
    "        self.task_names = task_names\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Get the model's first layer (input layer) and last layer (output layer)\n",
    "        input_layer = self.model.layers[0]\n",
    "        output_layers = self.model.layers[1:]  # Exclude the input layer\n",
    "\n",
    "        # Print the shapes of the input and output tensors of the model\n",
    "        print(f\"Input Data Shape: {self.input_data.shape}\")\n",
    "        print(f\"Input Layer Shape: {input_layer.input_shape}\")\n",
    "\n",
    "        # Print the shapes of the output tensors for each task\n",
    "        for task_name, output_layer in zip(self.task_names, output_layers):\n",
    "            print(f\"Output Layer Shape for {task_name}: {output_layer.output_shape}\")\n",
    "\n",
    "# List of task names\n",
    "task_names = ['landmark_output', 'previous_illuminance_output', 'image_retinex_output']\n",
    "\n",
    "# Create an instance of the callback with input data and task names\n",
    "shape_callback = InputOutputShapeCallback(input_data=imageTensor, task_names=task_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d61ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T11:05:08.866023Z",
     "start_time": "2023-10-31T11:03:45.866261Z"
    }
   },
   "outputs": [],
   "source": [
    "history = multi_task_model.fit(x=imageTensor,\n",
    "                              y=[landmarkTensor, illumsRetTensor, imageRetTensor],\n",
    "                              epochs=10,\n",
    "                              batch_size=13)\n",
    "\n",
    "\n",
    "# history = multi_task_model.fit(x=imageTensor,\n",
    "#                                y={'landmark_output': landmarkTensor, \n",
    "#                                 'previous_illuminance_output': illuminanceTensor, \n",
    "#                                 'illuminance_retinex_output': illumsRetTensor},\n",
    "#                                epochs=10,\n",
    "#                                batch_size=4,\n",
    "#                                callbacks=[shape_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52600a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T11:05:18.752754Z",
     "start_time": "2023-10-31T11:05:18.746455Z"
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
